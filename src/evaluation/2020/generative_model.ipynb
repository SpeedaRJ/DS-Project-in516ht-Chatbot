{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from datasets import *\n",
    "import numpy as np\n",
    "import pathlib as pl\n",
    "import pandas as pd\n",
    "import torch\n",
    "import ast\n",
    "import os\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "from haystack.nodes import DensePassageRetriever, Seq2SeqGenerator\n",
    "from haystack.nodes.answer_generator.transformers import _BartEli5Converter\n",
    "from haystack.pipelines import Pipeline\n",
    "\n",
    "YEAR = 2020\n",
    "DPR_FINE_TUNE = True\n",
    "\n",
    "MODEL_PATH = \"../../data/models/T5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/rjutr/.cache/huggingface/datasets/csv/default-441dad80248323f2/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached split indices for dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-441dad80248323f2\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-81887bdfa56bc407.arrow and C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-441dad80248323f2\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-c675e85464b79a7d.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-441dad80248323f2\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-f2b288b0cb18cfcd.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-441dad80248323f2\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-043742aa8e6797a9.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'answers', 'id'],\n",
       "    num_rows: 56\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_data = load_dataset('csv', data_files=f\"../../data/clean/sustainability-report-{YEAR}-squad-format.csv\",\n",
    "                    delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True, seed=42)\n",
    "\n",
    "generated_data[\"test\"] = generated_data[\"test\"].map(\n",
    "    lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "generated_data[\"test\"] = generated_data[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\n",
    "                                  \"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "generated_data[\"test\"].remove_columns([\"text\", \"answer_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = evaluate.load(\"bertscore\")\n",
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = FAISSDocumentStore.load(index_path=\"document_store.faiss\", config_path=\"document_store.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rjutr\\miniconda3\\envs\\project_ds_2\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "if DPR_FINE_TUNE:\n",
    "    retriever = DensePassageRetriever.load(load_dir=f\"../../data/models/DPR/{YEAR}\", document_store=document_store, use_gpu=True)\n",
    "else: \n",
    "    retriever = DensePassageRetriever(\n",
    "        document_store=document_store,\n",
    "        query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "        passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "        use_gpu=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device(\n",
    "    \"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Define the prediction function\n",
    "def inference_answer(model, question):\n",
    "    question = question\n",
    "    with torch.no_grad():\n",
    "        outputs = model.run(query=question, params={\"Model\": {\"top_k\": 3}})\n",
    "    return outputs[\"answers\"][0].answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = os.listdir(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Model\": [],\n",
    "    \"Data\": [],\n",
    "    \"Bert.Precision\": [],\n",
    "    \"Bert.Recall\": [],\n",
    "    \"Bert.F1\": [],\n",
    "    \"BLEU\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_answer_true = [generated_data[\"test\"][\"answers\"][idx][\"text\"][0] for idx in range(generated_data[\"test\"].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model t5-base-finetuned-squadv2-finetuned-NLB-QA-2020-full...\n",
      "Evaluating model t5-base-finetuned-squadv2-finetuned-NLB-QA-2020-smaller...\n",
      "Evaluating model t5-small-finetuned-squadv2-finetuned-NLB-QA-2020-full...\n",
      "Evaluating model t5-small-finetuned-squadv2-finetuned-NLB-QA-2020-smaller...\n"
     ]
    }
   ],
   "source": [
    "generator = None\n",
    "pipe = None\n",
    "\n",
    "for model in models:\n",
    "    model_data = model.split(\"-\")\n",
    "    year = model_data[-2]\n",
    "\n",
    "    if int(year) != YEAR:\n",
    "        continue\n",
    "\n",
    "    print(f\"Evaluating model {model}...\")\n",
    "    model_name = \"-\".join(model_data[:2])\n",
    "    data_name = model_data[-1]\n",
    "\n",
    "    generator = Seq2SeqGenerator(model_name_or_path=f\"{MODEL_PATH}/{model}\", input_converter=_BartEli5Converter())\n",
    "    pipe = Pipeline()\n",
    "    pipe.add_node(component=retriever, name=\"Retriever\", inputs=[\"Query\"])\n",
    "    pipe.add_node(component=generator, name=\"Model\", inputs=[\"Retriever\"])\n",
    "\n",
    "    results[\"Model\"].append(model_name)\n",
    "    results[\"Data\"].append(data_name)\n",
    "\n",
    "    answer_pred = [inference_answer(pipe, generated_data[\"test\"][\"question\"][idx]) for idx in range(generated_data[\"test\"].shape[0])]\n",
    "\n",
    "    results_1 = bertscore.compute(predictions=answer_pred, references=generated_answer_true, lang=\"en\")\n",
    "    results_2 = bleu.compute(predictions=answer_pred, references=generated_answer_true)\n",
    "\n",
    "    results[\"Bert.Precision\"].append(np.array(results_1[\"precision\"]).mean())\n",
    "    results[\"Bert.Recall\"].append(np.array(results_1[\"recall\"]).mean())\n",
    "    results[\"Bert.F1\"].append(np.array(results_1[\"f1\"]).mean())\n",
    "    results[\"BLEU\"].append(results_2[\"bleu\"])\n",
    "\n",
    "    del generator\n",
    "    del pipe\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Data</th>\n",
       "      <th>Bert.Precision</th>\n",
       "      <th>Bert.Recall</th>\n",
       "      <th>Bert.F1</th>\n",
       "      <th>BLEU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>full</td>\n",
       "      <td>0.922392</td>\n",
       "      <td>0.919341</td>\n",
       "      <td>0.920657</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>smaller</td>\n",
       "      <td>0.908387</td>\n",
       "      <td>0.914201</td>\n",
       "      <td>0.910993</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t5-small</td>\n",
       "      <td>full</td>\n",
       "      <td>0.932427</td>\n",
       "      <td>0.928069</td>\n",
       "      <td>0.930096</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t5-small</td>\n",
       "      <td>smaller</td>\n",
       "      <td>0.931120</td>\n",
       "      <td>0.924618</td>\n",
       "      <td>0.927697</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model     Data  Bert.Precision  Bert.Recall   Bert.F1  BLEU\n",
       "0   t5-base     full        0.922392     0.919341  0.920657   0.0\n",
       "1   t5-base  smaller        0.908387     0.914201  0.910993   0.0\n",
       "2  t5-small     full        0.932427     0.928069  0.930096   0.0\n",
       "3  t5-small  smaller        0.931120     0.924618  0.927697   0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_ds_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
