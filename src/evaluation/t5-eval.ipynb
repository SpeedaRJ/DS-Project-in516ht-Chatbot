{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, set_seed\n",
    "from datasets import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "local_models_path = '../models/T5'\n",
    "\n",
    "results = pd.DataFrame(columns=['Model', 'Train Data', 'Data Type', 'Bert.Precision', 'Bert.Recall', 'Bert.F1', 'BLEU'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question, context, tokenizer, model):\n",
    "    input_text = \"question: %s  context: %s\" % (question, context)\n",
    "    features = tokenizer([input_text], return_tensors='pt')\n",
    "\n",
    "    output = model.generate(input_ids=features['input_ids'], attention_mask=features['attention_mask'])\n",
    "\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/rjutr/.cache/huggingface/datasets/csv/default-dc9275c3697e5cc0/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached split indices for dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-dc9275c3697e5cc0\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-0b40be795cd765b7.arrow and C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-dc9275c3697e5cc0\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-3e1cf7e5eca93f71.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-dc9275c3697e5cc0\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-1e92815268136ea2.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-dc9275c3697e5cc0\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-21e74bfcddde162b.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-dc9275c3697e5cc0\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-f966a9c7e65e9acb.arrow\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from file and split it into train and test datasets\n",
    "data_2020_full = load_dataset('csv', data_files=f\"../../data/clean/sustainability-report-2020-squad-format.csv\",\n",
    "                    delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "\n",
    "# Reformat the train and test set such as they adhere to the SQuAD format (reading from cvs loads strings not objects as expected)\n",
    "data_2020_full[\"test\"] = data_2020_full[\"test\"].map(\n",
    "    lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data_2020_full[\"test\"] = data_2020_full[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\n",
    "                                \"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "# replace all \"\\n\" with \" \" in the context, answers and questions\n",
    "data_2020_full[\"test\"] = data_2020_full[\"test\"].map(lambda example: {\"question\": example[\"question\"].replace(\"\\n\", \" \"), \"context\": example[\"context\"].replace(\"\\n\", \" \"), \"answers\": {\n",
    "                                \"text\": [example[\"answers\"][\"text\"][0].replace(\"\\n\", \" \")], \"answer_start\": example[\"answers\"][\"answer_start\"]}})\n",
    "data_2020_full[\"test\"] = data_2020_full[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "# get ground truth answers\n",
    "test_data_2020_full = data_2020_full[\"test\"]\n",
    "gt_answers_2020_full = [temp[\"answers\"][\"text\"][0] for temp in test_data_2020_full]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/rjutr/.cache/huggingface/datasets/csv/default-a8af1b4c8d81fb1c/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached split indices for dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-a8af1b4c8d81fb1c\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-7d8841dd72615495.arrow and C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-a8af1b4c8d81fb1c\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-8b1142ae44904f4e.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-a8af1b4c8d81fb1c\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-36096c12f970e2cd.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-a8af1b4c8d81fb1c\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-b621ad6a176502d0.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-a8af1b4c8d81fb1c\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-c2ee3b08607cceb8.arrow\n"
     ]
    }
   ],
   "source": [
    "data_2022_full = load_dataset('csv', data_files=f\"../../data/clean/sustainability-report-2022-squad-format.csv\",\n",
    "                    delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "\n",
    "# Reformat the train and test set such as they adhere to the SQuAD format (reading from cvs loads strings not objects as expected)\n",
    "data_2022_full[\"test\"] = data_2022_full[\"test\"].map(\n",
    "    lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data_2022_full[\"test\"] = data_2022_full[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\n",
    "                                \"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "# replace all \"\\n\" with \" \" in the context, answers and questions\n",
    "data_2022_full[\"test\"] = data_2022_full[\"test\"].map(lambda example: {\"question\": example[\"question\"].replace(\"\\n\", \" \"), \"context\": example[\"context\"].replace(\"\\n\", \" \"), \"answers\": {\n",
    "                                \"text\": [example[\"answers\"][\"text\"][0].replace(\"\\n\", \" \")], \"answer_start\": example[\"answers\"][\"answer_start\"]}})\n",
    "data_2022_full[\"test\"] = data_2022_full[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "\n",
    "test_data_2022_full = data_2022_full[\"test\"]\n",
    "gt_answers_2022_full = [temp[\"answers\"][\"text\"][0] for temp in test_data_2022_full]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2020 + 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/rjutr/.cache/huggingface/datasets/csv/default-dc46deea403e6d7a/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached split indices for dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-dc46deea403e6d7a\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-8c4226c3883b9f9f.arrow and C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-dc46deea403e6d7a\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-24d9770f6403af3d.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-dc46deea403e6d7a\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-47e77242f5a0d387.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-dc46deea403e6d7a\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-cb788cd2e517f2b5.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-dc46deea403e6d7a\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-4957f1c2e4c5cb13.arrow\n"
     ]
    }
   ],
   "source": [
    "data_2020_2022 = load_dataset('csv', data_files=\"../../data/clean/sustainability-report-2042-squad-format.csv\",\n",
    "                                delimiter=\";\", split=\"train\").train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "\n",
    "# Reformat the train and test set such as they adhere to the SQuAD format (reading from cvs loads strings not objects as expected)\n",
    "data_2020_2022[\"test\"] = data_2020_2022[\"test\"].map(\n",
    "    lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data_2020_2022[\"test\"] = data_2020_2022[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\n",
    "                                \"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "# replace all \"\\n\" with \" \" in the context, answers and questions\n",
    "data_2020_2022[\"test\"] = data_2020_2022[\"test\"].map(lambda example: {\"question\": example[\"question\"].replace(\"\\n\", \" \"), \"context\": example[\"context\"].replace(\"\\n\", \" \"), \"answers\": {\n",
    "                                \"text\": [example[\"answers\"][\"text\"][0].replace(\"\\n\", \" \")], \"answer_start\": example[\"answers\"][\"answer_start\"]}})\n",
    "data_2020_2022[\"test\"] = data_2020_2022[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "# get ground truth answers\n",
    "test_data_2020_2022 = data_2020_2022[\"test\"]\n",
    "gt_answers_2020_2022 = [temp[\"answers\"][\"text\"][0] for temp in test_data_2020_2022]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022 handwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/rjutr/.cache/huggingface/datasets/csv/default-094de926302c4454/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached split indices for dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-094de926302c4454\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-a6b47fc8c478d969.arrow and C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-094de926302c4454\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-4ae4e0308bfc9ae2.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-094de926302c4454\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-b9d36a6ac093f305.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-094de926302c4454\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-c31eb97e51e66589.arrow\n",
      "Loading cached processed dataset at C:\\Users\\rjutr\\.cache\\huggingface\\datasets\\csv\\default-094de926302c4454\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-665c42fd0ca30190.arrow\n"
     ]
    }
   ],
   "source": [
    "data_2022_handwritten = load_dataset('csv', data_files=f\"../../data/clean/QA_SR_2022_Expert-squad-format.csv\",\n",
    "                                        delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "\n",
    "# Reformat the train and test set such as they adhere to the SQuAD format (reading from cvs loads strings not objects as expected)\n",
    "data_2022_handwritten[\"test\"] = data_2022_handwritten[\"test\"].map(\n",
    "    lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data_2022_handwritten[\"test\"] = data_2022_handwritten[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\n",
    "                                \"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "# replace all \"\\n\" with \" \" in the context, answers and questions\n",
    "data_2022_handwritten[\"test\"] = data_2022_handwritten[\"test\"].map(lambda example: {\"question\": example[\"question\"].replace(\"\\n\", \" \"), \"context\": example[\"context\"].replace(\"\\n\", \" \"), \"answers\": {\n",
    "                                \"text\": [example[\"answers\"][\"text\"][0].replace(\"\\n\", \" \")], \"answer_start\": example[\"answers\"][\"answer_start\"]}})\n",
    "data_2022_handwritten[\"test\"] = data_2022_handwritten[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "\n",
    "test_data_2022_handwritten = data_2022_handwritten[\"test\"]\n",
    "gt_answers_2022_handwritten = [temp[\"answers\"][\"text\"][0] for temp in test_data_2022_handwritten]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMPLE EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "c:\\Users\\rjutr\\miniconda3\\envs\\project_ds_2\\lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mrm8488/t5-small-finetuned-squadv2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "answers_2020 = [get_answer(question, context, tokenizer, model) for question, context in zip(test_data_2020_full[\"question\"], test_data_2020_full[\"context\"])]\n",
    "answers_2022 = [get_answer(question, context, tokenizer, model) for question, context in zip(test_data_2022_full[\"question\"], test_data_2022_full[\"context\"])]\n",
    "answers_2020_2022 = [get_answer(question, context, tokenizer, model) for question, context in zip(test_data_2020_2022[\"question\"], test_data_2020_2022[\"context\"])]\n",
    "answers_2022_handwritten = [get_answer(question, context, tokenizer, model) for question, context in zip(test_data_2022_handwritten[\"question\"], test_data_2022_handwritten[\"context\"])]\n",
    "\n",
    "# bertscore\n",
    "bert_results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "bert_results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "bert_results_2020_2022 = bertscore.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022, lang=\"en\")\n",
    "bert_results_2022_handwritten = bertscore.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten, lang=\"en\")\n",
    "# print(f\"Bertscore results 2020\\nF1: {np.array(bert_results_2020['f1']).mean()}, Precision: {np.array(bert_results_2020['precision']).mean()}, Recall: {np.array(bert_results_2020['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022\\nF1: {np.array(bert_results_2022['f1']).mean()}, Precision: {np.array(bert_results_2022['precision']).mean()}, Recall: {np.array(bert_results_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2020-2022\\nF1: {np.array(bert_results_2020_2022['f1']).mean()}, Precision: {np.array(bert_results_2020_2022['precision']).mean()}, Recall: {np.array(bert_results_2020_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022 handwritten\\nF1: {np.array(bert_results_2022_handwritten['f1']).mean()}, Precision: {np.array(bert_results_2022_handwritten['precision']).mean()}, Recall: {np.array(bert_results_2022_handwritten['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "bleu_results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "bleu_results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "bleu_results_2020_2022 = bleu.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022)\n",
    "bleu_results_2022_handwritten = bleu.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten)\n",
    "# print(f\"Bleu results 2020\\n{bleu_results_2020}\")\n",
    "# print(f\"Bleu results 2022\\n{bleu_results_2022}\")\n",
    "# print(f\"Bleu results 2020-2022\\n{bleu_results_2020_2022}\")\n",
    "# print(f\"Bleu results 2022 handwritten\\n{bleu_results_2022_handwritten}\")\n",
    "\n",
    "\n",
    "# add results to dataframe\n",
    "results.loc[len(results)] = ['t5-small', None, '2020', np.array(bert_results_2020['precision']).mean(), np.array(bert_results_2020['recall']).mean(), np.array(bert_results_2020['f1']).mean(), bleu_results_2020['bleu']]\n",
    "results.loc[len(results)] = ['t5-small', None, '2022', np.array(bert_results_2022['precision']).mean(), np.array(bert_results_2022['recall']).mean(), np.array(bert_results_2022['f1']).mean(), bleu_results_2022['bleu']]\n",
    "results.loc[len(results)] = ['t5-small', None, '2020-2022', np.array(bert_results_2020_2022['precision']).mean(), np.array(bert_results_2020_2022['recall']).mean(), np.array(bert_results_2020_2022['f1']).mean(), bleu_results_2020_2022['bleu']]\n",
    "results.loc[len(results)] = ['t5-small', None, '2022 handwritten', np.array(bert_results_2022_handwritten['precision']).mean(), np.array(bert_results_2022_handwritten['recall']).mean(), np.array(bert_results_2022_handwritten['f1']).mean(), bleu_results_2022_handwritten['bleu']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small - finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rjutr\\miniconda3\\envs\\project_ds_2\\lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name_2020 = f\"{local_models_path}/t5-small-finetuned-squadv2-finetuned-NLB-QA-2020-full\"\n",
    "tokenizer_2020 = AutoTokenizer.from_pretrained(model_name_2020, local_files_only=True)\n",
    "model_2020 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2020, local_files_only=True)\n",
    "\n",
    "model_name_2022 = f\"{local_models_path}/t5-small-finetuned-squadv2-finetuned-NLB-QA-2022-full\"\n",
    "tokenizer_2022 = AutoTokenizer.from_pretrained(model_name_2022, local_files_only=True)\n",
    "model_2022 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2022, local_files_only=True)\n",
    "\n",
    "model_name_2020_2022 = f\"{local_models_path}/t5-small-finetuned-squadv2-finetuned-NLB-QA-2042-full_combined\"\n",
    "tokenizer_2020_2022 = AutoTokenizer.from_pretrained(model_name_2020_2022, local_files_only=True)\n",
    "model_2020_2022 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2020_2022, local_files_only=True)\n",
    "\n",
    "model_name_2022_handwritten = f\"{local_models_path}/t5-small-finetuned-squadv2-finetuned-NLB-QA-2022-handwritten\"\n",
    "tokenizer_2022_handwritten = AutoTokenizer.from_pretrained(model_name_2022_handwritten, local_files_only=True)\n",
    "model_2022_handwritten = AutoModelForSeq2SeqLM.from_pretrained(model_name_2022_handwritten, local_files_only=True)\n",
    "\n",
    "answers_2020 = [get_answer(question, context, tokenizer_2020, model_2020) for question, context in zip(test_data_2020_full[\"question\"], test_data_2020_full[\"context\"])]\n",
    "answers_2022 = [get_answer(question, context, tokenizer_2022, model_2022) for question, context in zip(test_data_2022_full[\"question\"], test_data_2022_full[\"context\"])]\n",
    "answers_2020_2022 = [get_answer(question, context, tokenizer_2020_2022, model_2020_2022) for question, context in zip(test_data_2020_2022[\"question\"], test_data_2020_2022[\"context\"])]\n",
    "answers_2022_handwritten = [get_answer(question, context, tokenizer_2022_handwritten, model_2022_handwritten) for question, context in zip(test_data_2022_handwritten[\"question\"], test_data_2022_handwritten[\"context\"])]\n",
    "\n",
    "# bertscore\n",
    "bert_results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "bert_results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "bert_results_2020_2022 = bertscore.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022, lang=\"en\")\n",
    "bert_results_2022_handwritten = bertscore.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten, lang=\"en\")\n",
    "# print(f\"Bertscore results 2020\\nF1: {np.array(bert_results_2020['f1']).mean()}, Precision: {np.array(bert_results_2020['precision']).mean()}, Recall: {np.array(bert_results_2020['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022\\nF1: {np.array(bert_results_2022['f1']).mean()}, Precision: {np.array(bert_results_2022['precision']).mean()}, Recall: {np.array(bert_results_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2020-2022\\nF1: {np.array(bert_results_2020_2022['f1']).mean()}, Precision: {np.array(bert_results_2020_2022['precision']).mean()}, Recall: {np.array(bert_results_2020_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022 handwritten\\nF1: {np.array(bert_results_2022_handwritten['f1']).mean()}, Precision: {np.array(bert_results_2022_handwritten['precision']).mean()}, Recall: {np.array(bert_results_2022_handwritten['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "bleu_results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "bleu_results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "bleu_results_2020_2022 = bleu.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022)\n",
    "bleu_results_2022_handwritten = bleu.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten)\n",
    "# print(f\"Bleu results 2020\\n{bleu_results_2020}\")\n",
    "# print(f\"Bleu results 2022\\n{bleu_results_2022}\")\n",
    "# print(f\"Bleu results 2022 handwritten\\n{bleu_results_2022_handwritten}\")\n",
    "\n",
    "\n",
    "# add results to dataframe\n",
    "results.loc[len(results)] = ['t5-small', 'full', '2020', np.array(bert_results_2020['precision']).mean(), np.array(bert_results_2020['recall']).mean(), np.array(bert_results_2020['f1']).mean(), bleu_results_2020['bleu']]\n",
    "results.loc[len(results)] = ['t5-small', 'full', '2022', np.array(bert_results_2022['precision']).mean(), np.array(bert_results_2022['recall']).mean(), np.array(bert_results_2022['f1']).mean(), bleu_results_2022['bleu']]\n",
    "results.loc[len(results)] = ['t5-small', 'full', '2020-2022', np.array(bert_results_2020_2022['precision']).mean(), np.array(bert_results_2020_2022['recall']).mean(), np.array(bert_results_2020_2022['f1']).mean(), bleu_results_2020_2022['bleu']]\n",
    "results.loc[len(results)] = ['t5-small', 'full', '2022 handwritten', np.array(bert_results_2022_handwritten['precision']).mean(), np.array(bert_results_2022_handwritten['recall']).mean(), np.array(bert_results_2022_handwritten['f1']).mean(), bleu_results_2022_handwritten['bleu']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small - finetuned - train set halved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rjutr\\miniconda3\\envs\\project_ds_2\\lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name_2020 = f\"{local_models_path}/t5-small-finetuned-squadv2-finetuned-NLB-QA-2020-smaller\"\n",
    "tokenizer_2020 = AutoTokenizer.from_pretrained(model_name_2020, local_files_only=True)\n",
    "model_2020 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2020, local_files_only=True)\n",
    "\n",
    "model_name_2022 = f\"{local_models_path}/t5-small-finetuned-squadv2-finetuned-NLB-QA-2022-smaller\"\n",
    "tokenizer_2022 = AutoTokenizer.from_pretrained(model_name_2022, local_files_only=True)\n",
    "model_2022 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2022, local_files_only=True)\n",
    "\n",
    "model_name_2020_2022 = f\"{local_models_path}/t5-small-finetuned-squadv2-finetuned-NLB-QA-2042-smaller_combined\"\n",
    "tokenizer_2020_2022 = AutoTokenizer.from_pretrained(model_name_2020_2022, local_files_only=True)\n",
    "model_2020_2022 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2020_2022, local_files_only=True)\n",
    "\n",
    "answers_2020 = [get_answer(question, context, tokenizer_2020, model_2020) for question, context in zip(test_data_2020_full[\"question\"], test_data_2020_full[\"context\"])]\n",
    "answers_2022 = [get_answer(question, context, tokenizer_2022, model_2022) for question, context in zip(test_data_2022_full[\"question\"], test_data_2022_full[\"context\"])]\n",
    "answers_2020_2022 = [get_answer(question, context, tokenizer_2020_2022, model_2020_2022) for question, context in zip(test_data_2020_2022[\"question\"], test_data_2020_2022[\"context\"])]\n",
    "\n",
    "# bertscore\n",
    "bert_results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "bert_results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "bert_results_2020_2022 = bertscore.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022, lang=\"en\")\n",
    "# print(f\"Bertscore results 2020\\nF1: {np.array(bert_results_2020['f1']).mean()}, Precision: {np.array(bert_results_2020['precision']).mean()}, Recall: {np.array(bert_results_2020['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022\\nF1: {np.array(bert_results_2022['f1']).mean()}, Precision: {np.array(bert_results_2022['precision']).mean()}, Recall: {np.array(bert_results_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2020-2022\\nF1: {np.array(bert_results_2020_2022['f1']).mean()}, Precision: {np.array(bert_results_2020_2022['precision']).mean()}, Recall: {np.array(bert_results_2020_2022['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "bleu_results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "bleu_results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "bleu_results_2020_2022 = bleu.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022)\n",
    "# print(f\"Bleu results 2020\\n{bleu_results_2020}\")\n",
    "# print(f\"Bleu results 2022\\n{bleu_results_2022}\")\n",
    "# print(f\"Bleu results 2020-2022\\n{bleu_results_2020_2022}\")\n",
    "\n",
    "\n",
    "# add results to dataframe\n",
    "results.loc[len(results)] = ['t5-small', 'smaller', '2020', np.array(bert_results_2020['precision']).mean(), np.array(bert_results_2020['recall']).mean(), np.array(bert_results_2020['f1']).mean(), bleu_results_2020['bleu']]\n",
    "results.loc[len(results)] = ['t5-small', 'smaller', '2022', np.array(bert_results_2022['precision']).mean(), np.array(bert_results_2022['recall']).mean(), np.array(bert_results_2022['f1']).mean(), bleu_results_2022['bleu']]\n",
    "results.loc[len(results)] = ['t5-small', 'smaller', '2020-2022', np.array(bert_results_2020_2022['precision']).mean(), np.array(bert_results_2020_2022['recall']).mean(), np.array(bert_results_2020_2022['f1']).mean(), bleu_results_2020_2022['bleu']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "c:\\Users\\rjutr\\miniconda3\\envs\\project_ds_2\\lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mrm8488/t5-base-finetuned-squadv2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "answers_2020 = [get_answer(question, context, tokenizer, model) for question, context in zip(test_data_2020_full[\"question\"], test_data_2020_full[\"context\"])]\n",
    "answers_2022 = [get_answer(question, context, tokenizer, model) for question, context in zip(test_data_2022_full[\"question\"], test_data_2022_full[\"context\"])]\n",
    "answers_2020_2022 = [get_answer(question, context, tokenizer, model) for question, context in zip(test_data_2020_2022[\"question\"], test_data_2020_2022[\"context\"])]\n",
    "answers_2022_handwritten = [get_answer(question, context, tokenizer, model) for question, context in zip(test_data_2022_handwritten[\"question\"], test_data_2022_handwritten[\"context\"])]\n",
    "\n",
    "# bertscore\n",
    "bert_results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "bert_results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "bert_results_2020_2022 = bertscore.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022, lang=\"en\")\n",
    "bert_results_2022_handwritten = bertscore.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten, lang=\"en\")\n",
    "# print(f\"Bertscore results 2020\\nF1: {np.array(bert_results_2020['f1']).mean()}, Precision: {np.array(bert_results_2020['precision']).mean()}, Recall: {np.array(bert_results_2020['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022\\nF1: {np.array(bert_results_2022['f1']).mean()}, Precision: {np.array(bert_results_2022['precision']).mean()}, Recall: {np.array(bert_results_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2020-2022\\nF1: {np.array(bert_results_2020_2022['f1']).mean()}, Precision: {np.array(bert_results_2020_2022['precision']).mean()}, Recall: {np.array(bert_results_2020_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022 handwritten\\nF1: {np.array(bert_results_2022_handwritten['f1']).mean()}, Precision: {np.array(bert_results_2022_handwritten['precision']).mean()}, Recall: {np.array(bert_results_2022_handwritten['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "bleu_results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "bleu_results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "bleu_results_2020_2022 = bleu.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022)\n",
    "bleu_results_2022_handwritten = bleu.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten)\n",
    "# print(f\"Bleu results 2020\\n{bleu_results_2020}\")\n",
    "# print(f\"Bleu results 2022\\n{bleu_results_2022}\")\n",
    "# print(f\"Bleu results 2020-2022\\n{bleu_results_2020_2022}\")\n",
    "# print(f\"Bleu results 2022 handwritten\\n{bleu_results_2022_handwritten}\")\n",
    "\n",
    "\n",
    "# add results to dataframe\n",
    "results.loc[len(results)] = ['t5-base', None, '2020', np.array(bert_results_2020['precision']).mean(), np.array(bert_results_2020['recall']).mean(), np.array(bert_results_2020['f1']).mean(), bleu_results_2020['bleu']]\n",
    "results.loc[len(results)] = ['t5-base', None, '2022', np.array(bert_results_2022['precision']).mean(), np.array(bert_results_2022['recall']).mean(), np.array(bert_results_2022['f1']).mean(), bleu_results_2022['bleu']]\n",
    "results.loc[len(results)] = ['t5-base', None, '2020-2022', np.array(bert_results_2020_2022['precision']).mean(), np.array(bert_results_2020_2022['recall']).mean(), np.array(bert_results_2020_2022['f1']).mean(), bleu_results_2020_2022['bleu']]\n",
    "results.loc[len(results)] = ['t5-base', None, '2022 handwritten', np.array(bert_results_2022_handwritten['precision']).mean(), np.array(bert_results_2022_handwritten['recall']).mean(), np.array(bert_results_2022_handwritten['f1']).mean(), bleu_results_2022_handwritten['bleu']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base - finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rjutr\\miniconda3\\envs\\project_ds_2\\lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name_2020 = f\"{local_models_path}/t5-base-finetuned-squadv2-finetuned-NLB-QA-2020-full\"\n",
    "tokenizer_2020 = AutoTokenizer.from_pretrained(model_name_2020, local_files_only=True)\n",
    "model_2020 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2020, local_files_only=True)\n",
    "\n",
    "model_name_2022 = f\"{local_models_path}/t5-base-finetuned-squadv2-finetuned-NLB-QA-2022-full\"\n",
    "tokenizer_2022 = AutoTokenizer.from_pretrained(model_name_2022, local_files_only=True)\n",
    "model_2022 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2022, local_files_only=True)\n",
    "\n",
    "model_name_2020_2022 = f\"{local_models_path}/t5-base-finetuned-squadv2-finetuned-NLB-QA-2042-full_combined\"\n",
    "tokenizer_2020_2022 = AutoTokenizer.from_pretrained(model_name_2020_2022, local_files_only=True)\n",
    "model_2020_2022 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2020_2022, local_files_only=True)\n",
    "\n",
    "model_name_2022_handwritten = f\"{local_models_path}/t5-base-finetuned-squadv2-finetuned-NLB-QA-2022-handwritten\"\n",
    "tokenizer_2022_handwritten = AutoTokenizer.from_pretrained(model_name_2022_handwritten, local_files_only=True)\n",
    "model_2022_handwritten = AutoModelForSeq2SeqLM.from_pretrained(model_name_2022_handwritten, local_files_only=True)\n",
    "\n",
    "answers_2020 = [get_answer(question, context, tokenizer_2020, model_2020) for question, context in zip(test_data_2020_full[\"question\"], test_data_2020_full[\"context\"])]\n",
    "answers_2022 = [get_answer(question, context, tokenizer_2022, model_2022) for question, context in zip(test_data_2022_full[\"question\"], test_data_2022_full[\"context\"])]\n",
    "answers_2020_2022 = [get_answer(question, context, tokenizer_2020_2022, model_2020_2022) for question, context in zip(test_data_2020_2022[\"question\"], test_data_2020_2022[\"context\"])]\n",
    "answers_2022_handwritten = [get_answer(question, context, tokenizer_2022_handwritten, model_2022_handwritten) for question, context in zip(test_data_2022_handwritten[\"question\"], test_data_2022_handwritten[\"context\"])]\n",
    "\n",
    "# bertscore\n",
    "bert_results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "bert_results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "bert_results_2020_2022 = bertscore.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022, lang=\"en\")\n",
    "bert_results_2022_handwritten = bertscore.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten, lang=\"en\")\n",
    "# print(f\"Bertscore results 2020\\nF1: {np.array(bert_results_2020['f1']).mean()}, Precision: {np.array(bert_results_2020['precision']).mean()}, Recall: {np.array(bert_results_2020['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022\\nF1: {np.array(bert_results_2022['f1']).mean()}, Precision: {np.array(bert_results_2022['precision']).mean()}, Recall: {np.array(bert_results_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2020-2022\\nF1: {np.array(bert_results_2020_2022['f1']).mean()}, Precision: {np.array(bert_results_2020_2022['precision']).mean()}, Recall: {np.array(bert_results_2020_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022 handwritten\\nF1: {np.array(bert_results_2022_handwritten['f1']).mean()}, Precision: {np.array(bert_results_2022_handwritten['precision']).mean()}, Recall: {np.array(bert_results_2022_handwritten['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "bleu_results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "bleu_results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "bleu_results_2020_2022 = bleu.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022)\n",
    "bleu_results_2022_handwritten = bleu.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten)\n",
    "# print(f\"Bleu results 2020\\n{bleu_results_2020}\")\n",
    "# print(f\"Bleu results 2022\\n{bleu_results_2022}\")\n",
    "# print(f\"Bleu results 2020-2022\\n{bleu_results_2020_2022}\")\n",
    "# print(f\"Bleu results 2022 handwritten\\n{bleu_results_2022_handwritten}\")\n",
    "\n",
    "\n",
    "# add results to dataframe\n",
    "results.loc[len(results)] = ['t5-base', 'full', '2020', np.array(bert_results_2020['precision']).mean(), np.array(bert_results_2020['recall']).mean(), np.array(bert_results_2020['f1']).mean(), bleu_results_2020['bleu']]\n",
    "results.loc[len(results)] = ['t5-base', 'full', '2022', np.array(bert_results_2022['precision']).mean(), np.array(bert_results_2022['recall']).mean(), np.array(bert_results_2022['f1']).mean(), bleu_results_2022['bleu']]\n",
    "results.loc[len(results)] = ['t5-base', 'full', '2020-2022', np.array(bert_results_2020_2022['precision']).mean(), np.array(bert_results_2020_2022['recall']).mean(), np.array(bert_results_2020_2022['f1']).mean(), bleu_results_2020_2022['bleu']]\n",
    "results.loc[len(results)] = ['t5-base', 'full', '2022 handwritten', np.array(bert_results_2022_handwritten['precision']).mean(), np.array(bert_results_2022_handwritten['recall']).mean(), np.array(bert_results_2022_handwritten['f1']).mean(), bleu_results_2022_handwritten['bleu']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base - finetuned - train set halved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rjutr\\miniconda3\\envs\\project_ds_2\\lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name_2020 = f\"{local_models_path}/t5-base-finetuned-squadv2-finetuned-NLB-QA-2020-smaller\"\n",
    "tokenizer_2020 = AutoTokenizer.from_pretrained(model_name_2020, local_files_only=True)\n",
    "model_2020 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2020, local_files_only=True)\n",
    "\n",
    "model_name_2022 = f\"{local_models_path}/t5-base-finetuned-squadv2-finetuned-NLB-QA-2022-smaller\"\n",
    "tokenizer_2022 = AutoTokenizer.from_pretrained(model_name_2022, local_files_only=True)\n",
    "model_2022 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2022, local_files_only=True)\n",
    "\n",
    "model_name_2020_2022 = f\"{local_models_path}/t5-base-finetuned-squadv2-finetuned-NLB-QA-2042-smaller_combined\"\n",
    "tokenizer_2020_2022 = AutoTokenizer.from_pretrained(model_name_2020_2022, local_files_only=True)\n",
    "model_2020_2022 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2020_2022, local_files_only=True)\n",
    "\n",
    "answers_2020 = [get_answer(question, context, tokenizer_2020, model_2020) for question, context in zip(test_data_2020_full[\"question\"], test_data_2020_full[\"context\"])]\n",
    "answers_2022 = [get_answer(question, context, tokenizer_2022, model_2022) for question, context in zip(test_data_2022_full[\"question\"], test_data_2022_full[\"context\"])]\n",
    "answers_2020_2022 = [get_answer(question, context, tokenizer_2020_2022, model_2020_2022) for question, context in zip(test_data_2020_2022[\"question\"], test_data_2020_2022[\"context\"])]\n",
    "\n",
    "# bertscore\n",
    "bert_results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "bert_results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "bert_results_2020_2022 = bertscore.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022, lang=\"en\")\n",
    "# print(f\"Bertscore results 2020\\nF1: {np.array(bert_results_2020['f1']).mean()}, Precision: {np.array(bert_results_2020['precision']).mean()}, Recall: {np.array(bert_results_2020['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022\\nF1: {np.array(bert_results_2022['f1']).mean()}, Precision: {np.array(bert_results_2022['precision']).mean()}, Recall: {np.array(bert_results_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2020-2022\\nF1: {np.array(bert_results_2020_2022['f1']).mean()}, Precision: {np.array(bert_results_2020_2022['precision']).mean()}, Recall: {np.array(bert_results_2020_2022['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "bleu_results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "bleu_results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "bleu_results_2020_2022 = bleu.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022)\n",
    "# print(f\"Bleu results 2020\\n{bleu_results_2020}\")\n",
    "# print(f\"Bleu results 2022\\n{bleu_results_2022}\")\n",
    "# print(f\"Bleu results 2020-2022\\n{bleu_results_2020_2022}\")\n",
    "\n",
    "\n",
    "# add results to dataframe\n",
    "results.loc[len(results)] = ['t5-base', 'smaller', '2020', np.array(bert_results_2020['precision']).mean(), np.array(bert_results_2020['recall']).mean(), np.array(bert_results_2020['f1']).mean(), bleu_results_2020['bleu']]\n",
    "results.loc[len(results)] = ['t5-base', 'smaller', '2022', np.array(bert_results_2022['precision']).mean(), np.array(bert_results_2022['recall']).mean(), np.array(bert_results_2022['f1']).mean(), bleu_results_2022['bleu']]\n",
    "results.loc[len(results)] = ['t5-base', 'smaller', '2020-2022', np.array(bert_results_2020_2022['precision']).mean(), np.array(bert_results_2020_2022['recall']).mean(), np.array(bert_results_2020_2022['f1']).mean(), bleu_results_2020_2022['bleu']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Data</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Bert.Precision</th>\n",
       "      <th>Bert.Recall</th>\n",
       "      <th>Bert.F1</th>\n",
       "      <th>BLEU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t5-small</td>\n",
       "      <td>None</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.968748</td>\n",
       "      <td>0.972370</td>\n",
       "      <td>0.970398</td>\n",
       "      <td>0.720917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t5-small</td>\n",
       "      <td>None</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.951183</td>\n",
       "      <td>0.951029</td>\n",
       "      <td>0.950949</td>\n",
       "      <td>0.648030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t5-small</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-2022</td>\n",
       "      <td>0.950706</td>\n",
       "      <td>0.955377</td>\n",
       "      <td>0.952809</td>\n",
       "      <td>0.554557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t5-small</td>\n",
       "      <td>None</td>\n",
       "      <td>2022 handwritten</td>\n",
       "      <td>0.894849</td>\n",
       "      <td>0.863893</td>\n",
       "      <td>0.878725</td>\n",
       "      <td>0.067425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t5-small</td>\n",
       "      <td>full</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.975338</td>\n",
       "      <td>0.981546</td>\n",
       "      <td>0.978331</td>\n",
       "      <td>0.706494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t5-small</td>\n",
       "      <td>full</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.972237</td>\n",
       "      <td>0.976406</td>\n",
       "      <td>0.974130</td>\n",
       "      <td>0.693284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t5-small</td>\n",
       "      <td>full</td>\n",
       "      <td>2020-2022</td>\n",
       "      <td>0.970261</td>\n",
       "      <td>0.981644</td>\n",
       "      <td>0.975732</td>\n",
       "      <td>0.543063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t5-small</td>\n",
       "      <td>full</td>\n",
       "      <td>2022 handwritten</td>\n",
       "      <td>0.922604</td>\n",
       "      <td>0.889278</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.221080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t5-small</td>\n",
       "      <td>smaller</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.973396</td>\n",
       "      <td>0.979162</td>\n",
       "      <td>0.976163</td>\n",
       "      <td>0.706436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t5-small</td>\n",
       "      <td>smaller</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.964420</td>\n",
       "      <td>0.966231</td>\n",
       "      <td>0.965146</td>\n",
       "      <td>0.695172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>t5-small</td>\n",
       "      <td>smaller</td>\n",
       "      <td>2020-2022</td>\n",
       "      <td>0.968889</td>\n",
       "      <td>0.977539</td>\n",
       "      <td>0.973003</td>\n",
       "      <td>0.556324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>None</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.878840</td>\n",
       "      <td>0.904816</td>\n",
       "      <td>0.891197</td>\n",
       "      <td>0.144543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>None</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.893193</td>\n",
       "      <td>0.918082</td>\n",
       "      <td>0.905063</td>\n",
       "      <td>0.133756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-2022</td>\n",
       "      <td>0.882943</td>\n",
       "      <td>0.909456</td>\n",
       "      <td>0.895528</td>\n",
       "      <td>0.127140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>None</td>\n",
       "      <td>2022 handwritten</td>\n",
       "      <td>0.836968</td>\n",
       "      <td>0.847005</td>\n",
       "      <td>0.841285</td>\n",
       "      <td>0.128133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>full</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.987526</td>\n",
       "      <td>0.990874</td>\n",
       "      <td>0.989142</td>\n",
       "      <td>0.855246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>full</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.987095</td>\n",
       "      <td>0.987846</td>\n",
       "      <td>0.987413</td>\n",
       "      <td>0.819159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>full</td>\n",
       "      <td>2020-2022</td>\n",
       "      <td>0.980687</td>\n",
       "      <td>0.984420</td>\n",
       "      <td>0.982464</td>\n",
       "      <td>0.682744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>full</td>\n",
       "      <td>2022 handwritten</td>\n",
       "      <td>0.932102</td>\n",
       "      <td>0.922462</td>\n",
       "      <td>0.926813</td>\n",
       "      <td>0.522983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>smaller</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.988735</td>\n",
       "      <td>0.991858</td>\n",
       "      <td>0.990242</td>\n",
       "      <td>0.823331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>smaller</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.985667</td>\n",
       "      <td>0.986575</td>\n",
       "      <td>0.986059</td>\n",
       "      <td>0.803700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>t5-base</td>\n",
       "      <td>smaller</td>\n",
       "      <td>2020-2022</td>\n",
       "      <td>0.975992</td>\n",
       "      <td>0.981590</td>\n",
       "      <td>0.978646</td>\n",
       "      <td>0.610333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model Train Data         Data Type  Bert.Precision  Bert.Recall  \\\n",
       "0   t5-small       None              2020        0.968748     0.972370   \n",
       "1   t5-small       None              2022        0.951183     0.951029   \n",
       "2   t5-small       None         2020-2022        0.950706     0.955377   \n",
       "3   t5-small       None  2022 handwritten        0.894849     0.863893   \n",
       "4   t5-small       full              2020        0.975338     0.981546   \n",
       "5   t5-small       full              2022        0.972237     0.976406   \n",
       "6   t5-small       full         2020-2022        0.970261     0.981644   \n",
       "7   t5-small       full  2022 handwritten        0.922604     0.889278   \n",
       "8   t5-small    smaller              2020        0.973396     0.979162   \n",
       "9   t5-small    smaller              2022        0.964420     0.966231   \n",
       "10  t5-small    smaller         2020-2022        0.968889     0.977539   \n",
       "11   t5-base       None              2020        0.878840     0.904816   \n",
       "12   t5-base       None              2022        0.893193     0.918082   \n",
       "13   t5-base       None         2020-2022        0.882943     0.909456   \n",
       "14   t5-base       None  2022 handwritten        0.836968     0.847005   \n",
       "15   t5-base       full              2020        0.987526     0.990874   \n",
       "16   t5-base       full              2022        0.987095     0.987846   \n",
       "17   t5-base       full         2020-2022        0.980687     0.984420   \n",
       "18   t5-base       full  2022 handwritten        0.932102     0.922462   \n",
       "19   t5-base    smaller              2020        0.988735     0.991858   \n",
       "20   t5-base    smaller              2022        0.985667     0.986575   \n",
       "21   t5-base    smaller         2020-2022        0.975992     0.981590   \n",
       "\n",
       "     Bert.F1      BLEU  \n",
       "0   0.970398  0.720917  \n",
       "1   0.950949  0.648030  \n",
       "2   0.952809  0.554557  \n",
       "3   0.878725  0.067425  \n",
       "4   0.978331  0.706494  \n",
       "5   0.974130  0.693284  \n",
       "6   0.975732  0.543063  \n",
       "7   0.905240  0.221080  \n",
       "8   0.976163  0.706436  \n",
       "9   0.965146  0.695172  \n",
       "10  0.973003  0.556324  \n",
       "11  0.891197  0.144543  \n",
       "12  0.905063  0.133756  \n",
       "13  0.895528  0.127140  \n",
       "14  0.841285  0.128133  \n",
       "15  0.989142  0.855246  \n",
       "16  0.987413  0.819159  \n",
       "17  0.982464  0.682744  \n",
       "18  0.926813  0.522983  \n",
       "19  0.990242  0.823331  \n",
       "20  0.986059  0.803700  \n",
       "21  0.978646  0.610333  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
