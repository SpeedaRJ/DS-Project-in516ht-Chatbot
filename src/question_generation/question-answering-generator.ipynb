{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haystack model for question answering generation\n",
    "from haystack.nodes import PDFToTextConverter, PreProcessor\n",
    "from haystack.pipelines import QuestionAnswerGenerationPipeline\n",
    "from haystack.nodes import QuestionGenerator\n",
    "from haystack.nodes import TransformersReader\n",
    "\n",
    "# Library for path handling\n",
    "import pathlib as pl\n",
    "\n",
    "# Library for data handling\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model for text extraction from pdf\n",
    "converter = PDFToTextConverter(remove_numeric_tables=True)\n",
    "\n",
    "# File preprocessor\n",
    "preprocessor = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=True,\n",
    "    split_by=\"sentence\",\n",
    "    split_length=4,\n",
    "    split_respect_sentence_boundary=False,\n",
    "    split_overlap=0\n",
    ")\n",
    "\n",
    "# Model for text analysis \n",
    "reader = TransformersReader(\"deepset/roberta-base-squad2\", use_gpu=1)\n",
    "\n",
    "# Question generation model\n",
    "qg = QuestionGenerator()\n",
    "\n",
    "# Question answering generation pipeline\n",
    "qag_pipeline = QuestionAnswerGenerationPipeline(qg, reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model to extract text from pdf\n",
    "extracted = converter.convert(file_path=pl.Path(\"../data/raw/sustainability-report-2022.pdf\"), meta=False, encoding=\"UTF-8\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4091b29f0ad64ad78b9e134ed43bf81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing:   0%|          | 0/1 [00:00<?, ?docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocess the extracted text\n",
    "cleaned = preprocessor.process([extracted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty dataframe for the results\n",
    "data_frame = pd.DataFrame(columns=[\"question\", \"answer\", \"context\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qag_pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Go over the generated document contents\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m i, x \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(cleaned):\n\u001b[0;32m      3\u001b[0m     \u001b[39m# Generate questions and answers from the before pipeline\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     result \u001b[39m=\u001b[39m qag_pipeline\u001b[39m.\u001b[39mrun(documents\u001b[39m=\u001b[39m[x])\n\u001b[0;32m      5\u001b[0m     \u001b[39m# Get the best answer for each question\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     answers \u001b[39m=\u001b[39m [\u001b[39msorted\u001b[39m(answer, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mscore, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m answer \u001b[39min\u001b[39;00m result[\u001b[39m\"\u001b[39m\u001b[39manswers\u001b[39m\u001b[39m\"\u001b[39m]]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'qag_pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "# Go over the generated document contents\n",
    "for i, x in enumerate(cleaned):\n",
    "    # Generate questions and answers from the before pipeline\n",
    "    result = qag_pipeline.run(documents=[x])\n",
    "    # Get the best answer for each question\n",
    "    answers = [sorted(answer, key=lambda x: x.score, reverse=True)[0] for answer in result[\"answers\"]]\n",
    "    # Get the answer and context for each question\n",
    "    answers_x = [answer.answer for answer in answers]\n",
    "    context_x = [answer.context for answer in answers]\n",
    "    # Add the results to the dataframe\n",
    "    data_frame = pd.concat([data_frame,\n",
    "        pd.DataFrame({\"question\": result[\"queries\"], \"answer\": answers_x, \"context\": context_x})], \n",
    "        ignore_index=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all non-valid spacial characters from the dataset\n",
    "data_frame = data_frame.replace('[^a-zA-Z0-9 /.?!,čšžćđ\\-%]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the dataset\n",
    "data_frame.to_csv(\"../data/processed/sustainability-report-2022.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
