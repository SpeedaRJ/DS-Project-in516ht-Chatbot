{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, set_seed\n",
    "from datasets import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "local_models_path = '../../data/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question, context, tokenizer, model):\n",
    "    input_text = \"question: %s  context: %s\" % (question, context)\n",
    "    features = tokenizer([input_text], return_tensors='pt')\n",
    "\n",
    "    output = model.generate(input_ids=features['input_ids'], attention_mask=features['attention_mask'])\n",
    "\n",
    "    return tokenizer.decode(output[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Luka/.cache/huggingface/datasets/csv/default-d8382661cd597e83/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached split indices for dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-d8382661cd597e83\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-c261d5613d28d856.arrow and C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-d8382661cd597e83\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-e61829c1e4a24b65.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-d8382661cd597e83\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-0b15501cefb41ff7.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-d8382661cd597e83\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-e4de42d02343959f.arrow\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from file and split it into train and test datasets\n",
    "data_2020_full = load_dataset('csv', data_files=f\"../../data/clean/sustainability-report-2020-squad-format.csv\",\n",
    "                    delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "\n",
    "# Reformat the train and test set such as they adhere to the SQuAD format (reading from cvs loads strings not objects as expected)\n",
    "data_2020_full[\"test\"] = data_2020_full[\"test\"].map(\n",
    "    lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data_2020_full[\"test\"] = data_2020_full[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\n",
    "                                \"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "data_2020_full[\"test\"] = data_2020_full[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "# get ground truth answers\n",
    "test_data_2020_full = data_2020_full[\"test\"]\n",
    "gt_answers_2020_full = [temp[\"answers\"][\"text\"][0] for temp in test_data_2020_full]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Luka/.cache/huggingface/datasets/csv/default-003bb09dc8228b5f/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached split indices for dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-003bb09dc8228b5f\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-515ab9eb5e89ae1b.arrow and C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-003bb09dc8228b5f\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-bf44f2d0ce4c658e.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-003bb09dc8228b5f\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-0158f993dabee325.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-003bb09dc8228b5f\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-bee36876181b6213.arrow\n"
     ]
    }
   ],
   "source": [
    "data_2022_full = load_dataset('csv', data_files=f\"../../data/clean/sustainability-report-2022-squad-format.csv\",\n",
    "                    delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "\n",
    "# Reformat the train and test set such as they adhere to the SQuAD format (reading from cvs loads strings not objects as expected)\n",
    "data_2022_full[\"test\"] = data_2022_full[\"test\"].map(\n",
    "    lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data_2022_full[\"test\"] = data_2022_full[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\n",
    "                                \"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "data_2022_full[\"test\"] = data_2022_full[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "\n",
    "test_data_2022_full = data_2022_full[\"test\"]\n",
    "gt_answers_2022_full = [temp[\"answers\"][\"text\"][0] for temp in test_data_2022_full]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022 handwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Luka/.cache/huggingface/datasets/csv/default-c5bf9e12cbe5e289/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached split indices for dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-c5bf9e12cbe5e289\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-592f80c0a0f49d80.arrow and C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-c5bf9e12cbe5e289\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-43fd30ca77e717aa.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-c5bf9e12cbe5e289\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-be881e01ba85fe52.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-c5bf9e12cbe5e289\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-aad286fdffd39dc8.arrow\n"
     ]
    }
   ],
   "source": [
    "data_2022_handwritten = load_dataset('csv', data_files=f\"../../data/clean/sr-2022-questions-answers-ALL-squad-format.csv\",\n",
    "                                        delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "\n",
    "# Reformat the train and test set such as they adhere to the SQuAD format (reading from cvs loads strings not objects as expected)\n",
    "data_2022_handwritten[\"test\"] = data_2022_handwritten[\"test\"].map(\n",
    "    lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data_2022_handwritten[\"test\"] = data_2022_handwritten[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\n",
    "                                \"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "data_2022_handwritten[\"test\"] = data_2022_handwritten[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "\n",
    "test_data_2022_handwritten = data_2022_handwritten[\"test\"]\n",
    "gt_answers_2022_handwritten = [temp[\"answers\"][\"text\"][0] for temp in test_data_2022_handwritten]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMPLE EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "c:\\Users\\Luka\\miniconda3\\envs\\project_ds\\lib\\site-packages\\transformers\\generation\\utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bertscore results 2020\n",
      "F1: 0.8861216168318476, Precision: 0.8740572429129055, Recall: 0.8988280562417847\n",
      "Bertscore results 2022\n",
      "F1: 0.870940368866252, Precision: 0.8626914174757271, Recall: 0.8798553821082428\n",
      "Bertscore results 2022 handwritten\n",
      "F1: 0.8875018869127546, Precision: 0.8931958647001357, Recall: 0.8840959015346709\n",
      "Bleu results 2020\n",
      "{'bleu': 0.14932377828599544, 'precisions': [0.2303473491773309, 0.15885947046843177, 0.12873563218390804, 0.10554089709762533], 'brevity_penalty': 1.0, 'length_ratio': 3.529032258064516, 'translation_length': 547, 'reference_length': 155}\n",
      "Bleu results 2022\n",
      "{'bleu': 0.1020040212593282, 'precisions': [0.18302658486707565, 0.1113662456946039, 0.08115183246073299, 0.0654490106544901], 'brevity_penalty': 1.0, 'length_ratio': 3.5434782608695654, 'translation_length': 978, 'reference_length': 276}\n",
      "Bleu results 2022 handwritten\n",
      "{'bleu': 0.2732796294973894, 'precisions': [0.39271255060728744, 0.3584070796460177, 0.32682926829268294, 0.31521739130434784], 'brevity_penalty': 0.7875200905792267, 'length_ratio': 0.8071895424836601, 'translation_length': 247, 'reference_length': 306}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mrm8488/t5-small-finetuned-squadv2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "answers_2020 = [get_answer(question, context, tokenizer, model) for question, context in zip(test_data_2020_full[\"question\"], test_data_2020_full[\"context\"])]\n",
    "answers_2022 = [get_answer(question, context, tokenizer, model) for question, context in zip(test_data_2022_full[\"question\"], test_data_2022_full[\"context\"])]\n",
    "answers_2022_handwritten = [get_answer(question, context, tokenizer, model) for question, context in zip(test_data_2022_handwritten[\"question\"], test_data_2022_handwritten[\"context\"])]\n",
    "\n",
    "# bertscore\n",
    "results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "results_2022_handwritten = bertscore.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten, lang=\"en\")\n",
    "print(f\"Bertscore results 2020\\nF1: {np.array(results_2020['f1']).mean()}, Precision: {np.array(results_2020['precision']).mean()}, Recall: {np.array(results_2020['recall']).mean()}\")\n",
    "print(f\"Bertscore results 2022\\nF1: {np.array(results_2022['f1']).mean()}, Precision: {np.array(results_2022['precision']).mean()}, Recall: {np.array(results_2022['recall']).mean()}\")\n",
    "print(f\"Bertscore results 2022 handwritten\\nF1: {np.array(results_2022_handwritten['f1']).mean()}, Precision: {np.array(results_2022_handwritten['precision']).mean()}, Recall: {np.array(results_2022_handwritten['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "results_2022_handwritten = bleu.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten)\n",
    "print(f\"Bleu results 2020\\n{results_2020}\")\n",
    "print(f\"Bleu results 2022\\n{results_2022}\")\n",
    "print(f\"Bleu results 2022 handwritten\\n{results_2022_handwritten}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small - finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bertscore results 2020\n",
      "F1: 0.8897274413279125, Precision: 0.8763338114534106, Recall: 0.9038189745375088\n",
      "Bertscore results 2022\n",
      "F1: 0.8710922983205207, Precision: 0.8516965218793566, Recall: 0.8918689584063593\n",
      "Bertscore results 2022 handwritten\n",
      "F1: 0.8914862048058283, Precision: 0.8950779948915754, Recall: 0.8898177345593771\n",
      "Bleu results 2020\n",
      "{'bleu': 0.1568508288241227, 'precisions': [0.24150268336314848, 0.16699801192842942, 0.13646532438478748, 0.10997442455242967], 'brevity_penalty': 1.0, 'length_ratio': 3.606451612903226, 'translation_length': 559, 'reference_length': 155}\n",
      "Bleu results 2022\n",
      "{'bleu': 0.11752063190477298, 'precisions': [0.21484375, 0.13304252998909488, 0.09382716049382717, 0.07112375533428165], 'brevity_penalty': 1.0, 'length_ratio': 3.710144927536232, 'translation_length': 1024, 'reference_length': 276}\n",
      "Bleu results 2022 handwritten\n",
      "{'bleu': 0.35494693966573837, 'precisions': [0.45977011494252873, 0.42916666666666664, 0.4018264840182648, 0.398989898989899], 'brevity_penalty': 0.8416308400672834, 'length_ratio': 0.8529411764705882, 'translation_length': 261, 'reference_length': 306}\n"
     ]
    }
   ],
   "source": [
    "model_name_2020 = f\"{local_models_path}/t5-small-finetuned-squadv2-finetuned-NLB-QA-2020-full\"\n",
    "tokenizer_2020 = AutoTokenizer.from_pretrained(model_name_2020, local_files_only=True)\n",
    "model_2020 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2020, local_files_only=True)\n",
    "\n",
    "model_name_2022 = f\"{local_models_path}/t5-small-finetuned-squadv2-finetuned-NLB-QA-2022-full\"\n",
    "tokenizer_2022 = AutoTokenizer.from_pretrained(model_name_2022, local_files_only=True)\n",
    "model_2022 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2022, local_files_only=True)\n",
    "\n",
    "model_name_2022_handwritten = f\"{local_models_path}/t5-small-finetuned-squadv2-finetuned-NLB-QA-2022-handwritten\"\n",
    "tokenizer_2022_handwritten = AutoTokenizer.from_pretrained(model_name_2022_handwritten, local_files_only=True)\n",
    "model_2022_handwritten = AutoModelForSeq2SeqLM.from_pretrained(model_name_2022_handwritten, local_files_only=True)\n",
    "\n",
    "answers_2020 = [get_answer(question, context, tokenizer_2020, model_2020) for question, context in zip(test_data_2020_full[\"question\"], test_data_2020_full[\"context\"])]\n",
    "answers_2022 = [get_answer(question, context, tokenizer_2022, model_2022) for question, context in zip(test_data_2022_full[\"question\"], test_data_2022_full[\"context\"])]\n",
    "answers_2022_handwritten = [get_answer(question, context, tokenizer_2022_handwritten, model_2022_handwritten) for question, context in zip(test_data_2022_handwritten[\"question\"], test_data_2022_handwritten[\"context\"])]\n",
    "\n",
    "# bertscore\n",
    "results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "results_2022_handwritten = bertscore.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten, lang=\"en\")\n",
    "print(f\"Bertscore results 2020\\nF1: {np.array(results_2020['f1']).mean()}, Precision: {np.array(results_2020['precision']).mean()}, Recall: {np.array(results_2020['recall']).mean()}\")\n",
    "print(f\"Bertscore results 2022\\nF1: {np.array(results_2022['f1']).mean()}, Precision: {np.array(results_2022['precision']).mean()}, Recall: {np.array(results_2022['recall']).mean()}\")\n",
    "print(f\"Bertscore results 2022 handwritten\\nF1: {np.array(results_2022_handwritten['f1']).mean()}, Precision: {np.array(results_2022_handwritten['precision']).mean()}, Recall: {np.array(results_2022_handwritten['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "results_2022_handwritten = bleu.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten)\n",
    "print(f\"Bleu results 2020\\n{results_2020}\")\n",
    "print(f\"Bleu results 2022\\n{results_2022}\")\n",
    "print(f\"Bleu results 2022 handwritten\\n{results_2022_handwritten}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small - finetuned - train set halved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bertscore results 2020\n",
      "F1: 0.8894282494272504, Precision: 0.8770850705248969, Recall: 0.902383339192186\n",
      "Bertscore results 2022\n",
      "F1: 0.8768286437631767, Precision: 0.8656512548990338, Recall: 0.8889033643998833\n",
      "Bleu results 2020\n",
      "{'bleu': 0.1556884614710667, 'precisions': [0.2392086330935252, 0.164, 0.13513513513513514, 0.11082474226804123], 'brevity_penalty': 1.0, 'length_ratio': 3.587096774193548, 'translation_length': 556, 'reference_length': 155}\n",
      "Bleu results 2022\n",
      "{'bleu': 0.10862415967904492, 'precisions': [0.2023928215353938, 0.12276785714285714, 0.08491761723700887, 0.06598240469208211], 'brevity_penalty': 1.0, 'length_ratio': 3.6340579710144927, 'translation_length': 1003, 'reference_length': 276}\n"
     ]
    }
   ],
   "source": [
    "model_name_2020 = f\"{local_models_path}/t5-small-finetuned-squadv2-finetuned-NLB-QA-2020-smaller\"\n",
    "tokenizer_2020 = AutoTokenizer.from_pretrained(model_name_2020, local_files_only=True)\n",
    "model_2020 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2020, local_files_only=True)\n",
    "\n",
    "model_name_2022 = f\"{local_models_path}/t5-small-finetuned-squadv2-finetuned-NLB-QA-2022-smaller\"\n",
    "tokenizer_2022 = AutoTokenizer.from_pretrained(model_name_2022, local_files_only=True)\n",
    "model_2022 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2022, local_files_only=True)\n",
    "\n",
    "answers_2020 = [get_answer(question, context, tokenizer_2020, model_2020) for question, context in zip(test_data_2020_full[\"question\"], test_data_2020_full[\"context\"])]\n",
    "answers_2022 = [get_answer(question, context, tokenizer_2022, model_2022) for question, context in zip(test_data_2022_full[\"question\"], test_data_2022_full[\"context\"])]\n",
    "\n",
    "# bertscore\n",
    "results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "print(f\"Bertscore results 2020\\nF1: {np.array(results_2020['f1']).mean()}, Precision: {np.array(results_2020['precision']).mean()}, Recall: {np.array(results_2020['recall']).mean()}\")\n",
    "print(f\"Bertscore results 2022\\nF1: {np.array(results_2022['f1']).mean()}, Precision: {np.array(results_2022['precision']).mean()}, Recall: {np.array(results_2022['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "print(f\"Bleu results 2020\\n{results_2020}\")\n",
    "print(f\"Bleu results 2022\\n{results_2022}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bertscore results 2020\n",
      "F1: 0.8447753457086427, Precision: 0.824425471680505, Recall: 0.8669386208057404\n",
      "Bertscore results 2022\n",
      "F1: 0.8554230616471478, Precision: 0.8355540778035315, Recall: 0.877084895829174\n",
      "Bertscore results 2022 handwritten\n",
      "F1: 0.8456224543707711, Precision: 0.8388337521325975, Recall: 0.8554613419941494\n",
      "Bleu results 2020\n",
      "{'bleu': 0.08073612217075588, 'precisions': [0.11964735516372796, 0.08536585365853659, 0.07038123167155426, 0.05910543130990415], 'brevity_penalty': 1.0, 'length_ratio': 5.122580645161291, 'translation_length': 794, 'reference_length': 155}\n",
      "Bleu results 2022\n",
      "{'bleu': 0.06065554146750149, 'precisions': [0.1196769456681351, 0.07410358565737052, 0.04965156794425087, 0.03073967339097022], 'brevity_penalty': 1.0, 'length_ratio': 4.934782608695652, 'translation_length': 1362, 'reference_length': 276}\n",
      "Bleu results 2022 handwritten\n",
      "{'bleu': 0.17715613418099863, 'precisions': [0.21337579617834396, 0.18430034129692832, 0.16544117647058823, 0.15139442231075698], 'brevity_penalty': 1.0, 'length_ratio': 1.026143790849673, 'translation_length': 314, 'reference_length': 306}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"mrm8488/t5-base-finetuned-squadv2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "answers_2020 = [get_answer(question, context, tokenizer, model) for question, context in zip(test_data_2020_full[\"question\"], test_data_2020_full[\"context\"])]\n",
    "answers_2022 = [get_answer(question, context, tokenizer, model) for question, context in zip(test_data_2022_full[\"question\"], test_data_2022_full[\"context\"])]\n",
    "answers_2022_handwritten = [get_answer(question, context, tokenizer, model) for question, context in zip(test_data_2022_handwritten[\"question\"], test_data_2022_handwritten[\"context\"])]\n",
    "\n",
    "# bertscore\n",
    "results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "results_2022_handwritten = bertscore.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten, lang=\"en\")\n",
    "print(f\"Bertscore results 2020\\nF1: {np.array(results_2020['f1']).mean()}, Precision: {np.array(results_2020['precision']).mean()}, Recall: {np.array(results_2020['recall']).mean()}\")\n",
    "print(f\"Bertscore results 2022\\nF1: {np.array(results_2022['f1']).mean()}, Precision: {np.array(results_2022['precision']).mean()}, Recall: {np.array(results_2022['recall']).mean()}\")\n",
    "print(f\"Bertscore results 2022 handwritten\\nF1: {np.array(results_2022_handwritten['f1']).mean()}, Precision: {np.array(results_2022_handwritten['precision']).mean()}, Recall: {np.array(results_2022_handwritten['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "results_2022_handwritten = bleu.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten)\n",
    "print(f\"Bleu results 2020\\n{results_2020}\")\n",
    "print(f\"Bleu results 2022\\n{results_2022}\")\n",
    "print(f\"Bleu results 2022 handwritten\\n{results_2022_handwritten}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base - finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bertscore results 2020\n",
      "F1: 0.8797242705311094, Precision: 0.8563968549881663, Recall: 0.9045447419796672\n",
      "Bertscore results 2022\n",
      "F1: 0.8749183661469789, Precision: 0.8520659302996698, Recall: 0.899244485057403\n",
      "Bertscore results 2022 handwritten\n",
      "F1: 0.8911153163228717, Precision: 0.88534129517419, Recall: 0.8986274089132037\n",
      "Bleu results 2020\n",
      "{'bleu': 0.17734617872420755, 'precisions': [0.2669039145907473, 0.18774703557312253, 0.15555555555555556, 0.12690355329949238], 'brevity_penalty': 1.0, 'length_ratio': 3.6258064516129034, 'translation_length': 562, 'reference_length': 155}\n",
      "Bleu results 2022\n",
      "{'bleu': 0.15114436332580022, 'precisions': [0.2504798464491363, 0.16684491978609625, 0.12681159420289856, 0.09847434119278779], 'brevity_penalty': 1.0, 'length_ratio': 3.7753623188405796, 'translation_length': 1042, 'reference_length': 276}\n",
      "Bleu results 2022 handwritten\n",
      "{'bleu': 0.40995059579188065, 'precisions': [0.4535211267605634, 0.41317365269461076, 0.3929712460063898, 0.3835616438356164], 'brevity_penalty': 1.0, 'length_ratio': 1.1601307189542485, 'translation_length': 355, 'reference_length': 306}\n"
     ]
    }
   ],
   "source": [
    "model_name_2020 = f\"{local_models_path}/t5-base-finetuned-squadv2-finetuned-NLB-QA-2020-full\"\n",
    "tokenizer_2020 = AutoTokenizer.from_pretrained(model_name_2020, local_files_only=True)\n",
    "model_2020 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2020, local_files_only=True)\n",
    "\n",
    "model_name_2022 = f\"{local_models_path}/t5-base-finetuned-squadv2-finetuned-NLB-QA-2022-full\"\n",
    "tokenizer_2022 = AutoTokenizer.from_pretrained(model_name_2022, local_files_only=True)\n",
    "model_2022 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2022, local_files_only=True)\n",
    "\n",
    "model_name_2022_handwritten = f\"{local_models_path}/t5-base-finetuned-squadv2-finetuned-NLB-QA-2022-handwritten\"\n",
    "tokenizer_2022_handwritten = AutoTokenizer.from_pretrained(model_name_2022_handwritten, local_files_only=True)\n",
    "model_2022_handwritten = AutoModelForSeq2SeqLM.from_pretrained(model_name_2022_handwritten, local_files_only=True)\n",
    "\n",
    "answers_2020 = [get_answer(question, context, tokenizer_2020, model_2020) for question, context in zip(test_data_2020_full[\"question\"], test_data_2020_full[\"context\"])]\n",
    "answers_2022 = [get_answer(question, context, tokenizer_2022, model_2022) for question, context in zip(test_data_2022_full[\"question\"], test_data_2022_full[\"context\"])]\n",
    "answers_2022_handwritten = [get_answer(question, context, tokenizer_2022_handwritten, model_2022_handwritten) for question, context in zip(test_data_2022_handwritten[\"question\"], test_data_2022_handwritten[\"context\"])]\n",
    "\n",
    "# bertscore\n",
    "results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "results_2022_handwritten = bertscore.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten, lang=\"en\")\n",
    "print(f\"Bertscore results 2020\\nF1: {np.array(results_2020['f1']).mean()}, Precision: {np.array(results_2020['precision']).mean()}, Recall: {np.array(results_2020['recall']).mean()}\")\n",
    "print(f\"Bertscore results 2022\\nF1: {np.array(results_2022['f1']).mean()}, Precision: {np.array(results_2022['precision']).mean()}, Recall: {np.array(results_2022['recall']).mean()}\")\n",
    "print(f\"Bertscore results 2022 handwritten\\nF1: {np.array(results_2022_handwritten['f1']).mean()}, Precision: {np.array(results_2022_handwritten['precision']).mean()}, Recall: {np.array(results_2022_handwritten['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "results_2022_handwritten = bleu.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten)\n",
    "print(f\"Bleu results 2020\\n{results_2020}\")\n",
    "print(f\"Bleu results 2022\\n{results_2022}\")\n",
    "print(f\"Bleu results 2022 handwritten\\n{results_2022_handwritten}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base - finetuned - train set halved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bertscore results 2020\n",
      "F1: 0.8820760494896344, Precision: 0.859361724129745, Recall: 0.906265241759164\n",
      "Bertscore results 2022\n",
      "F1: 0.8725655602517529, Precision: 0.8504696744624699, Recall: 0.8960945890328594\n",
      "Bleu results 2020\n",
      "{'bleu': 0.17848622686317264, 'precisions': [0.26833631484794274, 0.18886679920477137, 0.15659955257270694, 0.1278772378516624], 'brevity_penalty': 1.0, 'length_ratio': 3.606451612903226, 'translation_length': 559, 'reference_length': 155}\n",
      "Bleu results 2022\n",
      "{'bleu': 0.14041551856356863, 'precisions': [0.24174757281553397, 0.1570964247020585, 0.11519607843137254, 0.08885754583921016], 'brevity_penalty': 1.0, 'length_ratio': 3.7318840579710146, 'translation_length': 1030, 'reference_length': 276}\n"
     ]
    }
   ],
   "source": [
    "model_name_2020 = f\"{local_models_path}/t5-base-finetuned-squadv2-finetuned-NLB-QA-2020-smaller\"\n",
    "tokenizer_2020 = AutoTokenizer.from_pretrained(model_name_2020, local_files_only=True)\n",
    "model_2020 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2020, local_files_only=True)\n",
    "\n",
    "model_name_2022 = f\"{local_models_path}/t5-base-finetuned-squadv2-finetuned-NLB-QA-2022-smaller\"\n",
    "tokenizer_2022 = AutoTokenizer.from_pretrained(model_name_2022, local_files_only=True)\n",
    "model_2022 = AutoModelForSeq2SeqLM.from_pretrained(model_name_2022, local_files_only=True)\n",
    "\n",
    "answers_2020 = [get_answer(question, context, tokenizer_2020, model_2020) for question, context in zip(test_data_2020_full[\"question\"], test_data_2020_full[\"context\"])]\n",
    "answers_2022 = [get_answer(question, context, tokenizer_2022, model_2022) for question, context in zip(test_data_2022_full[\"question\"], test_data_2022_full[\"context\"])]\n",
    "\n",
    "# bertscore\n",
    "results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "print(f\"Bertscore results 2020\\nF1: {np.array(results_2020['f1']).mean()}, Precision: {np.array(results_2020['precision']).mean()}, Recall: {np.array(results_2020['recall']).mean()}\")\n",
    "print(f\"Bertscore results 2022\\nF1: {np.array(results_2022['f1']).mean()}, Precision: {np.array(results_2022['precision']).mean()}, Recall: {np.array(results_2022['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "print(f\"Bleu results 2020\\n{results_2020}\")\n",
    "print(f\"Bleu results 2022\\n{results_2022}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
