{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "from datasets import *\n",
    "import torch\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/rjutr/.cache/huggingface/datasets/csv/default-6a9a3e730f68f403/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset('csv', data_files=\"../data/clean/sustainability-report-2020-squad-format.csv\", delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f643905f5dad46bda2a992bfd7908b22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038814cf80bd4bf690132e8aa6ea6675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ee1ffa735d42dc94ebc8ad4157ceca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa77cbea85f440abdc38b50d780fcbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'answers', 'id'],\n",
       "    num_rows: 129\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"test\"] = data[\"test\"].map(lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data[\"test\"] = data[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "data[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "\n",
    "data[\"train\"] = data[\"train\"].map(lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data[\"train\"] = data[\"train\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "data[\"train\"].remove_columns([\"text\", \"answer_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47141aa79a4841a4a56acfffc65a9e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rjutr\\miniconda3\\envs\\project_ds\\lib\\site-packages\\huggingface_hub-0.13.3-py3.8.egg\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rjutr\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c73ff0d3846d4256acc186651ecdd69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08c3af1fa5b4530aa2b6249772276db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7984043d3af453ea47c144b72ffee18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased-distilled-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca3fbe2204241a4b141d6b65ce46695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690ec00f8e6b495a9027a1c1f1cbca62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_sample_data(data):\n",
    "  # Tokenize\n",
    "  tokenized_feature = tokenizer(\n",
    "    data[\"question\"],\n",
    "    data[\"context\"],\n",
    "    max_length = 384,\n",
    "    return_overflowing_tokens=True,\n",
    "    stride=128,\n",
    "    truncation=\"only_second\",\n",
    "    padding = \"max_length\",\n",
    "    return_offsets_mapping=True,\n",
    "  )\n",
    "\n",
    "  # When it overflows, multiple rows will be returned for a single example.\n",
    "  # The following then gets the array of corresponding the original sample index.\n",
    "  sample_mapping = tokenized_feature.pop(\"overflow_to_sample_mapping\")\n",
    "  # Get the array of [start_char, end_char + 1] in each token.\n",
    "  # The shape is [returned_row_size, max_length]\n",
    "  offset_mapping = tokenized_feature.pop(\"offset_mapping\")\n",
    "\n",
    "  start_positions = []\n",
    "  end_positions = []\n",
    "  for i, offset in enumerate(offset_mapping):\n",
    "    sample_index = sample_mapping[i]\n",
    "    answers = data[\"answers\"][sample_index]\n",
    "    start_char = answers[\"answer_start\"][0]\n",
    "    end_char = start_char + len(answers[\"text\"][0]) - 1\n",
    "    # The format of sequence_ids is [None, 0, ..., 0, None, None, 1, ..., 1, None, None, ...]\n",
    "    # in which question's token is 0 and contex's token is 1\n",
    "    sequence_ids = tokenized_feature.sequence_ids(i)\n",
    "    # find the start and end index of context\n",
    "    idx = 0\n",
    "    while sequence_ids[idx] != 1:\n",
    "      idx += 1\n",
    "    context_start = idx\n",
    "    while sequence_ids[idx] == 1:\n",
    "      idx += 1\n",
    "    context_end = idx - 1\n",
    "    # Set start positions and end positions in inputs_ids\n",
    "    # Note: The second element in offset is end_char + 1\n",
    "    # if offset[context_start][0] > end_char or offset[context_end][1] <= start_char:\n",
    "    if not (offset[context_start][0] <= start_char and end_char < offset[context_end][1]):\n",
    "      # The case that answer is not inside the context\n",
    "      ## Note : Some tokenizer (such as, tokenizer in rinna model) doesn't place CLS\n",
    "      ## for the first token in sequence, and I then set -1 as positions.\n",
    "      ## (Later I'll process rows with start_positions=-1.)\n",
    "      start_positions.append(-1)\n",
    "      end_positions.append(-1)\n",
    "    else:\n",
    "      # The case that answer is found in the context\n",
    "\n",
    "      # Set start position\n",
    "      idx = context_start\n",
    "      while offset[idx][0] < start_char:\n",
    "        idx += 1\n",
    "      if offset[idx][0] == start_char:\n",
    "        start_positions.append(idx)\n",
    "      else:\n",
    "        start_positions.append(idx - 1)\n",
    "\n",
    "      # Set end position\n",
    "      idx = context_end\n",
    "      while offset[idx][1] > end_char + 1:\n",
    "        idx -= 1\n",
    "      if offset[idx][1] == end_char + 1:\n",
    "        end_positions.append(idx)\n",
    "      else:\n",
    "        end_positions.append(idx + 1)\n",
    "\n",
    "  # Build result\n",
    "  tokenized_feature[\"start_positions\"] = start_positions\n",
    "  tokenized_feature[\"end_positions\"] = end_positions   \n",
    "  return tokenized_feature\n",
    "\n",
    "# Run conversion\n",
    "tokenized_ds = data.map(\n",
    "  tokenize_sample_data,\n",
    "  remove_columns=[\"id\", \"context\", \"question\", \"answers\"],\n",
    "  batched=True,\n",
    "  batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f30b8f74c6432aaf16710bf8ab2c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8329d07f4d5d46e097b0c08175893adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/56 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds = tokenized_ds.filter(lambda x: x[\"start_positions\"] != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'answer_start', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 129\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'answer_start', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 56\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir = \"distilbert-nlb-qa\",\n",
    "  log_level = \"error\",\n",
    "  num_train_epochs = 10,\n",
    "  learning_rate = 2e-5,\n",
    "  lr_scheduler_type = \"linear\",\n",
    "  warmup_steps = 2,\n",
    "  per_device_train_batch_size = 16,\n",
    "  per_device_eval_batch_size = 16,\n",
    "  gradient_accumulation_steps = 16,\n",
    "  evaluation_strategy = \"steps\",\n",
    "  eval_steps = 2,\n",
    "  save_steps = 2,\n",
    "  logging_steps = 2,\n",
    "  push_to_hub = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rjutr\\miniconda3\\envs\\project_ds\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4372, 'learning_rate': 2e-05, 'epoch': 1.78}\n",
      "{'eval_loss': 0.6099743247032166, 'eval_runtime': 0.2752, 'eval_samples_per_second': 203.451, 'eval_steps_per_second': 14.532, 'epoch': 1.78}\n",
      "{'loss': 0.1798, 'learning_rate': 1.5000000000000002e-05, 'epoch': 3.0}\n",
      "{'eval_loss': 0.5812585949897766, 'eval_runtime': 0.2742, 'eval_samples_per_second': 204.194, 'eval_steps_per_second': 14.585, 'epoch': 3.0}\n",
      "{'loss': 0.1233, 'learning_rate': 1e-05, 'epoch': 4.0}\n",
      "{'eval_loss': 0.5635116696357727, 'eval_runtime': 0.2752, 'eval_samples_per_second': 203.452, 'eval_steps_per_second': 14.532, 'epoch': 4.0}\n",
      "{'loss': 0.1481, 'learning_rate': 5e-06, 'epoch': 5.33}\n",
      "{'eval_loss': 0.5557196736335754, 'eval_runtime': 0.2758, 'eval_samples_per_second': 203.041, 'eval_steps_per_second': 14.503, 'epoch': 5.33}\n",
      "{'loss': 0.1892, 'learning_rate': 0.0, 'epoch': 7.0}\n",
      "{'eval_loss': 0.5533846616744995, 'eval_runtime': 0.2732, 'eval_samples_per_second': 204.942, 'eval_steps_per_second': 14.639, 'epoch': 7.0}\n",
      "{'train_runtime': 44.7201, 'train_samples_per_second': 28.846, 'train_steps_per_second': 0.224, 'train_loss': 0.21552665084600447, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=0.21552665084600447, metrics={'train_runtime': 44.7201, 'train_samples_per_second': 28.846, 'train_steps_per_second': 0.224, 'train_loss': 0.21552665084600447, 'epoch': 7.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "  model = model,\n",
    "  args = training_args,\n",
    "  data_collator = data_collator,\n",
    "  train_dataset = tokenized_ds[\"train\"],\n",
    "  eval_dataset = tokenized_ds[\"test\"],\n",
    "  tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5533846616744995, 'eval_runtime': 0.5655, 'eval_samples_per_second': 99.026, 'eval_steps_per_second': 7.073, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5533846616744995,\n",
       " 'eval_runtime': 0.5655,\n",
       " 'eval_samples_per_second': 99.026,\n",
       " 'eval_steps_per_second': 7.073,\n",
       " 'epoch': 7.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def inference_answer(model, question, context):\n",
    "  question = question\n",
    "  context = context\n",
    "  test_feature = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=318,\n",
    "  )\n",
    "  with torch.no_grad():\n",
    "    outputs = model(torch.tensor([test_feature[\"input_ids\"]]).to(device))\n",
    "  start_logits = outputs.start_logits.cpu().numpy()\n",
    "  end_logits = outputs.end_logits.cpu().numpy()\n",
    "  answer_ids = test_feature[\"input_ids\"][np.argmax(start_logits):np.argmax(end_logits)+1]\n",
    "  return \" \".join(tokenizer.batch_decode(answer_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_pred = [inference_answer(model, data[\"test\"][\"question\"][idx], data[\"test\"][\"context\"][idx]) for idx in range(data[\"test\"].shape[0])]\n",
    "answer_true = [data[\"test\"][\"answers\"][idx][\"text\"][0] for idx in range(data[\"test\"].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8967132440635136, Precision: 0.8799982922417777, Recall: 0.9153822979756764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "results = bertscore.compute(predictions=answer_pred, references=answer_true, lang=\"en\")\n",
    "# Embeddings bases\n",
    "print(f\"F1: {np.array(results['f1']).mean()}, Precision: {np.array(results['precision']).mean()}, Recall: {np.array(results['recall']).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact': 32.142857142857146,\n",
       " 'f1': 51.01089152075996,\n",
       " 'total': 56,\n",
       " 'HasAns_exact': 32.142857142857146,\n",
       " 'HasAns_f1': 51.01089152075996,\n",
       " 'HasAns_total': 56,\n",
       " 'best_exact': 32.142857142857146,\n",
       " 'best_exact_thresh': 0.0,\n",
       " 'best_f1': 51.01089152075996,\n",
       " 'best_f1_thresh': 0.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_v2_metric = evaluate.load(\"squad_v2\")\n",
    "references = [{\"answers\": {\"answer_start\": [answer[\"answer_start\"][0]], \"text\": [answer[\"text\"][0]]}, \"id\": str(id)} for id, answer in zip(data[\"test\"][\"id\"], data[\"test\"][\"answers\"])]\n",
    "predictions = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data[\"test\"][\"id\"], answer_pred)]\n",
    "results = squad_v2_metric.compute(predictions=predictions, references=references)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.12807288493596483,\n",
       " 'precisions': [0.2621145374449339,\n",
       "  0.17293233082706766,\n",
       "  0.10057471264367816,\n",
       "  0.05901639344262295],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 2.4148936170212765,\n",
       " 'translation_length': 454,\n",
       " 'reference_length': 188}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "references = [[answer] for answer in answer_true]\n",
    "predictions = answer_pred\n",
    "# N-Gram based\n",
    "results = bleu.compute(predictions=predictions, references=references)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_ft = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_pred_no_ft = [inference_answer(model_no_ft, data[\"test\"][\"question\"][idx], data[\"test\"][\"context\"][idx]) for idx in range(data[\"test\"].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8821883414472852, Precision: 0.8647412029760224, Recall: 0.9015512753810201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "results = bertscore.compute(predictions=answer_pred_no_ft, references=answer_true, lang=\"en\")\n",
    "# Embeddings bases\n",
    "print(f\"F1: {np.array(results['f1']).mean()}, Precision: {np.array(results['precision']).mean()}, Recall: {np.array(results['recall']).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact': 30.357142857142858,\n",
       " 'f1': 51.58764396086644,\n",
       " 'total': 56,\n",
       " 'HasAns_exact': 30.357142857142858,\n",
       " 'HasAns_f1': 51.58764396086644,\n",
       " 'HasAns_total': 56,\n",
       " 'best_exact': 30.357142857142858,\n",
       " 'best_exact_thresh': 0.0,\n",
       " 'best_f1': 51.58764396086644,\n",
       " 'best_f1_thresh': 0.0}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references = [{\"answers\": {\"answer_start\": [answer[\"answer_start\"][0]], \"text\": [answer[\"text\"][0]]}, \"id\": str(id)} for id, answer in zip(data[\"test\"][\"id\"], data[\"test\"][\"answers\"])]\n",
    "predictions = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data[\"test\"][\"id\"], answer_pred_no_ft)]\n",
    "results = squad_v2_metric.compute(predictions=predictions, references=references)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.1426860827382191,\n",
       " 'precisions': [0.27901785714285715,\n",
       "  0.18781725888324874,\n",
       "  0.11337209302325581,\n",
       "  0.06976744186046512],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 2.382978723404255,\n",
       " 'translation_length': 448,\n",
       " 'reference_length': 188}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references = [[answer] for answer in answer_true]\n",
    "predictions = answer_pred_no_ft\n",
    "# N-Gram based\n",
    "results = bleu.compute(predictions=predictions, references=references)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
