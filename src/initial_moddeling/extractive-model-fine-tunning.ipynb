{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "from datasets import *\n",
    "import torch\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/rjutr/.cache/huggingface/datasets/csv/default-6a9a3e730f68f403/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset('csv', data_files=\"../data/clean/sustainability-report-2020-squad-format.csv\", delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c298ac5fbd7c4c8685453b6cb44c59c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75200d5b0ba24e1599b1610e7e4a7763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3d480b974c4c858257c57611ffe518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "659f7e1fe8c341e3a216bc608a496c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'answers', 'id'],\n",
       "    num_rows: 129\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"test\"] = data[\"test\"].map(lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data[\"test\"] = data[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "data[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "\n",
    "data[\"train\"] = data[\"train\"].map(lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data[\"train\"] = data[\"train\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "data[\"train\"].remove_columns([\"text\", \"answer_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased-distilled-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c88026ffe1548c2a41dc220af68c69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2448ecda4f204d5eae09fcbd10c7fd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_sample_data(data):\n",
    "  # Tokenize\n",
    "  tokenized_feature = tokenizer(\n",
    "    data[\"question\"],\n",
    "    data[\"context\"],\n",
    "    max_length = 384,\n",
    "    return_overflowing_tokens=True,\n",
    "    stride=128,\n",
    "    truncation=\"only_second\",\n",
    "    padding = \"max_length\",\n",
    "    return_offsets_mapping=True,\n",
    "  )\n",
    "\n",
    "  # When it overflows, multiple rows will be returned for a single example.\n",
    "  # The following then gets the array of corresponding the original sample index.\n",
    "  sample_mapping = tokenized_feature.pop(\"overflow_to_sample_mapping\")\n",
    "  # Get the array of [start_char, end_char + 1] in each token.\n",
    "  # The shape is [returned_row_size, max_length]\n",
    "  offset_mapping = tokenized_feature.pop(\"offset_mapping\")\n",
    "\n",
    "  start_positions = []\n",
    "  end_positions = []\n",
    "  for i, offset in enumerate(offset_mapping):\n",
    "    sample_index = sample_mapping[i]\n",
    "    answers = data[\"answers\"][sample_index]\n",
    "    start_char = answers[\"answer_start\"][0]\n",
    "    end_char = start_char + len(answers[\"text\"][0]) - 1\n",
    "    # The format of sequence_ids is [None, 0, ..., 0, None, None, 1, ..., 1, None, None, ...]\n",
    "    # in which question's token is 0 and contex's token is 1\n",
    "    sequence_ids = tokenized_feature.sequence_ids(i)\n",
    "    # find the start and end index of context\n",
    "    idx = 0\n",
    "    while sequence_ids[idx] != 1:\n",
    "      idx += 1\n",
    "    context_start = idx\n",
    "    while sequence_ids[idx] == 1:\n",
    "      idx += 1\n",
    "    context_end = idx - 1\n",
    "    # Set start positions and end positions in inputs_ids\n",
    "    # Note: The second element in offset is end_char + 1\n",
    "    # if offset[context_start][0] > end_char or offset[context_end][1] <= start_char:\n",
    "    if not (offset[context_start][0] <= start_char and end_char < offset[context_end][1]):\n",
    "      # The case that answer is not inside the context\n",
    "      ## Note : Some tokenizer (such as, tokenizer in rinna model) doesn't place CLS\n",
    "      ## for the first token in sequence, and I then set -1 as positions.\n",
    "      ## (Later I'll process rows with start_positions=-1.)\n",
    "      start_positions.append(-1)\n",
    "      end_positions.append(-1)\n",
    "    else:\n",
    "      # The case that answer is found in the context\n",
    "\n",
    "      # Set start position\n",
    "      idx = context_start\n",
    "      while offset[idx][0] < start_char:\n",
    "        idx += 1\n",
    "      if offset[idx][0] == start_char:\n",
    "        start_positions.append(idx)\n",
    "      else:\n",
    "        start_positions.append(idx - 1)\n",
    "\n",
    "      # Set end position\n",
    "      idx = context_end\n",
    "      while offset[idx][1] > end_char + 1:\n",
    "        idx -= 1\n",
    "      if offset[idx][1] == end_char + 1:\n",
    "        end_positions.append(idx)\n",
    "      else:\n",
    "        end_positions.append(idx + 1)\n",
    "\n",
    "  # Build result\n",
    "  tokenized_feature[\"start_positions\"] = start_positions\n",
    "  tokenized_feature[\"end_positions\"] = end_positions   \n",
    "  return tokenized_feature\n",
    "\n",
    "# Run conversion\n",
    "tokenized_ds = data.map(\n",
    "  tokenize_sample_data,\n",
    "  remove_columns=[\"id\", \"context\", \"question\", \"answers\"],\n",
    "  batched=True,\n",
    "  batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ff110bf4814f84a9e9fb389c59b569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e357167bb1254d4587bef76cf4ee6058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/56 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds = tokenized_ds.filter(lambda x: x[\"start_positions\"] != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'answer_start', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 129\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'answer_start', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 56\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir = \"distilbert-nlb-qa\",\n",
    "  log_level = \"error\",\n",
    "  num_train_epochs = 10,\n",
    "  learning_rate = 2e-5,\n",
    "  lr_scheduler_type = \"linear\",\n",
    "  warmup_steps = 2,\n",
    "  per_device_train_batch_size = 16,\n",
    "  per_device_eval_batch_size = 16,\n",
    "  gradient_accumulation_steps = 16,\n",
    "  evaluation_strategy = \"steps\",\n",
    "  eval_steps = 2,\n",
    "  save_steps = 2,\n",
    "  logging_steps = 2,\n",
    "  push_to_hub = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rjutr\\miniconda3\\envs\\project_ds\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c42a33840549c48a43c3227801e3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3238, 'learning_rate': 2e-05, 'epoch': 1.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038282ee3d634ca6a68d74a8bd855b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8242867588996887, 'eval_runtime': 0.2758, 'eval_samples_per_second': 203.027, 'eval_steps_per_second': 14.502, 'epoch': 1.78}\n",
      "{'loss': 0.1439, 'learning_rate': 1.5000000000000002e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27629f68c85d4e76aefa5c9c78204b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7688385248184204, 'eval_runtime': 0.2853, 'eval_samples_per_second': 196.305, 'eval_steps_per_second': 14.022, 'epoch': 3.0}\n",
      "{'loss': 0.1114, 'learning_rate': 1e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21001eb969c74eec9b24898e0b657b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7356680035591125, 'eval_runtime': 0.2773, 'eval_samples_per_second': 201.982, 'eval_steps_per_second': 14.427, 'epoch': 4.0}\n",
      "{'loss': 0.1357, 'learning_rate': 5e-06, 'epoch': 5.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8285e74e860473ba8e4e86ecb06e295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7180922627449036, 'eval_runtime': 0.2763, 'eval_samples_per_second': 202.674, 'eval_steps_per_second': 14.477, 'epoch': 5.33}\n",
      "{'loss': 0.1253, 'learning_rate': 0.0, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bace2766f2e24c9e8f32862ff10972d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7125275731086731, 'eval_runtime': 0.2793, 'eval_samples_per_second': 200.535, 'eval_steps_per_second': 14.324, 'epoch': 7.0}\n",
      "{'train_runtime': 34.3988, 'train_samples_per_second': 37.501, 'train_steps_per_second': 0.291, 'train_loss': 0.16803598403930664, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=0.16803598403930664, metrics={'train_runtime': 34.3988, 'train_samples_per_second': 37.501, 'train_steps_per_second': 0.291, 'train_loss': 0.16803598403930664, 'epoch': 7.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "  model = model,\n",
    "  args = training_args,\n",
    "  data_collator = data_collator,\n",
    "  train_dataset = tokenized_ds[\"train\"],\n",
    "  eval_dataset = tokenized_ds[\"test\"],\n",
    "  tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd26ce2bdb5f4749b1e0326add78bc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7125275731086731,\n",
       " 'eval_runtime': 0.4294,\n",
       " 'eval_samples_per_second': 130.417,\n",
       " 'eval_steps_per_second': 9.316,\n",
       " 'epoch': 7.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def inference_answer(model, question, context):\n",
    "  question = question\n",
    "  context = context\n",
    "  test_feature = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=318\n",
    "  )\n",
    "  with torch.no_grad():\n",
    "    outputs = model(torch.tensor([test_feature[\"input_ids\"]]).to(device))\n",
    "  start_logits = outputs.start_logits.cpu().numpy()\n",
    "  end_logits = outputs.end_logits.cpu().numpy()\n",
    "  answer_ids = test_feature[\"input_ids\"][np.argmax(start_logits):np.argmax(end_logits)+1]\n",
    "  return \" \".join(tokenizer.batch_decode(answer_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_pred = [inference_answer(model, data[\"test\"][\"question\"][idx], data[\"test\"][\"context\"][idx]) for idx in range(data[\"test\"].shape[0])]\n",
    "answer_true = [data[\"test\"][\"answers\"][idx][\"text\"][0] for idx in range(data[\"test\"].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8900739869901112, Precision: 0.8748272540313857, Recall: 0.9073505688990865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "results = bertscore.compute(predictions=answer_pred, references=answer_true, lang=\"en\")\n",
    "# Embeddings bases\n",
    "print(f\"F1: {np.array(results['f1']).mean()}, Precision: {np.array(results['precision']).mean()}, Recall: {np.array(results['recall']).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact': 37.5,\n",
       " 'f1': 49.108280993556846,\n",
       " 'total': 56,\n",
       " 'HasAns_exact': 37.5,\n",
       " 'HasAns_f1': 49.108280993556846,\n",
       " 'HasAns_total': 56,\n",
       " 'best_exact': 37.5,\n",
       " 'best_exact_thresh': 0.0,\n",
       " 'best_f1': 49.108280993556846,\n",
       " 'best_f1_thresh': 0.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_v2_metric = evaluate.load(\"squad_v2\")\n",
    "references = [{\"answers\": {\"answer_start\": [answer[\"answer_start\"][0]], \"text\": [answer[\"text\"][0]]}, \"id\": str(id)} for id, answer in zip(data[\"test\"][\"id\"], data[\"test\"][\"answers\"])]\n",
    "predictions = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data[\"test\"][\"id\"], answer_pred)]\n",
    "results = squad_v2_metric.compute(predictions=predictions, references=references)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.09194097910786668,\n",
       " 'precisions': [0.2206703910614525,\n",
       "  0.12871287128712872,\n",
       "  0.0694980694980695,\n",
       "  0.03619909502262444],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 2.435374149659864,\n",
       " 'translation_length': 358,\n",
       " 'reference_length': 147}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "references = [[answer] for answer in answer_true]\n",
    "predictions = answer_pred\n",
    "# N-Gram based\n",
    "results = bleu.compute(predictions=predictions, references=references)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_no_ft = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_pred_no_ft = [inference_answer(model_no_ft, data[\"test\"][\"question\"][idx], data[\"test\"][\"context\"][idx]) for idx in range(data[\"test\"].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8753770696265357, Precision: 0.8592591062188148, Recall: 0.8936118877359799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "results = bertscore.compute(predictions=answer_pred_no_ft, references=answer_true, lang=\"en\")\n",
    "# Embeddings bases\n",
    "print(f\"F1: {np.array(results['f1']).mean()}, Precision: {np.array(results['precision']).mean()}, Recall: {np.array(results['recall']).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact': 35.714285714285715,\n",
       " 'f1': 48.04535582348882,\n",
       " 'total': 56,\n",
       " 'HasAns_exact': 35.714285714285715,\n",
       " 'HasAns_f1': 48.04535582348882,\n",
       " 'HasAns_total': 56,\n",
       " 'best_exact': 35.714285714285715,\n",
       " 'best_exact_thresh': 0.0,\n",
       " 'best_f1': 48.04535582348882,\n",
       " 'best_f1_thresh': 0.0}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references = [{\"answers\": {\"answer_start\": [answer[\"answer_start\"][0]], \"text\": [answer[\"text\"][0]]}, \"id\": str(id)} for id, answer in zip(data[\"test\"][\"id\"], data[\"test\"][\"answers\"])]\n",
    "predictions = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data[\"test\"][\"id\"], answer_pred_no_ft)]\n",
    "results = squad_v2_metric.compute(predictions=predictions, references=references)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.08900338261311068,\n",
       " 'precisions': [0.2154255319148936,\n",
       "  0.12732919254658384,\n",
       "  0.0683453237410072,\n",
       "  0.03347280334728033],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 2.557823129251701,\n",
       " 'translation_length': 376,\n",
       " 'reference_length': 147}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references = [[answer] for answer in answer_true]\n",
    "predictions = answer_pred_no_ft\n",
    "# N-Gram based\n",
    "results = bleu.compute(predictions=predictions, references=references)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./distilbert-nlb-qa\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
