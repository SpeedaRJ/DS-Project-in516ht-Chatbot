{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "from transformers import TFDistilBertForSequenceClassification\n",
    "from datasets import *\n",
    "import torch\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv('../data/clean/sustainability-report-2020-clean-BST_KK-fixed-with_starts.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine answe and answer_start into a new column called answers, make it a dict with keys 'text' and 'answer_start'\n",
    "data_frame['answers'] = data_frame.apply(lambda x: {'text': [x['answer']], 'answer_start': [x['answer_start']]}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add id column\n",
    "data_frame['id'] = data_frame.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column fLABEl\n",
    "data_frame = data_frame.drop(columns=['fLABEL', \"answer\", \"answer_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>context</th>\n",
       "      <th>answers</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What percentage of female managers were women ...</td>\n",
       "      <td>nts.56% of female managersAt the end of the ye...</td>\n",
       "      <td>{'text': ['56%'], 'answer_start': [4]}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What percentage of managers were women in the ...</td>\n",
       "      <td>e end of the year, women represented56% of all...</td>\n",
       "      <td>{'text': ['49%'], 'answer_start': [69]}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How much of managers in the second management ...</td>\n",
       "      <td>nagement positions. 49% ofwomen at the first m...</td>\n",
       "      <td>{'text': ['55%'], 'answer_start': [67]}</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What percentage of Supervisory and Management ...</td>\n",
       "      <td>Women represent 31% of allSupervisory and Mana...</td>\n",
       "      <td>{'text': ['31%'], 'answer_start': [16]}</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In 2020, what was the proportion of staff with...</td>\n",
       "      <td>rtunities. In 2020 the proportionof staff with...</td>\n",
       "      <td>{'text': ['2%.'], 'answer_start': [69]}</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>What percentage of Komercijalna Banka a.d. Beo...</td>\n",
       "      <td>of work and creativity.With the completion of...</td>\n",
       "      <td>{'text': ['83.23%'], 'answer_start': [69]}</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>When was Banka a.d. Beograd acquired?</td>\n",
       "      <td>ry shareholding inKomercijalna Banka a.d. Beog...</td>\n",
       "      <td>{'text': ['2020'], 'answer_start': [67]}</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>What is the name of the financial institution ...</td>\n",
       "      <td>e completion of the acquisition of an 83.23% o...</td>\n",
       "      <td>{'text': ['Komercijalna Banka a.d. Beograd'], ...</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>When was Komercijalna Banka acquired?</td>\n",
       "      <td>in our home, the SEE region.Since Komercijalna...</td>\n",
       "      <td>{'text': ['30th December 2020'], 'answer_start...</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>In what year do we plan to fully integrate Kom...</td>\n",
       "      <td>In 2021, we plan to fully integrate Komercijal...</td>\n",
       "      <td>{'text': ['2021'], 'answer_start': [3]}</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    What percentage of female managers were women ...   \n",
       "1    What percentage of managers were women in the ...   \n",
       "2    How much of managers in the second management ...   \n",
       "3    What percentage of Supervisory and Management ...   \n",
       "4    In 2020, what was the proportion of staff with...   \n",
       "..                                                 ...   \n",
       "180  What percentage of Komercijalna Banka a.d. Beo...   \n",
       "181              When was Banka a.d. Beograd acquired?   \n",
       "182  What is the name of the financial institution ...   \n",
       "183              When was Komercijalna Banka acquired?   \n",
       "184  In what year do we plan to fully integrate Kom...   \n",
       "\n",
       "                                               context  \\\n",
       "0    nts.56% of female managersAt the end of the ye...   \n",
       "1    e end of the year, women represented56% of all...   \n",
       "2    nagement positions. 49% ofwomen at the first m...   \n",
       "3    Women represent 31% of allSupervisory and Mana...   \n",
       "4    rtunities. In 2020 the proportionof staff with...   \n",
       "..                                                 ...   \n",
       "180   of work and creativity.With the completion of...   \n",
       "181  ry shareholding inKomercijalna Banka a.d. Beog...   \n",
       "182  e completion of the acquisition of an 83.23% o...   \n",
       "183  in our home, the SEE region.Since Komercijalna...   \n",
       "184  In 2021, we plan to fully integrate Komercijal...   \n",
       "\n",
       "                                               answers   id  \n",
       "0               {'text': ['56%'], 'answer_start': [4]}    0  \n",
       "1              {'text': ['49%'], 'answer_start': [69]}    1  \n",
       "2              {'text': ['55%'], 'answer_start': [67]}    2  \n",
       "3              {'text': ['31%'], 'answer_start': [16]}    3  \n",
       "4              {'text': ['2%.'], 'answer_start': [69]}    4  \n",
       "..                                                 ...  ...  \n",
       "180         {'text': ['83.23%'], 'answer_start': [69]}  180  \n",
       "181           {'text': ['2020'], 'answer_start': [67]}  181  \n",
       "182  {'text': ['Komercijalna Banka a.d. Beograd'], ...  182  \n",
       "183  {'text': ['30th December 2020'], 'answer_start...  183  \n",
       "184            {'text': ['2021'], 'answer_start': [3]}  184  \n",
       "\n",
       "[185 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv('../data/clean/sustainability-report-2020-squad-format.csv', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/rjutr/.cache/huggingface/datasets/csv/default-6dc907f97847b38a/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee4e229dfac4fb78d1cdcb0b3d5dd22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c952d2c732d490aa1e5085129104b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "776c015e733e491888110564395f3819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/rjutr/.cache/huggingface/datasets/csv/default-6dc907f97847b38a/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset('csv', data_files=\"../data/clean/sustainability-report-2020-squad-format.csv\", delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c56d028f74541d9aff0518edeaadebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd39f0e5909e4e0cb7bcbe5f72abfbad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37ba8f7b42147a59c4dbe4cb7912769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705baa57ccf3419092de62e58c68eeeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'answers', 'id'],\n",
       "    num_rows: 129\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"test\"] = data[\"test\"].map(lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data[\"test\"] = data[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "data[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "\n",
    "data[\"train\"] = data[\"train\"].map(lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data[\"train\"] = data[\"train\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "data[\"train\"].remove_columns([\"text\", \"answer_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2429924033944fee82705b74df5e06d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b3abc68edd481ebd69c16fb8351823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/56 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_sample_data(data):\n",
    "  # tokenize\n",
    "  tokenized_feature = tokenizer(\n",
    "    data[\"question\"],\n",
    "    data[\"context\"],\n",
    "    max_length = 384,\n",
    "    return_overflowing_tokens=True,\n",
    "    stride=128,\n",
    "    truncation=\"only_second\",\n",
    "    padding = \"max_length\",\n",
    "    return_offsets_mapping=True,\n",
    "  )\n",
    "\n",
    "  # When it overflows, multiple rows will be returned for a single example.\n",
    "  # The following then gets the array of corresponding the original sample index.\n",
    "  sample_mapping = tokenized_feature.pop(\"overflow_to_sample_mapping\")\n",
    "  # Get the array of [start_char, end_char + 1] in each token.\n",
    "  # The shape is [returned_row_size, max_length]\n",
    "  offset_mapping = tokenized_feature.pop(\"offset_mapping\")\n",
    "\n",
    "  start_positions = []\n",
    "  end_positions = []\n",
    "  for i, offset in enumerate(offset_mapping):\n",
    "    sample_index = sample_mapping[i]\n",
    "    answers = data[\"answers\"][sample_index]\n",
    "    start_char = answers[\"answer_start\"][0]\n",
    "    end_char = start_char + len(answers[\"text\"][0]) - 1\n",
    "    # The format of sequence_ids is [None, 0, ..., 0, None, None, 1, ..., 1, None, None, ...]\n",
    "    # in which question's token is 0 and contex's token is 1\n",
    "    sequence_ids = tokenized_feature.sequence_ids(i)\n",
    "    # find the start and end index of context\n",
    "    idx = 0\n",
    "    while sequence_ids[idx] != 1:\n",
    "      idx += 1\n",
    "    context_start = idx\n",
    "    while sequence_ids[idx] == 1:\n",
    "      idx += 1\n",
    "    context_end = idx - 1\n",
    "    # Set start positions and end positions in inputs_ids\n",
    "    # Note: The second element in offset is end_char + 1\n",
    "    #if offset[context_start][0] > end_char or offset[context_end][1] <= start_char:\n",
    "    if not (offset[context_start][0] <= start_char and end_char < offset[context_end][1]):\n",
    "      # The case that answer is not inside the context\n",
    "      ## Note : Some tokenizer (such as, tokenizer in rinna model) doesn't place CLS\n",
    "      ## for the first token in sequence, and I then set -1 as positions.\n",
    "      ## (Later I'll process rows with start_positions=-1.)\n",
    "      start_positions.append(-1)\n",
    "      end_positions.append(-1)\n",
    "    else:\n",
    "      # The case that answer is found in the context\n",
    "\n",
    "      # Set start position\n",
    "      idx = context_start\n",
    "      while offset[idx][0] < start_char:\n",
    "        idx += 1\n",
    "      if offset[idx][0] == start_char:\n",
    "        start_positions.append(idx)\n",
    "      else:\n",
    "        start_positions.append(idx - 1)\n",
    "\n",
    "      # Set end position\n",
    "      idx = context_end\n",
    "      while offset[idx][1] > end_char + 1:\n",
    "        idx -= 1\n",
    "      if offset[idx][1] == end_char + 1:\n",
    "        end_positions.append(idx)\n",
    "      else:\n",
    "        end_positions.append(idx + 1)\n",
    "\n",
    "  # build result\n",
    "  tokenized_feature[\"start_positions\"] = start_positions\n",
    "  tokenized_feature[\"end_positions\"] = end_positions   \n",
    "  return tokenized_feature\n",
    "\n",
    "# Run conversion\n",
    "tokenized_ds = data.map(\n",
    "  tokenize_sample_data,\n",
    "  remove_columns=[\"id\", \"context\", \"question\", \"answers\"],\n",
    "  batched=True,\n",
    "  batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375450c997b34061a306607d5f6488fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/129 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6a911da5e14e35a67b36ee81617a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/56 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds = tokenized_ds.filter(lambda x: x[\"start_positions\"] != -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'answer_start', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 129\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'answer_start', 'input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
       "        num_rows: 56\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForQuestionAnswering\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model = (AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\").to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  output_dir = \"distilbert-nlb-qa\",\n",
    "  log_level = \"error\",\n",
    "  num_train_epochs = 200,\n",
    "  learning_rate = 7e-5,\n",
    "  lr_scheduler_type = \"linear\",\n",
    "  warmup_steps = 100,\n",
    "  per_device_train_batch_size = 16,\n",
    "  per_device_eval_batch_size = 16,\n",
    "  gradient_accumulation_steps = 16,\n",
    "  evaluation_strategy = \"steps\",\n",
    "  eval_steps = 150,\n",
    "  save_steps = 500,\n",
    "  logging_steps = 50,\n",
    "  push_to_hub = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rjutr\\miniconda3\\envs\\project_ds\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d023e8bd11694182964c93cb992d0e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6773, 'learning_rate': 3.5e-05, 'epoch': 33.78}\n",
      "{'loss': 0.0683, 'learning_rate': 7e-05, 'epoch': 67.0}\n",
      "{'loss': 0.0016, 'learning_rate': 3.5e-05, 'epoch': 100.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d3495621604952a6cfd51e36c79b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.0335118770599365, 'eval_runtime': 0.1735, 'eval_samples_per_second': 161.402, 'eval_steps_per_second': 11.529, 'epoch': 100.0}\n",
      "{'loss': 0.0005, 'learning_rate': 0.0, 'epoch': 133.33}\n",
      "{'train_runtime': 306.5086, 'train_samples_per_second': 84.174, 'train_steps_per_second': 0.653, 'train_loss': 0.4369335945695639, 'epoch': 133.33}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.4369335945695639, metrics={'train_runtime': 306.5086, 'train_samples_per_second': 84.174, 'train_steps_per_second': 0.653, 'train_loss': 0.4369335945695639, 'epoch': 133.33})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "  model = model,\n",
    "  args = training_args,\n",
    "  data_collator = data_collator,\n",
    "  train_dataset = tokenized_ds[\"train\"],\n",
    "  eval_dataset = tokenized_ds[\"test\"].select(range(data[\"test\"].shape[0] // 2)),\n",
    "  tokenizer = tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def inference_answer(question, context):\n",
    "  question = question\n",
    "  context = context\n",
    "  test_feature = tokenizer(\n",
    "    question,\n",
    "    context,\n",
    "    max_length=318,\n",
    "  )\n",
    "  with torch.no_grad():\n",
    "    outputs = model(torch.tensor([test_feature[\"input_ids\"]]).to(device))\n",
    "  start_logits = outputs.start_logits.cpu().numpy()\n",
    "  end_logits = outputs.end_logits.cpu().numpy()\n",
    "  answer_ids = test_feature[\"input_ids\"][np.argmax(start_logits):np.argmax(end_logits)+1]\n",
    "  return \"\".join(tokenizer.batch_decode(answer_ids))\n",
    "\n",
    "\n",
    "answer_pred = [inference_answer(data[\"test\"][\"question\"][idx], data[\"test\"][\"context\"][idx]) for idx in range(data[\"test\"].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_true = [data[\"test\"][\"answers\"][idx][\"text\"][0] for idx in range(data[\"test\"].shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "results = bertscore.compute(predictions=answer_pred, references=answer_true, lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.78750842916114, Precision: 0.7792423899684634, Recall: 0.7983093421374049\n"
     ]
    }
   ],
   "source": [
    "# mean all of the metrics\n",
    "print(f\"F1: {np.array(results['f1']).mean()}, Precision: {np.array(results['precision']).mean()}, Recall: {np.array(results['recall']).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = [{\"answers\": {\"answer_start\": [answer[\"answer_start\"][0]], \"text\": [answer[\"text\"][0]]}, \"id\": str(id)} for id, answer in zip(data[\"test\"][\"id\"], data[\"test\"][\"answers\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data[\"test\"][\"id\"], answer_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact': 30.357142857142858,\n",
       " 'f1': 31.944444444444446,\n",
       " 'total': 56,\n",
       " 'HasAns_exact': 30.357142857142858,\n",
       " 'HasAns_f1': 31.944444444444446,\n",
       " 'HasAns_total': 56,\n",
       " 'best_exact': 30.357142857142858,\n",
       " 'best_exact_thresh': 0.0,\n",
       " 'best_f1': 31.944444444444446,\n",
       " 'best_f1_thresh': 0.0}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_v2_metric = evaluate.load(\"squad_v2\")\n",
    "results = squad_v2_metric.compute(predictions=predictions, references=references)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
