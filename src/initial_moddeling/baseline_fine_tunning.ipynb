{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/clean/sustainability-report-2020-clean-BST_KK-fixed-with_starts.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly copy half of the rows to a new dataframe\n",
    "data_sample = data.sample(frac=0.5, random_state=1)\n",
    "data_sample = data_sample.reset_index(drop=True)\n",
    "# Set all values in the fLABEL column to NOTOK\n",
    "data_sample['fLABEL'] = 'NOT_OK'\n",
    "# Shuffle the context column\n",
    "data_sample['context'] = np.random.permutation(data_sample['context'])\n",
    "# Get starting positions\n",
    "for i in range(len(data_sample)):\n",
    "    text = data_sample[\"context\"][i]\n",
    "    answer = data_sample[\"answer\"][i]\n",
    "    answer_start = text.find(answer)\n",
    "    data_sample.loc[i, \"answer_start\"] = int(answer_start)\n",
    "\n",
    "# Set label to OK for all rows where the answer_start is not -1\n",
    "data_sample.loc[data_sample['answer_start'] != -1, 'fLABEL'] = 'OK'\n",
    "\n",
    "# Concatenate the original dataframe with the modified sample\n",
    "data = pd.concat([data, data_sample], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column containing dictionaries\n",
    "data['answers'] = data.apply(lambda x: {'text': [x['answer']] * 3, 'answer_start': [x['answer_start']] * 3}, axis=1)\n",
    "data[\"id\"] = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)\n",
    "data = data.drop(columns=['answer_start', 'answer', 'fLABEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data.sample(frac=0.8, random_state=1)\n",
    "test_df = data.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df, split=\"train\", preserve_index=False)\n",
    "test_ds = Dataset.from_pandas(test_df, split=\"test\", preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 384\n",
    "stride = 128\n",
    "\n",
    "\n",
    "def preprocess_training_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_idx = sample_map[i]\n",
    "        answer = answers[sample_idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label is (0, 0)\n",
    "        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f4079e837c4849ab06e7f611d097cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/222 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(222, 222)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = train_ds.map(\n",
    "    preprocess_training_examples,\n",
    "    batched=True,\n",
    "    remove_columns=train_ds.column_names,\n",
    ")\n",
    "len(train_ds), len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_validation_examples(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=max_length,\n",
    "        truncation=\"only_second\",\n",
    "        stride=stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    \n",
    "    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n",
    "    example_ids = []\n",
    "\n",
    "    for i in range(len(inputs[\"input_ids\"])):\n",
    "        sample_idx = sample_map[i]\n",
    "        example_ids.append(examples[\"id\"][sample_idx])\n",
    "\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "        offset = inputs[\"offset_mapping\"][i]\n",
    "        inputs[\"offset_mapping\"][i] = [\n",
    "            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n",
    "        ]\n",
    "    \n",
    "    inputs[\"example_id\"] = example_ids\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3d5afe9df3479cb63ddb6ad980ce3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/55 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(55, 55)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_dataset = test_ds.map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=test_ds.column_names,\n",
    ")\n",
    "len(test_ds), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-cased-distilled-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_qa_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rjutr\\miniconda3\\envs\\project_ds\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0306909e184e949797d5cad2e7c7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/42 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60779848b4349ac96ee2ddea37cfff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 0.2979, 'eval_samples_per_second': 184.631, 'eval_steps_per_second': 13.428, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "213f01cd7abf451fa7c2c2938d36d916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 0.298, 'eval_samples_per_second': 184.58, 'eval_steps_per_second': 13.424, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720c9b25b4da48f3be61147f0e33f94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_runtime': 0.3053, 'eval_samples_per_second': 180.164, 'eval_steps_per_second': 13.103, 'epoch': 3.0}\n",
      "{'train_runtime': 13.036, 'train_samples_per_second': 51.089, 'train_steps_per_second': 3.222, 'train_loss': 0.5904768989199684, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=42, training_loss=0.5904768989199684, metrics={'train_runtime': 13.036, 'train_samples_per_second': 51.089, 'train_steps_per_second': 3.222, 'train_loss': 0.5904768989199684, 'epoch': 3.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset squad (C:/Users/rjutr/.cache/huggingface/datasets/squad/plain_text/1.0.0/d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92c22e77939d49039421eb0e00cd8332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94c5c96c18c455d9e9b7b6d74433290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "small_eval_set = test_ds.select(range(50))\n",
    "trained_checkpoint = \"distilbert-base-cased-distilled-squad\"\n",
    "\n",
    "# Add length to the answers in the dataset\n",
    "for i, example in enumerate(small_eval_set):\n",
    "    small_eval_set[i][\"answers\"][\"len\"] = len(example[\"answers\"][\"text\"][0])\n",
    "    \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n",
    "eval_set = small_eval_set.map(\n",
    "    preprocess_validation_examples,\n",
    "    batched=True,\n",
    "    remove_columns=test_ds.column_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForQuestionAnswering\n",
    "\n",
    "eval_set_for_model = eval_set.remove_columns([\"example_id\", \"offset_mapping\"])\n",
    "eval_set_for_model.set_format(\"torch\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "batch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}\n",
    "trained_model = AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(\n",
    "    device\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = trained_model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = outputs.start_logits.cpu().numpy()\n",
    "end_logits = outputs.end_logits.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "example_to_features = collections.defaultdict(list)\n",
    "for idx, feature in enumerate(eval_set):\n",
    "    example_to_features[feature[\"example_id\"]].append(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_best = 20\n",
    "max_answer_length = 30\n",
    "predicted_answers = []\n",
    "\n",
    "for example in small_eval_set:\n",
    "    example_id = example[\"id\"]\n",
    "    context = example[\"context\"]\n",
    "    answers = []\n",
    "\n",
    "    for feature_index in example_to_features[example_id]:\n",
    "        start_logit = start_logits[feature_index]\n",
    "        end_logit = end_logits[feature_index]\n",
    "        offsets = eval_set[\"offset_mapping\"][feature_index]\n",
    "\n",
    "        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "        for start_index in start_indexes:\n",
    "            for end_index in end_indexes:\n",
    "                # Skip answers that are not fully in the context\n",
    "                if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                    continue\n",
    "                # Skip answers with a length that is either < 0 or > max_answer_length.\n",
    "                if (\n",
    "                    end_index < start_index\n",
    "                    or end_index - start_index + 1 > max_answer_length\n",
    "                ):\n",
    "                    continue\n",
    "\n",
    "                answers.append(\n",
    "                    {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "    predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical_answers = [\n",
    "    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in small_eval_set\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'answers': {'answer_start': [69, 69, 69], 'text': ['49%', '49%', '49%']}},\n",
       " {'id': 3,\n",
       "  'answers': {'answer_start': [16, 16, 16], 'text': ['31%', '31%', '31%']}},\n",
       " {'id': 7, 'answers': {'answer_start': [69, 69, 69], 'text': ['1', '1', '1']}},\n",
       " {'id': 8,\n",
       "  'answers': {'answer_start': [68, 68, 68], 'text': ['58%', '58%', '58%']}},\n",
       " {'id': 22,\n",
       "  'answers': {'answer_start': [69, 69, 69],\n",
       "   'text': ['knowledge and lifelong learning',\n",
       "    'knowledge and lifelong learning',\n",
       "    'knowledge and lifelong learning']}},\n",
       " {'id': 24,\n",
       "  'answers': {'answer_start': [69, 69, 69],\n",
       "   'text': ['a higher quality of life of the wider society',\n",
       "    'a higher quality of life of the wider society',\n",
       "    'a higher quality of life of the wider society']}},\n",
       " {'id': 26,\n",
       "  'answers': {'answer_start': [69, 69, 69],\n",
       "   'text': ['local banking and environmental legislation',\n",
       "    'local banking and environmental legislation',\n",
       "    'local banking and environmental legislation']}},\n",
       " {'id': 30,\n",
       "  'answers': {'answer_start': [69, 69, 69],\n",
       "   'text': ['Environmental and Social Management System',\n",
       "    'Environmental and Social Management System',\n",
       "    'Environmental and Social Management System']}},\n",
       " {'id': 37,\n",
       "  'answers': {'answer_start': [69, 69, 69],\n",
       "   'text': ['three', 'three', 'three']}},\n",
       " {'id': 41,\n",
       "  'answers': {'answer_start': [68, 68, 68], 'text': ['ESG', 'ESG', 'ESG']}},\n",
       " {'id': 43,\n",
       "  'answers': {'answer_start': [67, 67, 67],\n",
       "   'text': ['The NLB Group', 'The NLB Group', 'The NLB Group']}},\n",
       " {'id': 49,\n",
       "  'answers': {'answer_start': [68, 68, 68], 'text': ['459', '459', '459']}},\n",
       " {'id': 50,\n",
       "  'answers': {'answer_start': [70, 70, 70],\n",
       "   'text': ['2.11million', '2.11million', '2.11million']}},\n",
       " {'id': 52,\n",
       "  'answers': {'answer_start': [69, 69, 69], 'text': ['2020', '2020', '2020']}},\n",
       " {'id': 57,\n",
       "  'answers': {'answer_start': [68, 68, 68],\n",
       "   'text': ['Risk management', 'Risk management', 'Risk management']}},\n",
       " {'id': 60,\n",
       "  'answers': {'answer_start': [69, 69, 69],\n",
       "   'text': ['todetect and manage new potential emerging risks',\n",
       "    'todetect and manage new potential emerging risks',\n",
       "    'todetect and manage new potential emerging risks']}},\n",
       " {'id': 61,\n",
       "  'answers': {'answer_start': [66, 66, 66],\n",
       "   'text': ['HelpFrame', 'HelpFrame', 'HelpFrame']}},\n",
       " {'id': 63,\n",
       "  'answers': {'answer_start': [66, 66, 66],\n",
       "   'text': ['HelpFrame', 'HelpFrame', 'HelpFrame']}},\n",
       " {'id': 68,\n",
       "  'answers': {'answer_start': [69, 69, 69], 'text': ['10%', '10%', '10%']}},\n",
       " {'id': 71,\n",
       "  'answers': {'answer_start': [69, 69, 69],\n",
       "   'text': ['9.87%', '9.87%', '9.87%']}},\n",
       " {'id': 72,\n",
       "  'answers': {'answer_start': [69, 69, 69],\n",
       "   'text': ['Sarajevo and Belgrade',\n",
       "    'Sarajevo and Belgrade',\n",
       "    'Sarajevo and Belgrade']}},\n",
       " {'id': 76,\n",
       "  'answers': {'answer_start': [68, 68, 68],\n",
       "   'text': ['a reduction in the archives on paper',\n",
       "    'a reduction in the archives on paper',\n",
       "    'a reduction in the archives on paper']}},\n",
       " {'id': 80,\n",
       "  'answers': {'answer_start': [67, 67, 67],\n",
       "   'text': ['3,709 kg', '3,709 kg', '3,709 kg']}},\n",
       " {'id': 86,\n",
       "  'answers': {'answer_start': [69, 69, 69],\n",
       "   'text': ['69% women and 31% men',\n",
       "    '69% women and 31% men',\n",
       "    '69% women and 31% men']}},\n",
       " {'id': 109,\n",
       "  'answers': {'answer_start': [36, 36, 36],\n",
       "   'text': ['human rights, employees rights',\n",
       "    'human rights, employees rights',\n",
       "    'human rights, employees rights']}},\n",
       " {'id': 115,\n",
       "  'answers': {'answer_start': [69, 69, 69],\n",
       "   'text': ['equal opportunities, justice',\n",
       "    'equal opportunities, justice',\n",
       "    'equal opportunities, justice']}},\n",
       " {'id': 121,\n",
       "  'answers': {'answer_start': [69, 69, 69],\n",
       "   'text': ['in accordance with theinstructions',\n",
       "    'in accordance with theinstructions',\n",
       "    'in accordance with theinstructions']}},\n",
       " {'id': 128,\n",
       "  'answers': {'answer_start': [69, 69, 69],\n",
       "   'text': ['Enterprise Compliance and integrity Risk Assessment',\n",
       "    'Enterprise Compliance and integrity Risk Assessment',\n",
       "    'Enterprise Compliance and integrity Risk Assessment']}},\n",
       " {'id': 129,\n",
       "  'answers': {'answer_start': [53, 53, 53],\n",
       "   'text': ['the NLB Group carriesout several activities to manage these risks',\n",
       "    'the NLB Group carriesout several activities to manage these risks',\n",
       "    'the NLB Group carriesout several activities to manage these risks']}},\n",
       " {'id': 131,\n",
       "  'answers': {'answer_start': [68, 68, 68], 'text': ['2017', '2017', '2017']}},\n",
       " {'id': 133,\n",
       "  'answers': {'answer_start': [68, 68, 68],\n",
       "   'text': ['by e-mail, via the website,and social networks',\n",
       "    'by e-mail, via the website,and social networks',\n",
       "    'by e-mail, via the website,and social networks']}},\n",
       " {'id': 141,\n",
       "  'answers': {'answer_start': [69, 69, 69],\n",
       "   'text': ['Working in smaller groups at different locations',\n",
       "    'Working in smaller groups at different locations',\n",
       "    'Working in smaller groups at different locations']}},\n",
       " {'id': 144,\n",
       "  'answers': {'answer_start': [69, 69, 69], 'text': ['11', '11', '11']}},\n",
       " {'id': 149,\n",
       "  'answers': {'answer_start': [64, 64, 64],\n",
       "   'text': ['General Managers directlysubordinated to Management Board',\n",
       "    'General Managers directlysubordinated to Management Board',\n",
       "    'General Managers directlysubordinated to Management Board']}},\n",
       " {'id': 156,\n",
       "  'answers': {'answer_start': [65, 65, 65], 'text': ['45', '45', '45']}},\n",
       " {'id': 175,\n",
       "  'answers': {'answer_start': [68, 68, 68],\n",
       "   'text': ['anyform of discrimination and violence',\n",
       "    'anyform of discrimination and violence',\n",
       "    'anyform of discrimination and violence']}},\n",
       " {'id': 178,\n",
       "  'answers': {'answer_start': [34, 34, 34],\n",
       "   'text': ['1.4 million', '1.4 million', '1.4 million']}},\n",
       " {'id': 196,\n",
       "  'answers': {'answer_start': [-1, -1, -1],\n",
       "   'text': ['SHIMMPO', 'SHIMMPO', 'SHIMMPO']}},\n",
       " {'id': 198,\n",
       "  'answers': {'answer_start': [-1, -1, -1],\n",
       "   'text': ['General Managers directlysubordinated to Management Board',\n",
       "    'General Managers directlysubordinated to Management Board',\n",
       "    'General Managers directlysubordinated to Management Board']}},\n",
       " {'id': 200,\n",
       "  'answers': {'answer_start': [106, 106, 106],\n",
       "   'text': ['2020', '2020', '2020']}},\n",
       " {'id': 203,\n",
       "  'answers': {'answer_start': [-1, -1, -1],\n",
       "   'text': ['reports received through channels for anonymous reportingof suspected harmful practices',\n",
       "    'reports received through channels for anonymous reportingof suspected harmful practices',\n",
       "    'reports received through channels for anonymous reportingof suspected harmful practices']}},\n",
       " {'id': 209,\n",
       "  'answers': {'answer_start': [-1, -1, -1],\n",
       "   'text': ['trust, support, and constant feed-back',\n",
       "    'trust, support, and constant feed-back',\n",
       "    'trust, support, and constant feed-back']}},\n",
       " {'id': 215,\n",
       "  'answers': {'answer_start': [-1, -1, -1], 'text': ['94', '94', '94']}},\n",
       " {'id': 216,\n",
       "  'answers': {'answer_start': [-1, -1, -1],\n",
       "   'text': ['57.7%', '57.7%', '57.7%']}},\n",
       " {'id': 234,\n",
       "  'answers': {'answer_start': [-1, -1, -1],\n",
       "   'text': ['corruption and bribery',\n",
       "    'corruption and bribery',\n",
       "    'corruption and bribery']}},\n",
       " {'id': 235,\n",
       "  'answers': {'answer_start': [-1, -1, -1],\n",
       "   'text': ['36.89', '36.89', '36.89']}},\n",
       " {'id': 237,\n",
       "  'answers': {'answer_start': [-1, -1, -1],\n",
       "   'text': ['the privacy of customers andemployees',\n",
       "    'the privacy of customers andemployees',\n",
       "    'the privacy of customers andemployees']}},\n",
       " {'id': 241,\n",
       "  'answers': {'answer_start': [3, 3, 3], 'text': ['2020', '2020', '2020']}},\n",
       " {'id': 244,\n",
       "  'answers': {'answer_start': [-1, -1, -1],\n",
       "   'text': ['More than 200', 'More than 200', 'More than 200']}},\n",
       " {'id': 252,\n",
       "  'answers': {'answer_start': [-1, -1, -1],\n",
       "   'text': ['The NLB Group Code of Conduct',\n",
       "    'The NLB Group Code of Conduct',\n",
       "    'The NLB Group Code of Conduct']}}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theoretical_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def compute_metrics(start_logits, end_logits, features, examples):\n",
    "    example_to_features = collections.defaultdict(list)\n",
    "    for idx, feature in enumerate(features):\n",
    "        example_to_features[feature[\"example_id\"]].append(idx)\n",
    "\n",
    "    predicted_answers = []\n",
    "    for example in tqdm(examples):\n",
    "        example_id = example[\"id\"]\n",
    "        context = example[\"context\"]\n",
    "        answers = []\n",
    "\n",
    "        # Loop through all features associated with that example\n",
    "        for feature_index in example_to_features[example_id]:\n",
    "            start_logit = start_logits[feature_index]\n",
    "            end_logit = end_logits[feature_index]\n",
    "            offsets = features[feature_index][\"offset_mapping\"]\n",
    "\n",
    "            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n",
    "            for start_index in start_indexes:\n",
    "                for end_index in end_indexes:\n",
    "                    # Skip answers that are not fully in the context\n",
    "                    if offsets[start_index] is None or offsets[end_index] is None:\n",
    "                        continue\n",
    "                    # Skip answers with a length that is either < 0 or > max_answer_length\n",
    "                    if (\n",
    "                        end_index < start_index\n",
    "                        or end_index - start_index + 1 > max_answer_length\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    answer = {\n",
    "                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n",
    "                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n",
    "                    }\n",
    "                    answers.append(answer)\n",
    "\n",
    "        # Select the answer with the best score\n",
    "        if len(answers) > 0:\n",
    "            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n",
    "            predicted_answers.append(\n",
    "                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n",
    "            )\n",
    "        else:\n",
    "            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n",
    "\n",
    "    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n",
    "    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
