{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, AutoTokenizer, AutoModelForQuestionAnswering, set_seed\n",
    "from datasets import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "local_models_path = '../../data/models/BERT'\n",
    "\n",
    "results = pd.DataFrame(columns=['Model', 'Train Data', 'Data Type', 'Bert.Precision', 'Bert.Recall', 'Bert.F1', 'BLEU', 'Squad.Exact', 'Squad.F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prediction function\n",
    "def inference_answer(question, context, tokenizer, model):\n",
    "    question = question\n",
    "    context = context\n",
    "    test_feature = tokenizer(\n",
    "        question,\n",
    "        context,\n",
    "        max_length=318\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        outputs = model(torch.tensor([test_feature[\"input_ids\"]]))\n",
    "    start_logits = outputs.start_logits.cpu().numpy()\n",
    "    end_logits = outputs.end_logits.cpu().numpy()\n",
    "    answer_ids = test_feature[\"input_ids\"][np.argmax(\n",
    "        start_logits):np.argmax(end_logits)+1]\n",
    "    return \" \".join(tokenizer.batch_decode(answer_ids))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Luka/.cache/huggingface/datasets/csv/default-d8382661cd597e83/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached split indices for dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-d8382661cd597e83\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-c261d5613d28d856.arrow and C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-d8382661cd597e83\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-e61829c1e4a24b65.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-d8382661cd597e83\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-0b15501cefb41ff7.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-d8382661cd597e83\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-e4de42d02343959f.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-d8382661cd597e83\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-a5add48769f938cd.arrow\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from file and split it into train and test datasets\n",
    "data_2020_full = load_dataset('csv', data_files=f\"../../data/clean/sustainability-report-2020-squad-format.csv\",\n",
    "                    delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "\n",
    "# Reformat the train and test set such as they adhere to the SQuAD format (reading from cvs loads strings not objects as expected)\n",
    "data_2020_full[\"test\"] = data_2020_full[\"test\"].map(\n",
    "    lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data_2020_full[\"test\"] = data_2020_full[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\n",
    "                                \"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "# replace all \"\\n\" with \" \" in the context, answers and questions\n",
    "data_2020_full[\"test\"] = data_2020_full[\"test\"].map(lambda example: {\"question\": example[\"question\"].replace(\"\\n\", \" \"), \"context\": example[\"context\"].replace(\"\\n\", \" \"), \"answers\": {\n",
    "                                \"text\": [example[\"answers\"][\"text\"][0].replace(\"\\n\", \" \")], \"answer_start\": example[\"answers\"][\"answer_start\"]}})\n",
    "data_2020_full[\"test\"] = data_2020_full[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "# get ground truth answers\n",
    "test_data_2020_full = data_2020_full[\"test\"]\n",
    "gt_answers_2020_full = [temp[\"answers\"][\"text\"][0] for temp in test_data_2020_full]\n",
    "\n",
    "# squad formatted data\n",
    "references_2020 = [{\"answers\": {\"answer_start\": [answer[\"answer_start\"][0]], \"text\": [answer[\"text\"][0]]}, \"id\": str(id)} for id, answer in zip(data_2020_full[\"test\"][\"id\"], data_2020_full[\"test\"][\"answers\"])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Luka/.cache/huggingface/datasets/csv/default-003bb09dc8228b5f/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached split indices for dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-003bb09dc8228b5f\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-515ab9eb5e89ae1b.arrow and C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-003bb09dc8228b5f\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-bf44f2d0ce4c658e.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-003bb09dc8228b5f\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-0158f993dabee325.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-003bb09dc8228b5f\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-bee36876181b6213.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-003bb09dc8228b5f\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-74602f82da6cdf7e.arrow\n"
     ]
    }
   ],
   "source": [
    "data_2022_full = load_dataset('csv', data_files=f\"../../data/clean/sustainability-report-2022-squad-format.csv\",\n",
    "                    delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "\n",
    "# Reformat the train and test set such as they adhere to the SQuAD format (reading from cvs loads strings not objects as expected)\n",
    "data_2022_full[\"test\"] = data_2022_full[\"test\"].map(\n",
    "    lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data_2022_full[\"test\"] = data_2022_full[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\n",
    "                                \"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "# replace all \"\\n\" with \" \" in the context, answers and questions\n",
    "data_2022_full[\"test\"] = data_2022_full[\"test\"].map(lambda example: {\"question\": example[\"question\"].replace(\"\\n\", \" \"), \"context\": example[\"context\"].replace(\"\\n\", \" \"), \"answers\": {\n",
    "                                \"text\": [example[\"answers\"][\"text\"][0].replace(\"\\n\", \" \")], \"answer_start\": example[\"answers\"][\"answer_start\"]}})\n",
    "data_2022_full[\"test\"] = data_2022_full[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "\n",
    "test_data_2022_full = data_2022_full[\"test\"]\n",
    "gt_answers_2022_full = [temp[\"answers\"][\"text\"][0] for temp in test_data_2022_full]\n",
    "\n",
    "# squad formatted data\n",
    "references_2022 = [{\"answers\": {\"answer_start\": [answer[\"answer_start\"][0]], \"text\": [answer[\"text\"][0]]}, \"id\": str(id)} for id, answer in zip(data_2022_full[\"test\"][\"id\"], data_2022_full[\"test\"][\"answers\"])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2020 + 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Luka/.cache/huggingface/datasets/csv/default-a6bdc04297c1a3c2/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached split indices for dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-a6bdc04297c1a3c2\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-4c58d6607e064ca8.arrow and C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-a6bdc04297c1a3c2\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-6ec98b5ad96d608a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-a6bdc04297c1a3c2\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-b60d97fbf617fa23.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-a6bdc04297c1a3c2\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-da9287d5acd53d81.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-a6bdc04297c1a3c2\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-0fead63929b725db.arrow\n"
     ]
    }
   ],
   "source": [
    "data_2020_2022 = load_dataset('csv', data_files=\"../../data/clean/sustainability-report-2042-squad-format.csv\",\n",
    "                                delimiter=\";\", split=\"train\").train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "\n",
    "# Reformat the train and test set such as they adhere to the SQuAD format (reading from cvs loads strings not objects as expected)\n",
    "data_2020_2022[\"test\"] = data_2020_2022[\"test\"].map(\n",
    "    lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data_2020_2022[\"test\"] = data_2020_2022[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\n",
    "                                \"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "# replace all \"\\n\" with \" \" in the context, answers and questions\n",
    "data_2020_2022[\"test\"] = data_2020_2022[\"test\"].map(lambda example: {\"question\": example[\"question\"].replace(\"\\n\", \" \"), \"context\": example[\"context\"].replace(\"\\n\", \" \"), \"answers\": {\n",
    "                                \"text\": [example[\"answers\"][\"text\"][0].replace(\"\\n\", \" \")], \"answer_start\": example[\"answers\"][\"answer_start\"]}})\n",
    "data_2020_2022[\"test\"] = data_2020_2022[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "# get ground truth answers\n",
    "test_data_2020_2022 = data_2020_2022[\"test\"]\n",
    "gt_answers_2020_2022 = [temp[\"answers\"][\"text\"][0] for temp in test_data_2020_2022]\n",
    "\n",
    "# squad formatted data\n",
    "references_2020_2022 = [{\"answers\": {\"answer_start\": [answer[\"answer_start\"][0]], \"text\": [answer[\"text\"][0]]}, \"id\": str(id)} for id, answer in zip(data_2020_2022[\"test\"][\"id\"], data_2020_2022[\"test\"][\"answers\"])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2022 handwritten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Luka/.cache/huggingface/datasets/csv/default-853b320bab41342e/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached split indices for dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-853b320bab41342e\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-690d708f98f9a3b4.arrow and C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-853b320bab41342e\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-b3c2cbaa1563558c.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-853b320bab41342e\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-227bc1b6d7ce66b1.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-853b320bab41342e\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-ea73fd3146b3fd5a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-853b320bab41342e\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-51580e58cadacd1e.arrow\n"
     ]
    }
   ],
   "source": [
    "data_2022_handwritten = load_dataset('csv', data_files=f\"../../data/clean/QA_SR_2022_Expert-squad-format.csv\",\n",
    "                                        delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "\n",
    "# Reformat the train and test set such as they adhere to the SQuAD format (reading from cvs loads strings not objects as expected)\n",
    "data_2022_handwritten[\"test\"] = data_2022_handwritten[\"test\"].map(\n",
    "    lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data_2022_handwritten[\"test\"] = data_2022_handwritten[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\n",
    "                                \"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "# replace all \"\\n\" with \" \" in the context, answers and questions\n",
    "data_2022_handwritten[\"test\"] = data_2022_handwritten[\"test\"].map(lambda example: {\"question\": example[\"question\"].replace(\"\\n\", \" \"), \"context\": example[\"context\"].replace(\"\\n\", \" \"), \"answers\": {\n",
    "                                \"text\": [example[\"answers\"][\"text\"][0].replace(\"\\n\", \" \")], \"answer_start\": example[\"answers\"][\"answer_start\"]}})\n",
    "data_2022_handwritten[\"test\"] = data_2022_handwritten[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "\n",
    "test_data_2022_handwritten = data_2022_handwritten[\"test\"]\n",
    "gt_answers_2022_handwritten = [temp[\"answers\"][\"text\"][0] for temp in test_data_2022_handwritten]\n",
    "\n",
    "# squad formatted data\n",
    "references_2022_handwritten = [{\"answers\": {\"answer_start\": [answer[\"answer_start\"][0]], \"text\": [answer[\"text\"][0]]}, \"id\": str(id)} for id, answer in enumerate(data_2022_handwritten[\"test\"][\"answers\"])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SIMPLE EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "squad_v2_metric = evaluate.load(\"squad_v2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-cased-distilled-squad\"\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "answers_2020 = [inference_answer(data_2020_full[\"test\"][\"question\"][idx], data_2020_full[\"test\"][\"context\"][idx], tokenizer, model) for idx in range(data_2020_full[\"test\"].shape[0])]\n",
    "answers_2020_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2020_full[\"test\"][\"id\"], answers_2020)]\n",
    "answers_2022 = [inference_answer(data_2022_full[\"test\"][\"question\"][idx], data_2022_full[\"test\"][\"context\"][idx], tokenizer, model) for idx in range(data_2022_full[\"test\"].shape[0])]\n",
    "answers_2022_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2022_full[\"test\"][\"id\"], answers_2022)]\n",
    "answers_2020_2022 = [inference_answer(data_2020_2022[\"test\"][\"question\"][idx], data_2020_2022[\"test\"][\"context\"][idx], tokenizer, model) for idx in range(data_2020_2022[\"test\"].shape[0])]\n",
    "answers_2020_2022_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2020_2022[\"test\"][\"id\"], answers_2020_2022)]\n",
    "answers_2022_handwritten = [inference_answer(data_2022_handwritten[\"test\"][\"question\"][idx], data_2022_handwritten[\"test\"][\"context\"][idx], tokenizer, model) for idx in range(data_2022_handwritten[\"test\"].shape[0])]\n",
    "answers_2022_handwritten_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in enumerate(answers_2022_handwritten)]\n",
    "\n",
    "# bertscore\n",
    "bert_results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "bert_results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "bert_results_2020_2022 = bertscore.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022, lang=\"en\")\n",
    "bert_results_2022_handwritten = bertscore.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten, lang=\"en\")\n",
    "# print(f\"Bertscore results 2020\\nF1: {np.array(bert_results_2020['f1']).mean()}, Precision: {np.array(bert_results_2020['precision']).mean()}, Recall: {np.array(bert_results_2020['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022\\nF1: {np.array(bert_results_2022['f1']).mean()}, Precision: {np.array(bert_results_2022['precision']).mean()}, Recall: {np.array(bert_results_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2020-2022\\nF1: {np.array(bert_results_2020_2022['f1']).mean()}, Precision: {np.array(bert_results_2020_2022['precision']).mean()}, Recall: {np.array(bert_results_2020_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022 handwritten\\nF1: {np.array(bert_results_2022_handwritten['f1']).mean()}, Precision: {np.array(bert_results_2022_handwritten['precision']).mean()}, Recall: {np.array(bert_results_2022_handwritten['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "bleu_results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "bleu_results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "bleu_results_2020_2022 = bleu.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022)\n",
    "bleu_results_2022_handwritten = bleu.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten)\n",
    "# print(f\"Bleu results 2020\\n{bleu_results_2020}\")\n",
    "# print(f\"Bleu results 2022\\n{bleu_results_2022}\")\n",
    "# print(f\"Bleu results 2020-2022\\n{bleu_results_2020_2022}\")\n",
    "# print(f\"Bleu results 2022 handwritten\\n{bleu_results_2022_handwritten}\")\n",
    "\n",
    "# squad_v2\n",
    "squad_results_2020 = squad_v2_metric.compute(predictions=answers_2020_squad, references=references_2020)\n",
    "squad_results_2022 = squad_v2_metric.compute(predictions=answers_2022_squad, references=references_2022)\n",
    "squad_results_2020_2022 = squad_v2_metric.compute(predictions=answers_2020_2022_squad, references=references_2020_2022)\n",
    "squad_results_2022_handwritten = squad_v2_metric.compute(predictions=answers_2022_handwritten_squad, references=references_2022_handwritten)\n",
    "# print(f\"Squad_v2 results 2020\\n{squad_results_2020}\")\n",
    "# print(f\"Squad_v2 results 2022\\n{squad_results_2022}\")\n",
    "# print(f\"Squad_v2 results 2020-2022\\n{squad_results_2020_2022}\")\n",
    "# print(f\"Squad_v2 results 2022 handwritten\\n{squad_results_2022_handwritten}\")\n",
    "\n",
    "\n",
    "# add results to dataframe\n",
    "results.loc[len(results)] = ['distilbert', None, '2020', np.array(bert_results_2020['precision']).mean(), np.array(bert_results_2020['recall']).mean(), np.array(bert_results_2020['f1']).mean(), bleu_results_2020['bleu'], squad_results_2020['exact'], squad_results_2020['f1']]\n",
    "results.loc[len(results)] = ['distilbert', None, '2022', np.array(bert_results_2022['precision']).mean(), np.array(bert_results_2022['recall']).mean(), np.array(bert_results_2022['f1']).mean(), bleu_results_2022['bleu'], squad_results_2022['exact'], squad_results_2022['f1']]\n",
    "results.loc[len(results)] = ['distilbert', None, '2020-2022', np.array(bert_results_2020_2022['precision']).mean(), np.array(bert_results_2020_2022['recall']).mean(), np.array(bert_results_2020_2022['f1']).mean(), bleu_results_2020_2022['bleu'], squad_results_2020_2022['exact'], squad_results_2020_2022['f1']]\n",
    "results.loc[len(results)] = ['distilbert', None, '2022 handwritten', np.array(bert_results_2022_handwritten['precision']).mean(), np.array(bert_results_2022_handwritten['recall']).mean(), np.array(bert_results_2022_handwritten['f1']).mean(), bleu_results_2022_handwritten['bleu'], squad_results_2022_handwritten['exact'], squad_results_2022_handwritten['f1']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"deepset/roberta-base-squad2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "answers_2020 = [inference_answer(data_2020_full[\"test\"][\"question\"][idx], data_2020_full[\"test\"][\"context\"][idx], tokenizer, model) for idx in range(data_2020_full[\"test\"].shape[0])]\n",
    "answers_2020_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2020_full[\"test\"][\"id\"], answers_2020)]\n",
    "answers_2022 = [inference_answer(data_2022_full[\"test\"][\"question\"][idx], data_2022_full[\"test\"][\"context\"][idx], tokenizer, model) for idx in range(data_2022_full[\"test\"].shape[0])]\n",
    "answers_2022_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2022_full[\"test\"][\"id\"], answers_2022)]\n",
    "answers_2020_2022 = [inference_answer(data_2020_2022[\"test\"][\"question\"][idx], data_2020_2022[\"test\"][\"context\"][idx], tokenizer, model) for idx in range(data_2020_2022[\"test\"].shape[0])]\n",
    "answers_2020_2022_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2020_2022[\"test\"][\"id\"], answers_2020_2022)]\n",
    "answers_2022_handwritten = [inference_answer(data_2022_handwritten[\"test\"][\"question\"][idx], data_2022_handwritten[\"test\"][\"context\"][idx], tokenizer, model) for idx in range(data_2022_handwritten[\"test\"].shape[0])]\n",
    "answers_2022_handwritten_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in enumerate(answers_2022_handwritten)]\n",
    "\n",
    "# bertscore\n",
    "bert_results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "bert_results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "bert_results_2020_2022 = bertscore.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022, lang=\"en\")\n",
    "bert_results_2022_handwritten = bertscore.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten, lang=\"en\")\n",
    "# print(f\"Bertscore results 2020\\nF1: {np.array(bert_results_2020['f1']).mean()}, Precision: {np.array(bert_results_2020['precision']).mean()}, Recall: {np.array(bert_results_2020['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022\\nF1: {np.array(bert_results_2022['f1']).mean()}, Precision: {np.array(bert_results_2022['precision']).mean()}, Recall: {np.array(bert_results_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2020-2022\\nF1: {np.array(bert_results_2020_2022['f1']).mean()}, Precision: {np.array(bert_results_2020_2022['precision']).mean()}, Recall: {np.array(bert_results_2020_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022 handwritten\\nF1: {np.array(bert_results_2022_handwritten['f1']).mean()}, Precision: {np.array(bert_results_2022_handwritten['precision']).mean()}, Recall: {np.array(bert_results_2022_handwritten['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "bleu_results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "bleu_results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "bleu_results_2020_2022 = bleu.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022)\n",
    "bleu_results_2022_handwritten = bleu.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten)\n",
    "# print(f\"Bleu results 2020\\n{bleu_results_2020}\")\n",
    "# print(f\"Bleu results 2022\\n{bleu_results_2022}\")\n",
    "# print(f\"Bleu results 2020-2022\\n{bleu_results_2020_2022}\")\n",
    "# print(f\"Bleu results 2022 handwritten\\n{bleu_results_2022_handwritten}\")\n",
    "\n",
    "# squad_v2\n",
    "squad_results_2020 = squad_v2_metric.compute(predictions=answers_2020_squad, references=references_2020)\n",
    "squad_results_2022 = squad_v2_metric.compute(predictions=answers_2022_squad, references=references_2022)\n",
    "squad_results_2020_2022 = squad_v2_metric.compute(predictions=answers_2020_2022_squad, references=references_2020_2022)\n",
    "squad_results_2022_handwritten = squad_v2_metric.compute(predictions=answers_2022_handwritten_squad, references=references_2022_handwritten)\n",
    "# print(f\"Squad_v2 results 2020\\n{squad_results_2020}\")\n",
    "# print(f\"Squad_v2 results 2022\\n{squad_results_2022}\")\n",
    "# print(f\"Squad_v2 results 2020-2022\\n{squad_results_2020_2022}\")\n",
    "# print(f\"Squad_v2 results 2022 handwritten\\n{squad_results_2022_handwritten}\")\n",
    "\n",
    "\n",
    "# add results to dataframe\n",
    "results.loc[len(results)] = ['roberta', None, '2020', np.array(bert_results_2020['precision']).mean(), np.array(bert_results_2020['recall']).mean(), np.array(bert_results_2020['f1']).mean(), bleu_results_2020['bleu'], squad_results_2020['exact'], squad_results_2020['f1']]\n",
    "results.loc[len(results)] = ['roberta', None, '2022', np.array(bert_results_2022['precision']).mean(), np.array(bert_results_2022['recall']).mean(), np.array(bert_results_2022['f1']).mean(), bleu_results_2022['bleu'], squad_results_2022['exact'], squad_results_2022['f1']]\n",
    "results.loc[len(results)] = ['roberta', None, '2020-2022', np.array(bert_results_2020_2022['precision']).mean(), np.array(bert_results_2020_2022['recall']).mean(), np.array(bert_results_2020_2022['f1']).mean(), bleu_results_2020_2022['bleu'], squad_results_2020_2022['exact'], squad_results_2020_2022['f1']]\n",
    "results.loc[len(results)] = ['roberta', None, '2022 handwritten', np.array(bert_results_2022_handwritten['precision']).mean(), np.array(bert_results_2022_handwritten['recall']).mean(), np.array(bert_results_2022_handwritten['f1']).mean(), bleu_results_2022_handwritten['bleu'], squad_results_2022_handwritten['exact'], squad_results_2022_handwritten['f1']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distilbert - finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "model_name_2020 = f\"{local_models_path}/distilbert-base-cased-distilled-squad-finetuned-NLB-QA-2020-full\"\n",
    "tokenizer_2020 = DistilBertTokenizerFast.from_pretrained(model_name_2020)\n",
    "model_2020 = AutoModelForQuestionAnswering.from_pretrained(model_name_2020)\n",
    "\n",
    "model_name_2022 = f\"{local_models_path}/distilbert-base-cased-distilled-squad-finetuned-NLB-QA-2022-full\"\n",
    "tokenizer_2022 = DistilBertTokenizerFast.from_pretrained(model_name_2022)\n",
    "model_2022 = AutoModelForQuestionAnswering.from_pretrained(model_name_2022)\n",
    "\n",
    "model_name_2020_2022 = f\"{local_models_path}/distilbert-base-cased-distilled-squad-finetuned-NLB-QA-2042-full_combined\"\n",
    "tokenizer_2020_2022 = DistilBertTokenizerFast.from_pretrained(model_name_2020_2022)\n",
    "model_2020_2022 = AutoModelForQuestionAnswering.from_pretrained(model_name_2020_2022)\n",
    "\n",
    "model_name_2022_handwritten = f\"{local_models_path}/distilbert-base-cased-distilled-squad-finetuned-NLB-QA-2022-handwritten\"\n",
    "tokenizer_2022_handwritten = DistilBertTokenizerFast.from_pretrained(model_name_2022_handwritten)\n",
    "model_2022_handwritten = AutoModelForQuestionAnswering.from_pretrained(model_name_2022_handwritten)\n",
    "\n",
    "answers_2020 = [inference_answer(data_2020_full[\"test\"][\"question\"][idx], data_2020_full[\"test\"][\"context\"][idx], tokenizer_2020, model_2020) for idx in range(data_2020_full[\"test\"].shape[0])]\n",
    "answers_2020_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2020_full[\"test\"][\"id\"], answers_2020)]\n",
    "answers_2022 = [inference_answer(data_2022_full[\"test\"][\"question\"][idx], data_2022_full[\"test\"][\"context\"][idx], tokenizer_2022, model_2022) for idx in range(data_2022_full[\"test\"].shape[0])]\n",
    "answers_2022_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2022_full[\"test\"][\"id\"], answers_2022)]\n",
    "answers_2020_2022 = [inference_answer(data_2020_2022[\"test\"][\"question\"][idx], data_2020_2022[\"test\"][\"context\"][idx], tokenizer_2020_2022, model_2020_2022) for idx in range(data_2020_2022[\"test\"].shape[0])]\n",
    "answers_2020_2022_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2020_2022[\"test\"][\"id\"], answers_2020_2022)]\n",
    "answers_2022_handwritten = [inference_answer(data_2022_handwritten[\"test\"][\"question\"][idx], data_2022_handwritten[\"test\"][\"context\"][idx], tokenizer_2022_handwritten, model_2022_handwritten) for idx in range(data_2022_handwritten[\"test\"].shape[0])]\n",
    "answers_2022_handwritten_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in enumerate(answers_2022_handwritten)]\n",
    "\n",
    "# bertscore\n",
    "bert_results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "bert_results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "bert_results_2020_2022 = bertscore.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022, lang=\"en\")\n",
    "bert_results_2022_handwritten = bertscore.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten, lang=\"en\")\n",
    "# print(f\"Bertscore results 2020\\nF1: {np.array(bert_results_2020['f1']).mean()}, Precision: {np.array(bert_results_2020['precision']).mean()}, Recall: {np.array(bert_results_2020['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022\\nF1: {np.array(bert_results_2022['f1']).mean()}, Precision: {np.array(bert_results_2022['precision']).mean()}, Recall: {np.array(bert_results_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2020-2022\\nF1: {np.array(bert_results_2020_2022['f1']).mean()}, Precision: {np.array(bert_results_2020_2022['precision']).mean()}, Recall: {np.array(bert_results_2020_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022 handwritten\\nF1: {np.array(bert_results_2022_handwritten['f1']).mean()}, Precision: {np.array(bert_results_2022_handwritten['precision']).mean()}, Recall: {np.array(bert_results_2022_handwritten['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "bleu_results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "bleu_results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "bleu_results_2020_2022 = bleu.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022)\n",
    "bleu_results_2022_handwritten = bleu.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten)\n",
    "# print(f\"Bleu results 2020\\n{bleu_results_2020}\")\n",
    "# print(f\"Bleu results 2022\\n{bleu_results_2022}\")\n",
    "# print(f\"Bleu results 2020-2022\\n{bleu_results_2020_2022}\")\n",
    "# print(f\"Bleu results 2022 handwritten\\n{bleu_results_2022_handwritten}\")\n",
    "\n",
    "# squad_v2\n",
    "squad_results_2020 = squad_v2_metric.compute(predictions=answers_2020_squad, references=references_2020)\n",
    "squad_results_2022 = squad_v2_metric.compute(predictions=answers_2022_squad, references=references_2022)\n",
    "squad_results_2020_2022 = squad_v2_metric.compute(predictions=answers_2020_2022_squad, references=references_2020_2022)\n",
    "squad_results_2022_handwritten = squad_v2_metric.compute(predictions=answers_2022_handwritten_squad, references=references_2022_handwritten)\n",
    "# print(f\"Squad_v2 results 2020\\n{squad_results_2020}\")\n",
    "# print(f\"Squad_v2 results 2022\\n{squad_results_2022}\")\n",
    "# print(f\"Squad_v2 results 2020-2022\\n{squad_results_2020_2022}\")\n",
    "# print(f\"Squad_v2 results 2022 handwritten\\n{squad_results_2022_handwritten}\")\n",
    "\n",
    "\n",
    "# add results to dataframe\n",
    "results.loc[len(results)] = ['distilbert', 'full', '2020', np.array(bert_results_2020['precision']).mean(), np.array(bert_results_2020['recall']).mean(), np.array(bert_results_2020['f1']).mean(), bleu_results_2020['bleu'], squad_results_2020['exact'], squad_results_2020['f1']]\n",
    "results.loc[len(results)] = ['distilbert', 'full', '2022', np.array(bert_results_2022['precision']).mean(), np.array(bert_results_2022['recall']).mean(), np.array(bert_results_2022['f1']).mean(), bleu_results_2022['bleu'], squad_results_2022['exact'], squad_results_2022['f1']]\n",
    "results.loc[len(results)] = ['distilbert', 'full', '2020-2022', np.array(bert_results_2020_2022['precision']).mean(), np.array(bert_results_2020_2022['recall']).mean(), np.array(bert_results_2020_2022['f1']).mean(), bleu_results_2020_2022['bleu'], squad_results_2020_2022['exact'], squad_results_2020_2022['f1']]\n",
    "results.loc[len(results)] = ['distilbert', 'full', '2022 handwritten', np.array(bert_results_2022_handwritten['precision']).mean(), np.array(bert_results_2022_handwritten['recall']).mean(), np.array(bert_results_2022_handwritten['f1']).mean(), bleu_results_2022_handwritten['bleu'], squad_results_2022_handwritten['exact'], squad_results_2022_handwritten['f1']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta - finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "model_name_2020 = f\"{local_models_path}/roberta-base-squad2-finetuned-NLB-QA-2020-full\"\n",
    "tokenizer_2020 = AutoTokenizer.from_pretrained(model_name_2020)\n",
    "model_2020 = AutoModelForQuestionAnswering.from_pretrained(model_name_2020)\n",
    "\n",
    "model_name_2022 = f\"{local_models_path}/roberta-base-squad2-finetuned-NLB-QA-2022-full\"\n",
    "tokenizer_2022 = AutoTokenizer.from_pretrained(model_name_2022)\n",
    "model_2022 = AutoModelForQuestionAnswering.from_pretrained(model_name_2022)\n",
    "\n",
    "model_name_2020_2022 = f\"{local_models_path}/roberta-base-squad2-finetuned-NLB-QA-2042-full_combined\"\n",
    "tokenizer_2020_2022 = AutoTokenizer.from_pretrained(model_name_2020_2022)\n",
    "model_2020_2022 = AutoModelForQuestionAnswering.from_pretrained(model_name_2020_2022)\n",
    "\n",
    "model_name_2022_handwritten = f\"{local_models_path}/roberta-base-squad2-finetuned-NLB-QA-2022-handwritten\"\n",
    "tokenizer_2022_handwritten = AutoTokenizer.from_pretrained(model_name_2022_handwritten)\n",
    "model_2022_handwritten = AutoModelForQuestionAnswering.from_pretrained(model_name_2022_handwritten)\n",
    "\n",
    "answers_2020 = [inference_answer(data_2020_full[\"test\"][\"question\"][idx], data_2020_full[\"test\"][\"context\"][idx], tokenizer_2020, model_2020) for idx in range(data_2020_full[\"test\"].shape[0])]\n",
    "answers_2020_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2020_full[\"test\"][\"id\"], answers_2020)]\n",
    "answers_2022 = [inference_answer(data_2022_full[\"test\"][\"question\"][idx], data_2022_full[\"test\"][\"context\"][idx], tokenizer_2022, model_2022) for idx in range(data_2022_full[\"test\"].shape[0])]\n",
    "answers_2022_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2022_full[\"test\"][\"id\"], answers_2022)]\n",
    "answers_2020_2022 = [inference_answer(data_2020_2022[\"test\"][\"question\"][idx], data_2020_2022[\"test\"][\"context\"][idx], tokenizer_2020_2022, model_2020_2022) for idx in range(data_2020_2022[\"test\"].shape[0])]\n",
    "answers_2020_2022_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2020_2022[\"test\"][\"id\"], answers_2020_2022)]\n",
    "answers_2022_handwritten = [inference_answer(data_2022_handwritten[\"test\"][\"question\"][idx], data_2022_handwritten[\"test\"][\"context\"][idx], tokenizer_2022_handwritten, model_2022_handwritten) for idx in range(data_2022_handwritten[\"test\"].shape[0])]\n",
    "answers_2022_handwritten_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in enumerate(answers_2022_handwritten)]\n",
    "\n",
    "# bertscore\n",
    "bert_results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "bert_results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "bert_results_2020_2022 = bertscore.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022, lang=\"en\")\n",
    "bert_results_2022_handwritten = bertscore.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten, lang=\"en\")\n",
    "# print(f\"Bertscore results 2020\\nF1: {np.array(bert_results_2020['f1']).mean()}, Precision: {np.array(bert_results_2020['precision']).mean()}, Recall: {np.array(bert_results_2020['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022\\nF1: {np.array(bert_results_2022['f1']).mean()}, Precision: {np.array(bert_results_2022['precision']).mean()}, Recall: {np.array(bert_results_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2020-2022\\nF1: {np.array(bert_results_2020_2022['f1']).mean()}, Precision: {np.array(bert_results_2020_2022['precision']).mean()}, Recall: {np.array(bert_results_2020_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022 handwritten\\nF1: {np.array(bert_results_2022_handwritten['f1']).mean()}, Precision: {np.array(bert_results_2022_handwritten['precision']).mean()}, Recall: {np.array(bert_results_2022_handwritten['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "bleu_results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "bleu_results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "bleu_results_2020_2022 = bleu.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022)\n",
    "bleu_results_2022_handwritten = bleu.compute(predictions=answers_2022_handwritten, references=gt_answers_2022_handwritten)\n",
    "# print(f\"Bleu results 2020\\n{bleu_results_2020}\")\n",
    "# print(f\"Bleu results 2022\\n{bleu_results_2022}\")\n",
    "# print(f\"Bleu results 2020-2022\\n{bleu_results_2020_2022}\")\n",
    "# print(f\"Bleu results 2022 handwritten\\n{bleu_results_2022_handwritten}\")\n",
    "\n",
    "# squad_v2\n",
    "squad_results_2020 = squad_v2_metric.compute(predictions=answers_2020_squad, references=references_2020)\n",
    "squad_results_2022 = squad_v2_metric.compute(predictions=answers_2022_squad, references=references_2022)\n",
    "squad_results_2020_2022 = squad_v2_metric.compute(predictions=answers_2020_2022_squad, references=references_2020_2022)\n",
    "squad_results_2022_handwritten = squad_v2_metric.compute(predictions=answers_2022_handwritten_squad, references=references_2022_handwritten)\n",
    "# print(f\"Squad_v2 results 2020\\n{squad_results_2020}\")\n",
    "# print(f\"Squad_v2 results 2022\\n{squad_results_2022}\")\n",
    "# print(f\"Squad_v2 results 2020-2022\\n{squad_results_2020_2022}\")\n",
    "# print(f\"Squad_v2 results 2022 handwritten\\n{squad_results_2022_handwritten}\")\n",
    "\n",
    "\n",
    "# add results to dataframe\n",
    "results.loc[len(results)] = ['roberta', 'full', '2020', np.array(bert_results_2020['precision']).mean(), np.array(bert_results_2020['recall']).mean(), np.array(bert_results_2020['f1']).mean(), bleu_results_2020['bleu'], squad_results_2020['exact'], squad_results_2020['f1']]\n",
    "results.loc[len(results)] = ['roberta', 'full', '2022', np.array(bert_results_2022['precision']).mean(), np.array(bert_results_2022['recall']).mean(), np.array(bert_results_2022['f1']).mean(), bleu_results_2022['bleu'], squad_results_2022['exact'], squad_results_2022['f1']]\n",
    "results.loc[len(results)] = ['roberta', 'full', '2020-2022', np.array(bert_results_2020_2022['precision']).mean(), np.array(bert_results_2020_2022['recall']).mean(), np.array(bert_results_2020_2022['f1']).mean(), bleu_results_2020_2022['bleu'], squad_results_2020_2022['exact'], squad_results_2020_2022['f1']]\n",
    "results.loc[len(results)] = ['roberta', 'full', '2022 handwritten', np.array(bert_results_2022_handwritten['precision']).mean(), np.array(bert_results_2022_handwritten['recall']).mean(), np.array(bert_results_2022_handwritten['f1']).mean(), bleu_results_2022_handwritten['bleu'], squad_results_2022_handwritten['exact'], squad_results_2022_handwritten['f1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/models/BERT/roberta-base-squad2-finetuned-NLB-QA-2020-full'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_2020"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distilbert - finetuned  - train set halved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "model_name_2020 = f\"{local_models_path}/distilbert-base-cased-distilled-squad-finetuned-NLB-QA-2020-smaller\"\n",
    "tokenizer_2020 = DistilBertTokenizerFast.from_pretrained(model_name_2020)\n",
    "model_2020 = AutoModelForQuestionAnswering.from_pretrained(model_name_2020)\n",
    "\n",
    "model_name_2022 = f\"{local_models_path}/distilbert-base-cased-distilled-squad-finetuned-NLB-QA-2022-smaller\"\n",
    "tokenizer_2022 = DistilBertTokenizerFast.from_pretrained(model_name_2022)\n",
    "model_2022 = AutoModelForQuestionAnswering.from_pretrained(model_name_2022)\n",
    "\n",
    "model_name_2020_2022 = f\"{local_models_path}/distilbert-base-cased-distilled-squad-finetuned-NLB-QA-2042-smaller_combined\"\n",
    "tokenizer_2020_2022 = DistilBertTokenizerFast.from_pretrained(model_name_2020_2022)\n",
    "model_2020_2022 = AutoModelForQuestionAnswering.from_pretrained(model_name_2020_2022)\n",
    "\n",
    "answers_2020 = [inference_answer(data_2020_full[\"test\"][\"question\"][idx], data_2020_full[\"test\"][\"context\"][idx], tokenizer_2020, model_2020) for idx in range(data_2020_full[\"test\"].shape[0])]\n",
    "answers_2020_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2020_full[\"test\"][\"id\"], answers_2020)]\n",
    "answers_2022 = [inference_answer(data_2022_full[\"test\"][\"question\"][idx], data_2022_full[\"test\"][\"context\"][idx], tokenizer_2022, model_2022) for idx in range(data_2022_full[\"test\"].shape[0])]\n",
    "answers_2022_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2022_full[\"test\"][\"id\"], answers_2022)]\n",
    "answers_2020_2022 = [inference_answer(data_2020_2022[\"test\"][\"question\"][idx], data_2020_2022[\"test\"][\"context\"][idx], tokenizer_2020_2022, model_2020_2022) for idx in range(data_2020_2022[\"test\"].shape[0])]\n",
    "answers_2020_2022_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2020_2022[\"test\"][\"id\"], answers_2020_2022)]\n",
    "\n",
    "# bertscore\n",
    "bert_results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "bert_results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "bert_results_2020_2022 = bertscore.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022, lang=\"en\")\n",
    "# print(f\"Bertscore results 2020\\nF1: {np.array(bert_results_2020['f1']).mean()}, Precision: {np.array(bert_results_2020['precision']).mean()}, Recall: {np.array(bert_results_2020['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022\\nF1: {np.array(bert_results_2022['f1']).mean()}, Precision: {np.array(bert_results_2022['precision']).mean()}, Recall: {np.array(bert_results_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2020-2022\\nF1: {np.array(bert_results_2020_2022['f1']).mean()}, Precision: {np.array(bert_results_2020_2022['precision']).mean()}, Recall: {np.array(bert_results_2020_2022['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "bleu_results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "bleu_results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "bleu_results_2020_2022 = bleu.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022)\n",
    "# print(f\"Bleu results 2020\\n{bleu_results_2020}\")\n",
    "# print(f\"Bleu results 2022\\n{bleu_results_2022}\")\n",
    "# print(f\"Bleu results 2020-2022\\n{bleu_results_2020_2022}\")\n",
    "\n",
    "# squad_v2\n",
    "squad_results_2020 = squad_v2_metric.compute(predictions=answers_2020_squad, references=references_2020)\n",
    "squad_results_2022 = squad_v2_metric.compute(predictions=answers_2022_squad, references=references_2022)\n",
    "squad_results_2020_2022 = squad_v2_metric.compute(predictions=answers_2020_2022_squad, references=references_2020_2022)\n",
    "# print(f\"Squad_v2 results 2020\\n{squad_results_2020}\")\n",
    "# print(f\"Squad_v2 results 2022\\n{squad_results_2022}\")\n",
    "# print(f\"Squad_v2 results 2020-2022\\n{squad_results_2020_2022}\")\n",
    "\n",
    "\n",
    "# add results to dataframe\n",
    "results.loc[len(results)] = ['distilbert', 'smaller', '2020', np.array(bert_results_2020['precision']).mean(), np.array(bert_results_2020['recall']).mean(), np.array(bert_results_2020['f1']).mean(), bleu_results_2020['bleu'], squad_results_2020['exact'], squad_results_2020['f1']]\n",
    "results.loc[len(results)] = ['distilbert', 'smaller', '2022', np.array(bert_results_2022['precision']).mean(), np.array(bert_results_2022['recall']).mean(), np.array(bert_results_2022['f1']).mean(), bleu_results_2022['bleu'], squad_results_2022['exact'], squad_results_2022['f1']]\n",
    "results.loc[len(results)] = ['distilbert', 'smaller', '2020-2022', np.array(bert_results_2020_2022['precision']).mean(), np.array(bert_results_2020_2022['recall']).mean(), np.array(bert_results_2020_2022['f1']).mean(), bleu_results_2020_2022['bleu'], squad_results_2020_2022['exact'], squad_results_2020_2022['f1']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Roberta - finetuned - train set halved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n",
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "model_name_2020 = f\"{local_models_path}/roberta-base-squad2-finetuned-NLB-QA-2020-smaller\"\n",
    "tokenizer_2020 = AutoTokenizer.from_pretrained(model_name_2020)\n",
    "model_2020 = AutoModelForQuestionAnswering.from_pretrained(model_name_2020)\n",
    "\n",
    "model_name_2022 = f\"{local_models_path}/roberta-base-squad2-finetuned-NLB-QA-2022-smaller\"\n",
    "tokenizer_2022 = AutoTokenizer.from_pretrained(model_name_2022)\n",
    "model_2022 = AutoModelForQuestionAnswering.from_pretrained(model_name_2022)\n",
    "\n",
    "model_name_2020_2022 = f\"{local_models_path}/roberta-base-squad2-finetuned-NLB-QA-2042-smaller_combined\"\n",
    "tokenizer_2020_2022 = AutoTokenizer.from_pretrained(model_name_2020_2022)\n",
    "model_2020_2022 = AutoModelForQuestionAnswering.from_pretrained(model_name_2020_2022)\n",
    "\n",
    "answers_2020 = [inference_answer(data_2020_full[\"test\"][\"question\"][idx], data_2020_full[\"test\"][\"context\"][idx], tokenizer_2020, model_2020) for idx in range(data_2020_full[\"test\"].shape[0])]\n",
    "answers_2020_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2020_full[\"test\"][\"id\"], answers_2020)]\n",
    "answers_2022 = [inference_answer(data_2022_full[\"test\"][\"question\"][idx], data_2022_full[\"test\"][\"context\"][idx], tokenizer_2022, model_2022) for idx in range(data_2022_full[\"test\"].shape[0])]\n",
    "answers_2022_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2022_full[\"test\"][\"id\"], answers_2022)]\n",
    "answers_2020_2022 = [inference_answer(data_2020_2022[\"test\"][\"question\"][idx], data_2020_2022[\"test\"][\"context\"][idx], tokenizer_2020_2022, model_2020_2022) for idx in range(data_2020_2022[\"test\"].shape[0])]\n",
    "answers_2020_2022_squad = [{\"id\": str(id), \"prediction_text\": answer, \"no_answer_probability\": 0.} for id, answer in zip(data_2020_2022[\"test\"][\"id\"], answers_2020_2022)]\n",
    "\n",
    "# bertscore\n",
    "bert_results_2020 = bertscore.compute(predictions=answers_2020, references=gt_answers_2020_full, lang=\"en\")\n",
    "bert_results_2022 = bertscore.compute(predictions=answers_2022, references=gt_answers_2022_full, lang=\"en\")\n",
    "bert_results_2020_2022 = bertscore.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022, lang=\"en\")\n",
    "# print(f\"Bertscore results 2020\\nF1: {np.array(bert_results_2020['f1']).mean()}, Precision: {np.array(bert_results_2020['precision']).mean()}, Recall: {np.array(bert_results_2020['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2022\\nF1: {np.array(bert_results_2022['f1']).mean()}, Precision: {np.array(bert_results_2022['precision']).mean()}, Recall: {np.array(bert_results_2022['recall']).mean()}\")\n",
    "# print(f\"Bertscore results 2020-2022\\nF1: {np.array(bert_results_2020_2022['f1']).mean()}, Precision: {np.array(bert_results_2020_2022['precision']).mean()}, Recall: {np.array(bert_results_2020_2022['recall']).mean()}\")\n",
    "\n",
    "# bleu\n",
    "bleu_results_2020 = bleu.compute(predictions=answers_2020, references=gt_answers_2020_full)\n",
    "bleu_results_2022 = bleu.compute(predictions=answers_2022, references=gt_answers_2022_full)\n",
    "bleu_results_2020_2022 = bleu.compute(predictions=answers_2020_2022, references=gt_answers_2020_2022)\n",
    "# print(f\"Bleu results 2020\\n{bleu_results_2020}\")\n",
    "# print(f\"Bleu results 2022\\n{bleu_results_2022}\")\n",
    "# print(f\"Bleu results 2020-2022\\n{bleu_results_2020_2022}\")\n",
    "\n",
    "# squad_v2\n",
    "squad_results_2020 = squad_v2_metric.compute(predictions=answers_2020_squad, references=references_2020)\n",
    "squad_results_2022 = squad_v2_metric.compute(predictions=answers_2022_squad, references=references_2022)\n",
    "squad_results_2020_2022 = squad_v2_metric.compute(predictions=answers_2020_2022_squad, references=references_2020_2022)\n",
    "# print(f\"Squad_v2 results 2020\\n{squad_results_2020}\")\n",
    "# print(f\"Squad_v2 results 2022\\n{squad_results_2022}\")\n",
    "# print(f\"Squad_v2 results 2020-2022\\n{squad_results_2020_2022}\")\n",
    "\n",
    "\n",
    "# add results to dataframe\n",
    "results.loc[len(results)] = ['roberta', 'smaller', '2020', np.array(bert_results_2020['precision']).mean(), np.array(bert_results_2020['recall']).mean(), np.array(bert_results_2020['f1']).mean(), bleu_results_2020['bleu'], squad_results_2020['exact'], squad_results_2020['f1']]\n",
    "results.loc[len(results)] = ['roberta', 'smaller', '2022', np.array(bert_results_2022['precision']).mean(), np.array(bert_results_2022['recall']).mean(), np.array(bert_results_2022['f1']).mean(), bleu_results_2022['bleu'], squad_results_2022['exact'], squad_results_2022['f1']]\n",
    "results.loc[len(results)] = ['roberta', 'smaller', '2020-2022', np.array(bert_results_2020_2022['precision']).mean(), np.array(bert_results_2020_2022['recall']).mean(), np.array(bert_results_2020_2022['f1']).mean(), bleu_results_2020_2022['bleu'], squad_results_2020_2022['exact'], squad_results_2020_2022['f1']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Data</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Bert.Precision</th>\n",
       "      <th>Bert.Recall</th>\n",
       "      <th>Bert.F1</th>\n",
       "      <th>BLEU</th>\n",
       "      <th>Squad.Exact</th>\n",
       "      <th>Squad.F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>None</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.905406</td>\n",
       "      <td>0.934903</td>\n",
       "      <td>0.919109</td>\n",
       "      <td>0.151413</td>\n",
       "      <td>44.642857</td>\n",
       "      <td>57.656287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>None</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.870398</td>\n",
       "      <td>0.909708</td>\n",
       "      <td>0.888749</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>31.775701</td>\n",
       "      <td>46.816539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-2022</td>\n",
       "      <td>0.860701</td>\n",
       "      <td>0.897586</td>\n",
       "      <td>0.877968</td>\n",
       "      <td>0.092217</td>\n",
       "      <td>37.323944</td>\n",
       "      <td>48.682393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>None</td>\n",
       "      <td>2022 handwritten</td>\n",
       "      <td>0.870675</td>\n",
       "      <td>0.857768</td>\n",
       "      <td>0.863793</td>\n",
       "      <td>0.153550</td>\n",
       "      <td>15.789474</td>\n",
       "      <td>37.710726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>roberta</td>\n",
       "      <td>None</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.902893</td>\n",
       "      <td>0.928263</td>\n",
       "      <td>0.914307</td>\n",
       "      <td>0.363732</td>\n",
       "      <td>46.428571</td>\n",
       "      <td>57.197390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>roberta</td>\n",
       "      <td>None</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.888020</td>\n",
       "      <td>0.910760</td>\n",
       "      <td>0.897950</td>\n",
       "      <td>0.212856</td>\n",
       "      <td>40.186916</td>\n",
       "      <td>53.357085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>roberta</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-2022</td>\n",
       "      <td>0.872339</td>\n",
       "      <td>0.890593</td>\n",
       "      <td>0.880310</td>\n",
       "      <td>0.235591</td>\n",
       "      <td>38.028169</td>\n",
       "      <td>46.469602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>roberta</td>\n",
       "      <td>None</td>\n",
       "      <td>2022 handwritten</td>\n",
       "      <td>0.782189</td>\n",
       "      <td>0.777999</td>\n",
       "      <td>0.778999</td>\n",
       "      <td>0.015593</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>22.144303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>full</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.902938</td>\n",
       "      <td>0.934031</td>\n",
       "      <td>0.917441</td>\n",
       "      <td>0.150651</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>56.703906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>full</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.869415</td>\n",
       "      <td>0.906245</td>\n",
       "      <td>0.886849</td>\n",
       "      <td>0.161154</td>\n",
       "      <td>37.383178</td>\n",
       "      <td>50.040854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>full</td>\n",
       "      <td>2020-2022</td>\n",
       "      <td>0.883702</td>\n",
       "      <td>0.916222</td>\n",
       "      <td>0.899024</td>\n",
       "      <td>0.116869</td>\n",
       "      <td>38.732394</td>\n",
       "      <td>50.503368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>full</td>\n",
       "      <td>2022 handwritten</td>\n",
       "      <td>0.874550</td>\n",
       "      <td>0.897994</td>\n",
       "      <td>0.885605</td>\n",
       "      <td>0.405031</td>\n",
       "      <td>15.789474</td>\n",
       "      <td>53.589571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>roberta</td>\n",
       "      <td>full</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.894044</td>\n",
       "      <td>0.932774</td>\n",
       "      <td>0.912179</td>\n",
       "      <td>0.395282</td>\n",
       "      <td>53.571429</td>\n",
       "      <td>65.235095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>roberta</td>\n",
       "      <td>full</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.899638</td>\n",
       "      <td>0.929622</td>\n",
       "      <td>0.913640</td>\n",
       "      <td>0.376058</td>\n",
       "      <td>51.401869</td>\n",
       "      <td>66.483992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>roberta</td>\n",
       "      <td>full</td>\n",
       "      <td>2020-2022</td>\n",
       "      <td>0.886665</td>\n",
       "      <td>0.923151</td>\n",
       "      <td>0.903832</td>\n",
       "      <td>0.320907</td>\n",
       "      <td>47.183099</td>\n",
       "      <td>59.320042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>roberta</td>\n",
       "      <td>full</td>\n",
       "      <td>2022 handwritten</td>\n",
       "      <td>0.713685</td>\n",
       "      <td>0.802122</td>\n",
       "      <td>0.754143</td>\n",
       "      <td>0.505577</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>52.000932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>smaller</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.903241</td>\n",
       "      <td>0.932248</td>\n",
       "      <td>0.916776</td>\n",
       "      <td>0.157392</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>55.334858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>smaller</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.876152</td>\n",
       "      <td>0.913444</td>\n",
       "      <td>0.893689</td>\n",
       "      <td>0.147825</td>\n",
       "      <td>36.448598</td>\n",
       "      <td>48.947544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>distilbert</td>\n",
       "      <td>smaller</td>\n",
       "      <td>2020-2022</td>\n",
       "      <td>0.861338</td>\n",
       "      <td>0.893057</td>\n",
       "      <td>0.876252</td>\n",
       "      <td>0.109701</td>\n",
       "      <td>39.436620</td>\n",
       "      <td>50.649359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>roberta</td>\n",
       "      <td>smaller</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.891093</td>\n",
       "      <td>0.929960</td>\n",
       "      <td>0.909174</td>\n",
       "      <td>0.304123</td>\n",
       "      <td>51.785714</td>\n",
       "      <td>63.447390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>roberta</td>\n",
       "      <td>smaller</td>\n",
       "      <td>2022</td>\n",
       "      <td>0.889228</td>\n",
       "      <td>0.924931</td>\n",
       "      <td>0.906049</td>\n",
       "      <td>0.392169</td>\n",
       "      <td>53.271028</td>\n",
       "      <td>66.666458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>roberta</td>\n",
       "      <td>smaller</td>\n",
       "      <td>2020-2022</td>\n",
       "      <td>0.877742</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>0.896709</td>\n",
       "      <td>0.289511</td>\n",
       "      <td>45.070423</td>\n",
       "      <td>57.817596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model Train Data         Data Type  Bert.Precision  Bert.Recall  \\\n",
       "0   distilbert       None              2020        0.905406     0.934903   \n",
       "1   distilbert       None              2022        0.870398     0.909708   \n",
       "2   distilbert       None         2020-2022        0.860701     0.897586   \n",
       "3   distilbert       None  2022 handwritten        0.870675     0.857768   \n",
       "4      roberta       None              2020        0.902893     0.928263   \n",
       "5      roberta       None              2022        0.888020     0.910760   \n",
       "6      roberta       None         2020-2022        0.872339     0.890593   \n",
       "7      roberta       None  2022 handwritten        0.782189     0.777999   \n",
       "8   distilbert       full              2020        0.902938     0.934031   \n",
       "9   distilbert       full              2022        0.869415     0.906245   \n",
       "10  distilbert       full         2020-2022        0.883702     0.916222   \n",
       "11  distilbert       full  2022 handwritten        0.874550     0.897994   \n",
       "12     roberta       full              2020        0.894044     0.932774   \n",
       "13     roberta       full              2022        0.899638     0.929622   \n",
       "14     roberta       full         2020-2022        0.886665     0.923151   \n",
       "15     roberta       full  2022 handwritten        0.713685     0.802122   \n",
       "16  distilbert    smaller              2020        0.903241     0.932248   \n",
       "17  distilbert    smaller              2022        0.876152     0.913444   \n",
       "18  distilbert    smaller         2020-2022        0.861338     0.893057   \n",
       "19     roberta    smaller              2020        0.891093     0.929960   \n",
       "20     roberta    smaller              2022        0.889228     0.924931   \n",
       "21     roberta    smaller         2020-2022        0.877742     0.918367   \n",
       "\n",
       "     Bert.F1      BLEU  Squad.Exact   Squad.F1  \n",
       "0   0.919109  0.151413    44.642857  57.656287  \n",
       "1   0.888749  0.109171    31.775701  46.816539  \n",
       "2   0.877968  0.092217    37.323944  48.682393  \n",
       "3   0.863793  0.153550    15.789474  37.710726  \n",
       "4   0.914307  0.363732    46.428571  57.197390  \n",
       "5   0.897950  0.212856    40.186916  53.357085  \n",
       "6   0.880310  0.235591    38.028169  46.469602  \n",
       "7   0.778999  0.015593     5.263158  22.144303  \n",
       "8   0.917441  0.150651    42.857143  56.703906  \n",
       "9   0.886849  0.161154    37.383178  50.040854  \n",
       "10  0.899024  0.116869    38.732394  50.503368  \n",
       "11  0.885605  0.405031    15.789474  53.589571  \n",
       "12  0.912179  0.395282    53.571429  65.235095  \n",
       "13  0.913640  0.376058    51.401869  66.483992  \n",
       "14  0.903832  0.320907    47.183099  59.320042  \n",
       "15  0.754143  0.505577    10.526316  52.000932  \n",
       "16  0.916776  0.157392    42.857143  55.334858  \n",
       "17  0.893689  0.147825    36.448598  48.947544  \n",
       "18  0.876252  0.109701    39.436620  50.649359  \n",
       "19  0.909174  0.304123    51.785714  63.447390  \n",
       "20  0.906049  0.392169    53.271028  66.666458  \n",
       "21  0.896709  0.289511    45.070423  57.817596  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
