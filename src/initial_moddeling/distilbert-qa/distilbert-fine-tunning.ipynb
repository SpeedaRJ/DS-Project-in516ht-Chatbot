{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, AutoModelForQuestionAnswering, DefaultDataCollator, Trainer, TrainingArguments, set_seed\n",
    "from datasets import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "# any combination of these years and dataset types can be used\n",
    "# year = 2020\n",
    "# year = 2022\n",
    "# dataset_type = \"full\"\n",
    "# dataset_type = \"smaller\"\n",
    "\n",
    "# only combination of these years and dataset types can be used\n",
    "# year = 2042 # idk some random number for file names\n",
    "# dataset_type = \"full-combined\"\n",
    "# dataset_type = \"smaller-combined\"\n",
    "\n",
    "# only combination of these years and dataset types can be used\n",
    "year = 2022\n",
    "dataset_type = \"handwritten\"\n",
    "\n",
    "local_models_path = '../../data/models/BERT'\n",
    "\n",
    "model_name = 'distilbert-base-cased-distilled-squad'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenizer and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "model = model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:/Users/Luka/.cache/huggingface/datasets/csv/default-853b320bab41342e/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a788f10be44aaaa9744bdefd5f8884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427bbbdd5326486abed5038c7f27cfb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e1b89242534774a41368e0cce79be5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:/Users/Luka/.cache/huggingface/datasets/csv/default-853b320bab41342e/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from file and split it into train and test datasets\n",
    "if dataset_type == \"full\":\n",
    "    data = load_dataset('csv', data_files=f\"../../data/clean/sustainability-report-{year}-squad-format.csv\",\n",
    "                        delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "elif dataset_type == \"smaller\":\n",
    "    data = load_dataset('csv', data_files=f\"../../data/clean/sustainability-report-{year}-squad-format.csv\",\n",
    "                        delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "    data[\"train\"] = data[\"train\"].select(range(len(data[\"train\"]) // 2))\n",
    "elif dataset_type == \"full-combined\":\n",
    "    data = load_dataset('csv', data_files=\"../../data/clean/sustainability-report-2042-squad-format.csv\",\n",
    "                        delimiter=\";\", split=\"train\").train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "elif dataset_type == \"smaller-combined\":\n",
    "    data = load_dataset('csv', data_files=\"../../data/clean/sustainability-report-2042-squad-format.csv\",\n",
    "                        delimiter=\";\", split=\"train\").train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "    data[\"train\"] = data[\"train\"].select(range(len(data[\"train\"]) // 2))\n",
    "elif dataset_type == \"handwritten\":\n",
    "    data = load_dataset('csv', data_files=f\"../../data/clean/QA_SR_2022_Expert-squad-format.csv\",\n",
    "                        delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True, seed=SEED)\n",
    "else:\n",
    "    raise Exception(\"Invalid dataset type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ae51ccbf7e4426baa8cd8ad3323ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d53cf7258b4b3e9d15528cb5824bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c80aec49b5546cd809fd4efad4f1cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac34bb749a0e4ed98aaedd5804cb14ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce15fbd9e8904d0982db37038ca68d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13b68fdc23b4176b78a14cd631d453d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reformat the train and test set such as they adhere to the SQuAD format (reading from cvs loads strings not objects as expected)\n",
    "data[\"test\"] = data[\"test\"].map(\n",
    "    lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data[\"test\"] = data[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\n",
    "                                \"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "# replace all \"\\n\" with \" \" in the context, answers and questions\n",
    "data[\"test\"] = data[\"test\"].map(lambda example: {\"question\": example[\"question\"].replace(\"\\n\", \" \"), \"context\": example[\"context\"].replace(\"\\n\", \" \"), \"answers\": {\n",
    "                                \"text\": [example[\"answers\"][\"text\"][0].replace(\"\\n\", \" \")], \"answer_start\": example[\"answers\"][\"answer_start\"]}})\n",
    "data[\"test\"] = data[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "\n",
    "data[\"train\"] = data[\"train\"].map(\n",
    "    lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data[\"train\"] = data[\"train\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\n",
    "                                  \"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "# replace all \"\\n\" with \" \" in the context, answers and questions\n",
    "data[\"train\"] = data[\"train\"].map(lambda example: {\"question\": example[\"question\"].replace(\"\\n\", \" \"), \"context\": example[\"context\"].replace(\"\\n\", \" \"), \"answers\": {\n",
    "                                \"text\": [example[\"answers\"][\"text\"][0].replace(\"\\n\", \" \")], \"answer_start\": example[\"answers\"][\"answer_start\"]}})\n",
    "data[\"train\"] = data[\"train\"].remove_columns([\"text\", \"answer_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcf59aa972346dab45eb6f988ed24f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/43 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45897f993451416a9eb2adbb87fccfa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/19 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_sample_data(data):\n",
    "    # Tokenize the data\n",
    "    tokenized_feature = tokenizer(\n",
    "        data[\"question\"],\n",
    "        data[\"context\"],\n",
    "        max_length=384,\n",
    "        return_overflowing_tokens=True,\n",
    "        stride=128,\n",
    "        truncation=\"only_second\",\n",
    "        padding=\"max_length\",\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "\n",
    "    # When it overflows, multiple rows will be returned for a single example.\n",
    "    # The following then gets the array of corresponding the original sample index.\n",
    "    sample_mapping = tokenized_feature.pop(\"overflow_to_sample_mapping\")\n",
    "    # Get the array of [start_char, end_char + 1] in each token.\n",
    "    # The shape is [returned_row_size, max_length]\n",
    "    offset_mapping = tokenized_feature.pop(\"offset_mapping\")\n",
    "\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        sample_index = sample_mapping[i]\n",
    "        answers = data[\"answers\"][sample_index]\n",
    "        start_char = answers[\"answer_start\"][0]\n",
    "        end_char = start_char + len(answers[\"text\"][0]) - 1\n",
    "        # The format of sequence_ids is [None, 0, ..., 0, None, None, 1, ..., 1, None, None, ...]\n",
    "        # in which question's token is 0 and contex's token is 1\n",
    "        sequence_ids = tokenized_feature.sequence_ids(i)\n",
    "        # find the start and end index of context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "        # Set start positions and end positions in inputs_ids\n",
    "        # Note: The second element in offset is end_char + 1\n",
    "        # if offset[context_start][0] > end_char or offset[context_end][1] <= start_char:\n",
    "        if not (offset[context_start][0] <= start_char and end_char < offset[context_end][1]):\n",
    "            # The case that answer is not inside the context\n",
    "            # Note : Some tokenizer (such as, tokenizer in rinna model) doesn't place CLS\n",
    "            # for the first token in sequence, and I then set -1 as positions.\n",
    "            # (Later I'll process rows with start_positions=-1.)\n",
    "            start_positions.append(-1)\n",
    "            end_positions.append(-1)\n",
    "        else:\n",
    "            # The case that answer is found in the context\n",
    "\n",
    "            # Set start position\n",
    "            idx = context_start\n",
    "            while offset[idx][0] < start_char:\n",
    "                idx += 1\n",
    "            if offset[idx][0] == start_char:\n",
    "                start_positions.append(idx)\n",
    "            else:\n",
    "                start_positions.append(idx - 1)\n",
    "\n",
    "            # Set end position\n",
    "            idx = context_end\n",
    "            while offset[idx][1] > end_char + 1:\n",
    "                idx -= 1\n",
    "            if offset[idx][1] == end_char + 1:\n",
    "                end_positions.append(idx)\n",
    "            else:\n",
    "                end_positions.append(idx + 1)\n",
    "\n",
    "    # Build result\n",
    "    tokenized_feature[\"start_positions\"] = start_positions\n",
    "    tokenized_feature[\"end_positions\"] = end_positions\n",
    "    return tokenized_feature\n",
    "\n",
    "\n",
    "# Run conversion\n",
    "if dataset_type == \"handwritten\":\n",
    "    remove_columns = [\"context\", \"question\", \"answers\"]\n",
    "else:\n",
    "    remove_columns = [\"id\", \"context\", \"question\", \"answers\"]\n",
    "tokenized_ds = data.map(\n",
    "    tokenize_sample_data,\n",
    "    remove_columns=remove_columns,\n",
    "    batched=True,\n",
    "    batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = model_name.split(\"/\")[-1]\n",
    "output_dir = f\"{local_models_path}/{name}-finetuned-NLB-QA-{year}-{dataset_type}\"\n",
    "\n",
    "# Set the data collator\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=25,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "# Define the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Luka\\miniconda3\\envs\\project_ds\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144eb343067f4fed9443018d9f655d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbfe168ae6b34348a26d7702fbe17e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.3760712146759033, 'eval_runtime': 0.0638, 'eval_samples_per_second': 298.012, 'eval_steps_per_second': 31.37, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0775304f1094b989b30b8d5c4a496f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.5286452770233154, 'eval_runtime': 0.0622, 'eval_samples_per_second': 305.574, 'eval_steps_per_second': 32.166, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539e32a89d3d4073be82b396099b8dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0230422019958496, 'eval_runtime': 0.0614, 'eval_samples_per_second': 309.299, 'eval_steps_per_second': 32.558, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2a2cd3146347b3b83fc72e5160dc04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8170872926712036, 'eval_runtime': 0.0615, 'eval_samples_per_second': 309.004, 'eval_steps_per_second': 32.527, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480af16fc00e4118855c06be3e9372dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7909610271453857, 'eval_runtime': 0.0615, 'eval_samples_per_second': 308.973, 'eval_steps_per_second': 32.523, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7c3394b9a74ff3a2f90e28309429a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8591469526290894, 'eval_runtime': 0.0626, 'eval_samples_per_second': 303.364, 'eval_steps_per_second': 31.933, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b7e66a69a646a8a6dce17539fc7e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9960260391235352, 'eval_runtime': 0.0729, 'eval_samples_per_second': 260.638, 'eval_steps_per_second': 27.436, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8f2d5f058a43bd906be935704a7b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1263301372528076, 'eval_runtime': 0.0622, 'eval_samples_per_second': 305.252, 'eval_steps_per_second': 32.132, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fc2c90194ef4d11800209dc43239438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1948211193084717, 'eval_runtime': 0.0609, 'eval_samples_per_second': 311.765, 'eval_steps_per_second': 32.817, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c85f7c743454734a7356d46bd636371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.2691538333892822, 'eval_runtime': 0.0643, 'eval_samples_per_second': 295.675, 'eval_steps_per_second': 31.124, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3ebb29ac534ce39475a3b329fe7ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.349482297897339, 'eval_runtime': 0.0634, 'eval_samples_per_second': 299.767, 'eval_steps_per_second': 31.554, 'epoch': 11.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db4c419bad848e19ee39d9f9ce2a8f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4939448833465576, 'eval_runtime': 0.0711, 'eval_samples_per_second': 267.407, 'eval_steps_per_second': 28.148, 'epoch': 12.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fa772ab3284c50b8728ea2d1284285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.6220929622650146, 'eval_runtime': 0.0641, 'eval_samples_per_second': 296.416, 'eval_steps_per_second': 31.202, 'epoch': 13.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe1da3a69bf40ea9e541b7b2db4530f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.712167739868164, 'eval_runtime': 0.0649, 'eval_samples_per_second': 292.762, 'eval_steps_per_second': 30.817, 'epoch': 14.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b6be3db58e4eea9ea2cd292a2ee4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7318904399871826, 'eval_runtime': 0.0603, 'eval_samples_per_second': 314.913, 'eval_steps_per_second': 33.149, 'epoch': 15.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb38380272a479199be27f9e610452c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7436156272888184, 'eval_runtime': 0.0628, 'eval_samples_per_second': 302.4, 'eval_steps_per_second': 31.832, 'epoch': 16.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43ff12997af47369aae9c926d32e03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.7945306301116943, 'eval_runtime': 0.0668, 'eval_samples_per_second': 284.29, 'eval_steps_per_second': 29.925, 'epoch': 17.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07cb996cdcc4906b966ebee7d65e47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.8607277870178223, 'eval_runtime': 0.0627, 'eval_samples_per_second': 303.134, 'eval_steps_per_second': 31.909, 'epoch': 18.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa09cde8a334a4c897b37ec66a0ab78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.946033000946045, 'eval_runtime': 0.0626, 'eval_samples_per_second': 303.75, 'eval_steps_per_second': 31.974, 'epoch': 19.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd717f3117d4ba583914b1426a617c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9745185375213623, 'eval_runtime': 0.0627, 'eval_samples_per_second': 302.827, 'eval_steps_per_second': 31.877, 'epoch': 20.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3a40836c0744fb903ff43948825be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.982778549194336, 'eval_runtime': 0.0618, 'eval_samples_per_second': 307.475, 'eval_steps_per_second': 32.366, 'epoch': 21.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630bd0d8f8d945599ed4278fc3766613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.9901421070098877, 'eval_runtime': 0.0691, 'eval_samples_per_second': 274.931, 'eval_steps_per_second': 28.94, 'epoch': 22.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9499f31bf43446a0835adccfd5fdc103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.995432138442993, 'eval_runtime': 0.0632, 'eval_samples_per_second': 300.745, 'eval_steps_per_second': 31.657, 'epoch': 23.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6a2f7528b6e46809eaa494bc3c95bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.999448776245117, 'eval_runtime': 0.0632, 'eval_samples_per_second': 300.605, 'eval_steps_per_second': 31.643, 'epoch': 24.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16313d3cbe3d495c8457d9d22bd32472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.003803253173828, 'eval_runtime': 0.0653, 'eval_samples_per_second': 290.809, 'eval_steps_per_second': 30.611, 'epoch': 25.0}\n",
      "{'train_runtime': 48.4247, 'train_samples_per_second': 22.199, 'train_steps_per_second': 1.549, 'train_loss': 0.6431894429524739, 'epoch': 25.0}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
