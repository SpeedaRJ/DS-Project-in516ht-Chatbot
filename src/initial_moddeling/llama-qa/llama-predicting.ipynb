{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "\n",
    "from datasets import *\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import ast\n",
    "\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LLaMATokenizer'. \n",
      "The class this function is called from is 'LlamaTokenizer'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fbf1a0df3634967be490ea5c613b31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"decapoda-research/llama-7b-hf\"\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_name)\n",
    "model = LlamaForCausalLM.from_pretrained(model_name)#.to(\"cuda\") # not enough memory on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Luka/.cache/huggingface/datasets/csv/default-d8382661cd597e83/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n",
      "Loading cached split indices for dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-d8382661cd597e83\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-c261d5613d28d856.arrow and C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-d8382661cd597e83\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-e61829c1e4a24b65.arrow\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from file and split it into train and test datasets\n",
    "data = load_dataset('csv', data_files=\"../../data/clean/sustainability-report-2020-squad-format.csv\", delimiter=\";\", split='train').train_test_split(test_size=0.3, shuffle=True, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-d8382661cd597e83\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-0b15501cefb41ff7.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-d8382661cd597e83\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-6c4455904f60e079.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-d8382661cd597e83\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-65eb14b3b79cbed9.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Luka\\.cache\\huggingface\\datasets\\csv\\default-d8382661cd597e83\\0.0.0\\6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1\\cache-559c811f459458f4.arrow\n"
     ]
    }
   ],
   "source": [
    "# Reformat the train and test set such as they adhere to the SQuAD format (reading from cvs loads strings not objects as expected)\n",
    "data[\"test\"] = data[\"test\"].map(lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data[\"test\"] = data[\"test\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "data[\"test\"] = data[\"test\"].remove_columns([\"text\", \"answer_start\"])\n",
    "\n",
    "data[\"train\"] = data[\"train\"].map(lambda example: ast.literal_eval(example[\"answers\"]))\n",
    "data[\"train\"] = data[\"train\"].map(lambda example: {\"question\": example[\"question\"], \"context\": example[\"context\"], \"answers\": {\"text\": example[\"text\"], \"answer_start\": example[\"answer_start\"]}})\n",
    "data[\"train\"] = data[\"train\"].remove_columns([\"text\", \"answer_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizer(name_or_path='decapoda-research/llama-7b-hf', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"\", rstrip=False, lstrip=False, single_word=False, normalized=True)}, clean_up_tokenization_spaces=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # process the examples in input and target text format and the eos token at the end \n",
    "# def add_eos_to_examples(example):\n",
    "#     example['input_text'] = 'question: %s  context: %s </s>' % (example['question'], example['context'])\n",
    "#     example['target_text'] = '%s </s>' % example['answers']['text'][0]\n",
    "#     return example\n",
    "\n",
    "# # tokenize the examples\n",
    "# def convert_to_features(examples):\n",
    "#     model_inputs = tokenizer(examples['input_text'])\n",
    "    \n",
    "#     with tokenizer.as_target_tokenizer():\n",
    "#         labels = tokenizer(examples['target_text'])\n",
    "#         # temp = np.array(labels[\"input_ids\"])\n",
    "#         # temp[temp == tokenizer.pad_token_id] = -100\n",
    "#         # labels[\"input_ids\"] = temp.tolist()\n",
    "\n",
    "#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "#     return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = data[\"train\"], data[\"test\"]\n",
    "\n",
    "# train_data = train_data.map(add_eos_to_examples, load_from_cache_file=False)\n",
    "# train_data = train_data.map(convert_to_features, batched=True, load_from_cache_file=False)\n",
    "\n",
    "# test_data = test_data.map(add_eos_to_examples, load_from_cache_file=False)\n",
    "# test_data = test_data.map(convert_to_features, batched=True, load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'answers', 'id'],\n",
       "    num_rows: 129\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How does the Bank prevent or manage cyber risks arising from the increased volume of work from home?',\n",
       " 'context': 'nages cyber risks arising from the increased volumeof work from home through implemented measures, some of which areexplained below, namelyPromoting Freedom of Expr',\n",
       " 'answers': {'answer_start': [69], 'text': ['through implemented measures']},\n",
       " 'id': 132}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(question, context):\n",
    "    input_text = \"You got the information that: %s Answer the following question: %s\" % (context, question)\n",
    "    features = tokenizer(input_text, return_tensors='pt')\n",
    "\n",
    "    output = model.generate(features.input_ids, max_length=128)\n",
    "\n",
    "    # return tokenizer.decode(output)\n",
    "    return tokenizer.batch_decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('How many employees departed from NLB Group in 2020?',\n",
       "  'NLB Group In total, 382 employeesdeparted from NLB Group in 2020.In total, 162 employees de')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = [temp[\"answers\"][\"text\"][0] for temp in test_data]\n",
    "llama_answers = [get_answer(question, context) for question, context in zip(test_data[\"question\"][:1], test_data[\"context\"][:1])]\n",
    "# [(question, context) for question, context in zip(test_data[\"question\"][:1], test_data[\"context\"][:1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['382',\n",
       " 'green/sustainability financing',\n",
       " '1',\n",
       " '2021',\n",
       " 'law, collectiveagreements and internal regulations',\n",
       " 'Social and EnvironmentalPolicy',\n",
       " 'equal opportunities, justice',\n",
       " 'a visit by Santa Claus',\n",
       " '2020',\n",
       " 'three',\n",
       " '30th December 2020',\n",
       " '2020',\n",
       " '6.7%,',\n",
       " 'Komercijalna Banka a.d. Beograd',\n",
       " '2020',\n",
       " '2021',\n",
       " 'Bogdan Darmanović',\n",
       " '4,769',\n",
       " 'World Institute forSustainability and Ethics in Rising Economies',\n",
       " '2018',\n",
       " '2020',\n",
       " '23 million EUR',\n",
       " '307',\n",
       " 'a higher quality of life of the wider society',\n",
       " 'EUR 340 million',\n",
       " 'Retail Banking in Slovenia, Corporate Bankingin Slovenia, and Strategic Foreign Markets',\n",
       " '30.12.2020',\n",
       " '69% women and 31% men',\n",
       " 'More than 200',\n",
       " '31%',\n",
       " 'corruption and bribery',\n",
       " '307',\n",
       " '2.11million',\n",
       " '17,297',\n",
       " '58%',\n",
       " '45',\n",
       " '2017',\n",
       " 'annually',\n",
       " 'CRS',\n",
       " '2019',\n",
       " '97%',\n",
       " 'EUR 340 million',\n",
       " '94',\n",
       " 'Beograd',\n",
       " '2,914',\n",
       " '4 Sep',\n",
       " '2%.',\n",
       " '69% women and 31% men',\n",
       " 'to invest in a systematicdevelopment of employees',\n",
       " '17,295',\n",
       " 'by e-mail, via the website,and social networks',\n",
       " '55%',\n",
       " '307',\n",
       " '2,914',\n",
       " '2020',\n",
       " '11']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You got the information that: NLB Group In total, 382 employeesdeparted from NLB Group in 2020.In total, 162 employees de Answer the following question: How many employees departed from NLB Group in 2020? 2. How many employees departed from NLB Group in 2020? 3. How many employees departed from NLB Group in 2020? 4. How many employees departed from NLB Group in 2020? 5.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_answers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
