# Robert Jutre≈°a's Data Science Project Competition journal

## March 2020 (8h)

* **1st (1h)**: Meeting with everyone - quick conversation about the data we are working with, establishing expectations, deciding on preliminary goals, setting up feature meetings and weekly schedule.
* **6th (2h)**: Working with my coworker - we looked at the agreed upon data, outlined important and numerical data, found some extraction tools for images, tables, text etc. We tested some, but not all, of them.
* **8th (30 min)**: Meeting with NLB - we talked about the data again, how they will prepare the question and answers that we will need, we also talked a bit about the scope of the task at hand.
* **9th (30 min)**: Meeting with faculty advisor - most importantly we discussed implementation approaches, as well as data preprocessing and acquisition (Tool-formers, paraphrasing to get more data, use text data not tables).
* **15th (4h)**: Meeting with the client and advisor from the industry - we talked about some starting ideas, decided to do a proof of concept for a simple question-answer generator using a model (1h). Creating and setting up stable conda environment (1h). We found a package *Haystack* with pre-built pipelines (also suggested by NLB). The first implementation was made to see how it would perform (2h).
* **20th (1h)**: Preparing the cleaned version of the extracted questions and answers for the client. Send it over e-mail (1h).
* **30th (30 min)**: Meeting with NLB - talked about the clean data, got an updated set. Talked about Cloud Computing platform with the advisor from the industry and got access to it. Made a plan for the next week.

## April 2020 (49h)
* **4th (6h)**: Working with my coworker - getting a baseline comparison of predictions from a model without fine tunning, working on the environment, and preparing a feature plan for development and testing of the main model.
* **5th (8h)**: Working with my coworker, meeting with the professor - original fine tuning, setting up a Sequence Extractive model, planning the next steps.
* **11th (8h)**: Working with my coworker - setting up a extractive model, starting the fine tunning process, further research, developing a plan.
* **12th (10h)**: Working with my coworker, meeting with the professor, meeting with NLB - fine tunning the model, setting up evaluation methods, comparing to a baseline model, future planning, writing the interim report, and status update.
* **13th (4h)**: Setting up a dense passage retrieval script, research, environment management.
* **14th (2h)**: Code/comment management, working environment assurance, report rereading, merging the development branch into master.
* **15th (1h)**: Interim report, minor changes, content updates based on advisor feedback and references fixes.  

## May 2020 (40h)
* **5th (6h)**: Working by myself - automatic question - answer - context generation for the 2022 report, collaboration with the client for a better dataset and setting plans for executing the plan.
* **9th (8h)**: Working with my coworker - setting up the full stable conda environment, testing functionalities of all scripts, setting up functional FAISS document store, building the full query - context extraction - answer generation pipeline.
* **10th (6h)**: Meeting with the client - talking about the final data (we should get it by the end of the week), planning the final report, setting up the full generative pipeline, making an MVP for model usage.
* **17th (8h)**: Meeting with the client, working with my coworker - going over final data changes, implementing the dpr fine tunning idea, working on pipeline evaluation and setting up scripts for the final phase.
* **18th (8h)**: Meeting with the professor, working with my coworker - implementing dpr fine tunning, going over final steps, setting up some extra scripts, final model training.
* **19th (4h)**: Working by myself - full data dpr fine-tunning, all model training, roberta testing.

## June 2020 ([total hours for June])

...

## Total: [total sum of hours]
